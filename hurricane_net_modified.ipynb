{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1001shiyuan/Hurricane-Trajectory-Prediction/blob/master/hurricane_net_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZAkYa2kYv4Q",
        "outputId": "33d23a0e-6f3e-4ab9-fe54-1a8e257a50a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/Hurricane-Trajectory-Prediction/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JBKmr2hMdb9",
        "outputId": "3f08a9e4-86d2-427e-84aa-a6890d77fed3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Hurricane-Trajectory-Prediction/docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5_QBAsqMtfD",
        "outputId": "39563403-6a5b-4b18-9559-724c5fd595ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive  hurricane-net-architecture.html  __init__.py\n",
            "data\t hurricane-net-architecture.png\n",
            "errors\t img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa7Z-ReQTA5t"
      },
      "source": [
        "# hurricane-net\n",
        "Hammad Usmani\n",
        "### A machine learning algorithm to forecast the intensity and trajectory of Atlantic tropical storms\n",
        "[https://github.com/hammad93/hurricane-net](https://github.com/hammad93/hurricane-net)\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "1. [Background](#Background)\n",
        "2. [Problem](#Problem)\n",
        "3. [Datasets](#Datasets)\n",
        "4. [Workflow Diagram](#Workflow)\n",
        "5. [Data Extraction](#Extract)\n",
        "6. [Data Transformation](#Transform)\n",
        "7. [Data Loading](#Load)\n",
        "8. [Feature Engineering](#FeatureEngineering)\n",
        "9. [Model Architecture](#ModelArchitecture)\n",
        "11. [Model Selection](#ModelSelection)\n",
        "12. [Paramater Optimization](#Optimization)\n",
        "13. [Model Evaluation & Benchmarks](#Benchmarks)\n",
        "14. [Visualizations](#Visualizations)\n",
        "\n",
        "![Hurricane Maria 2017](img/hurricane-maria.png \"Hurricane Maria. Source: NOAA\")\n",
        "\n",
        "## Background<a id=\"Background\"></a>\n",
        "\n",
        "The National Hurricane Center (NHC) and National Oceanic and Atmospheric Administration (NOAA) provide predictions for storms trajectories, intensity, and size. They create these predictions based on models that can be classified into 3 groups: dynamical, statistical, and ensemble [1]. The most accurate models are based on computational fluid dynamics and achieve more precision than their statistical and ensemble counterparts [1][4]. The current statistical models (OCD5) are based on multiple regression methods that can explain a significant amount of variance [1]. In this project, we research and implement the domain of machine learning and deep learning into predictive hurricane models for both trajectory and intensity and evaluate them against the NHC standards. \n",
        "Previous research into machine learning to forecast tropical Atlantic storms include a sparse recurrent neural network (Kordmahalleh, Sefidmazgi, & Homaifar, 2016) and an artificial neural network (Jung & Das, 2013); both achieved favorable results. The hurricane models created can be utilized to develop more precise emergency planning. There is a necessity for more accurate and timely models that can help reduce the amount of loss caused by hurricanes. \n",
        "\n",
        "## Problem<a id=\"Problem\"></a>\n",
        "\n",
        "The NOAA and NHC have several different classifications for Atlantic hurricane models that describe feature prediction and model architecture. The 3 main classifications for hurricane model architecture include dynamical, statistical, and ensemble. Classifications also include relative compute time required to create an output grouped as either early or late and forecast parameters such as trajectory, intensity, and wind radii. The most accurate models are late models that take upwards of 6 hours to produce an output whereas models that can produce an output in seconds to minutes are called early. Early models tend to be statistical which include the baseline model for trajectory named CLIPER5 Climatology and Persistence (CLP5) utilizing multivariate regression. The performance for these methods can be augmented by incorporating more advanced statistical methods from deep learning such as recurrent neural networks. Kordmahalleh et al., 2016 created a sparse recurrent neural network augmented by a genetic algorithm but there are factors requiring improvement. The training set utilized an older version of the NHC Hurricane Database format known as HURDAT while a new format has been released called HURDAT2 with additional information on wind radii. Kordmahalleh et al., 2016 also utilized benchmarks different from the standard applied within the NHC. Other than improving their methodology, we can expand the scope by creating separate models for both intensity and trajectory. These models can be used to predict the trajectory and intensity for future Atlantic storms.\n",
        "\n",
        "## Datasets<a id=\"Datasets\"></a>\n",
        "\n",
        "The following datasets and inputs including their sources will be used to create machine learning models:\n",
        "- NHC Hurricane Database (HURDAT2)\n",
        "    - http://www.nhc.noaa.gov/data/#hurdat\n",
        "    - https://www.kaggle.com/noaa/hurricane-database\n",
        "- NHC Forecast Error Database\n",
        "    - http://www.nhc.noaa.gov/verification/verify7.shtml\n",
        "- NHC GIS\n",
        "    - http://www.nhc.noaa.gov/gis/\n",
        "\n",
        "*In the future, the IBTrACS database will be used to extend the hurricane-ai to additional regions.*\n",
        "\n",
        "The NHC HURDAT2 database contains the tracking information for Atlantic tropical and subtropical cyclones which includes hurricanes and tropical storms from 1851 to 2016. The most updated version of the dataset is included on the noaa.gov site and includes 2 additional years of cyclone data compared to the data set available on Kaggle and is potentially more descriptive. To match the inputs of the baseline model used by the NHC, we are calculating the forward motion of the storm by applying a vector based on previous and current geographical location.\n",
        "\n",
        "*Table 1. This table contains the tentative features as input to the model*\n",
        "\n",
        "| **Name**         | **Data Type** | **Description**                                                     |\n",
        "|------------------|---------------|---------------------------------------------------------------------|\n",
        "| Time             | Date Time     | The date and time of the measurement.                               |\n",
        "| Latitude         | Float         | The geographical latitude of the storm eye to 1 decimal precision.  |\n",
        "| Longitude        | Float         | The geographical longitude of the storm eye to 1 decimal precision. |\n",
        "| Maximum Winds    | Integer       | The maximum sustained winds within the storm.                       |\n",
        "| Minimum Pressure | Integer       | The minimum barometric pressure within the storm.                   |\n",
        "| Forward Motion   | String        | Calculated vector of motion based on location in time series.       |\n",
        "\n",
        "The Forecast Error Database contains information on the accuracy of predicted models from the NHC. The two model forecast errors available are labeled OFCL and BCD5. The OFCL is the official NHC forecast and the BCD5 is the real track available. This data set can be used to benchmark and evaluate the deep learning model. \n",
        "The NOAA and NHC also hosts a geographical information system (GIS) that contains raw and processed data on hurricanes. The server hosting the GIS is publicly accessible and can be used to evaluate our model by comparing the 2017 Atlantic tropical season. The preliminary best tracks can be found here before they are finalized and available in the HURDAT2 data set. With the GIS, we can construct a final evaluation data set.\n",
        "\n",
        "*Diagram 1. This graphic describes the workflow for the deep learning models*.<a id=\"Workflow\"></a>\n",
        "![Data Pipeline](img/Deep Learning Workflow.png \"hurricane-net Data Pipeline\")\n",
        "\n",
        "## Extract Data<a id=\"Extract\"></a>\n",
        "\n",
        "*The following code uses the hurdat2 and models modules created to provide a class interface for the HURDAT2 and error forecast database located in the data and models folder. *\n",
        "\n",
        "We will begin our steps to perform extraction, transformation, and loading of our data for analysis or broadly known as ETL. Although we're dividing these steps into disctinct procedures, they are often more fluid and often have overlaps. The extraction phase consists of collecting and parsing the HURDAT2 and error forecast databases for analysis and benchmarking. The HURDAT2 database is our core foundation for creating the deep learning model. We store the database in its raw .txt format but it can be directly linked to the database hosted by the NHC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "F02MSMmiTA5x",
        "outputId": "4143679d-655b-414b-f697-0fc845276c7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
              "44681  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
              "44682  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
              "44683  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
              "44684  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
              "44685  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
              "\n",
              "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
              "44681  75.1W       30         1008       0  ...       0       0       0   \n",
              "44682  75.7W       30         1007       0  ...       0       0       0   \n",
              "44683  76.2W       30         1007       0  ...       0       0       0   \n",
              "44684  76.5W       35         1006      60  ...       0       0       0   \n",
              "44685  76.9W       40         1003      60  ...       0       0       0   \n",
              "\n",
              "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
              "44681       0       0       0       0       0       0       0  \n",
              "44682       0       0       0       0       0       0       0  \n",
              "44683       0       0       0       0       0       0       0  \n",
              "44684       0       0       0       0       0       0       0  \n",
              "44685       0       0       0       0       0       0       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fcccd20-3bda-47f2-8292-2da6099a130f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_id</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>34kt_ne</th>\n",
              "      <th>...</th>\n",
              "      <th>34kt_sw</th>\n",
              "      <th>34kt_nw</th>\n",
              "      <th>50kt_ne</th>\n",
              "      <th>50kt_se</th>\n",
              "      <th>50kt_sw</th>\n",
              "      <th>50kt_nw</th>\n",
              "      <th>64kt_ne</th>\n",
              "      <th>64kt_se</th>\n",
              "      <th>64kt_sw</th>\n",
              "      <th>64kt_nw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44681</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-23 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.1N</td>\n",
              "      <td>75.1W</td>\n",
              "      <td>30</td>\n",
              "      <td>1008</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44682</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.4N</td>\n",
              "      <td>75.7W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44683</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.8N</td>\n",
              "      <td>76.2W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44684</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>24.5N</td>\n",
              "      <td>76.5W</td>\n",
              "      <td>35</td>\n",
              "      <td>1006</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44685</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>25.4N</td>\n",
              "      <td>76.9W</td>\n",
              "      <td>40</td>\n",
              "      <td>1003</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fcccd20-3bda-47f2-8292-2da6099a130f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fcccd20-3bda-47f2-8292-2da6099a130f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fcccd20-3bda-47f2-8292-2da6099a130f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import various libraries throughout the software\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import datetime\n",
        "import dateutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from geopy.distance import great_circle as vc\n",
        "import math as Math\n",
        "# Import from hurdat2 class in data folder and models class from hurricane-models folder\n",
        "from data.hurdat2 import hurdat2\n",
        "from errors.models import models\n",
        "\n",
        "# Initialize Dataframe for hurricanes and error database\n",
        "# dataset = hurdat2(\"data/hurdat2.txt\")\n",
        "dataset = hurdat2(\"data/hurdat2-1851-2022-050423.txt\") # Note that this data includes up to and including 2016\n",
        "errors = models(\"errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt\")\n",
        "\n",
        "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
        "dataset.hurricanes.query('storm_id == \"AL122005\"').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk5uZFS0TA51",
        "outputId": "2fb5d72d-2b42-4098-aeed-adfa8add2d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): 0.0,\n",
            "                                      datetime.datetime(2005, 8, 29, 6, 0): 20.9,\n",
            "                                      datetime.datetime(2005, 8, 29, 18, 0): 93.6,\n",
            "                                      datetime.datetime(2005, 8, 30, 6, 0): 170.2,\n",
            "                                      datetime.datetime(2005, 8, 30, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 31, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 1, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'lat': 26.3,\n",
            "        'long': 88.6,\n",
            "        'sample_sizes': {       'F012': 0.33,\n",
            "                                'F024': 0.33,\n",
            "                                'F036': 0.33,\n",
            "                                'F048': 0.0,\n",
            "                                'F072': 0.0,\n",
            "                                'F096': 0.0,\n",
            "                                'F120': 0.0,\n",
            "                                'F144': 0.0,\n",
            "                                'F168': 0.0},\n",
            "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): 0.0,\n",
            "                                  datetime.datetime(2005, 8, 29, 6, 0): 28.0,\n",
            "                                  datetime.datetime(2005, 8, 29, 18, 0): 32.0,\n",
            "                                  datetime.datetime(2005, 8, 30, 6, 0): 17.0,\n",
            "                                  datetime.datetime(2005, 8, 30, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 31, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 1, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'wind_speed': 150}\n"
          ]
        }
      ],
      "source": [
        "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
        "pprint(errors.models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_direc_of_travel(data, total_data_count):\n",
        "  data['distance'] = np.zeros(total_data_count)\n",
        "  data['direction'] = np.zeros(total_data_count)\n",
        "\n",
        "  # For all hurricanes\n",
        "  for x in range(0, total_hurricane_count):\n",
        "      t = pd.DataFrame(data[data['unique-key'] == keys[x][1]], columns = data.keys()).reset_index(drop = False)\n",
        "      dst = 0\n",
        "      prev = (0,0)\n",
        "      \n",
        "      # For all latitude and longitude points of hurricane, calculate the angle of travel and distance\n",
        "      for p in zip(t['Lat'], t['Long']):\n",
        "          \n",
        "          if prev == (0,0):\n",
        "              prev = p\n",
        "              continue \n",
        "          # Stores the distance into the DataFrame\n",
        "          data.at[t[(t['Lat'] == p[0]) & (t['Long'] == p[1])]['index'].values[0], 'distance'] = vc(prev,p).miles\n",
        "          \n",
        "          dLon = p[1] - prev[1];  \n",
        "          temp = float(p[0]) # p[0] is a str?\n",
        "          y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "          \n",
        "          x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "          brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "          if (brng < 0):\n",
        "              brng+= 360;\n",
        "          \n",
        "          # Stores the angle of travel into the DataFrame\n",
        "          data.at[t[(t['Lat'] == p[0]) & (t['Long'] == p[1])]['index'].values[0], 'direction'] = brng\n",
        "          dst += vc(prev,p).miles\n",
        "          prev = p\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "iRX8M6uDaArh",
        "outputId": "37edacb5-63cf-4261-e2b2-7bd8dfdee3bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f6c17f2241ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhurricanes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'storm_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4472\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4473\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4474\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4476\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4610\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresolvers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENGINES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0meng_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/engines.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# make sure no names in resolvers and locals/globals clash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         return reconstruct_object(\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/engines.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0m_check_ne_builtin_clash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# Create a signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     signature = [(name, getType(arg)) for (name, arg) in\n\u001b[0m\u001b[1;32m    823\u001b[0m                  zip(names, arguments)]\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# Create a signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     signature = [(name, getType(arg)) for (name, arg) in\n\u001b[0m\u001b[1;32m    823\u001b[0m                  zip(names, arguments)]\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mgetType\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NumExpr 2 does not support Unicode as a dtype.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown type object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vtb4-c_TA55"
      },
      "source": [
        "## Transform Data<a id=\"Transform\"></a>\n",
        "\n",
        "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a `storm_id` dictionary to store storm names matched with ID's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXygtaGkTA56",
        "outputId": "708cc641-68cf-4344-d057-ff723b014e0d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming HURDAT2 into objects . . .\n",
            "Transforming 53976/53976 entries from HURDAT2\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Create hurricane class\n",
        "class hurricane(object) : \n",
        "    def __init__(self, name, id) :\n",
        "        # Set instance variables\n",
        "        self.name = name\n",
        "        self.id = id\n",
        "        self.entries = dict()\n",
        "        self.models = dict()\n",
        "        \n",
        "        return\n",
        "    # Add hurricane track entry based on standard HURDAT2 format\n",
        "    def add_entry(self, array) :\n",
        "        entry = {\n",
        "            array[0] : { # dateteime of entry\n",
        "                'entry_time' : array[0], \n",
        "                'entry_id' : array[1],\n",
        "                'entry_status' : array[2],\n",
        "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
        "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
        "                'max_wind' : float(array[5]),\n",
        "                'min_pressure' : 980 if array[6] is None else float(array[6]), # Early records are -999 or None\n",
        "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
        "            }\n",
        "        }\n",
        "        self.entries.update(entry)\n",
        "        \n",
        "        return\n",
        "    # Add hurricane model errors\n",
        "    def add_model(self, name, model) :\n",
        "        self.models[name] = model\n",
        "        \n",
        "        return\n",
        "# Storm ID Key for matching between datasets\n",
        "storm_ids = dict()\n",
        "\n",
        "# Parse in hurricanes\n",
        "hurricanes = dict()\n",
        "print(\"Transforming HURDAT2 into objects . . .\")\n",
        "for index, entry in dataset.hurricanes.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset.hurricanes)), end = \"\\r\")\n",
        "    # New hurricane\n",
        "    if entry['storm_id'] not in hurricanes :\n",
        "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storm_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "ZEMk97GRbWC0",
        "outputId": "13bf0449-3096-45d3-ec56-9dd2c667c5c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1f55ea694551>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstorm_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'storm_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(hurricanes.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AedAAgzqjXJI",
        "outputId": "6ee0fe6d-4a40-4a10-bffa-d4a1f56c4c72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'AL071948', 'AL141998', 'AL081994', 'AL061995', 'AL162000', 'AL091990', 'AL121934', 'AL091903', 'AL061931', 'AL041885', 'AL031953', 'AL041932', 'AL051878', 'AL061944', 'AL182005', 'AL181979', 'AL091997', 'AL041976', 'AL011981', 'AL051889', 'AL041983', 'AL011991', 'AL102015', 'AL051861', 'AL051974', 'AL022008', 'AL091878', 'AL061985', 'AL031989', 'AL112019', 'AL021938', 'AL202005', 'AL061976', 'AL101949', 'AL021991', 'AL051916', 'AL201981', 'AL021875', 'AL171933', 'AL011922', 'AL151975', 'AL121893', 'AL051899', 'AL021986', 'AL051955', 'AL082016', 'AL071880', 'AL011884', 'AL091924', 'AL091934', 'AL012021', 'AL041950', 'AL041861', 'AL122003', 'AL112012', 'AL051971', 'AL041923', 'AL011949', 'AL201979', 'AL202019', 'AL011890', 'AL071972', 'AL071888', 'AL142008', 'AL141944', 'AL041959', 'AL111988', 'AL011990', 'AL011904', 'AL061957', 'AL141966', 'AL031902', 'AL141959', 'AL022019', 'AL051954', 'AL141995', 'AL021928', 'AL071865', 'AL051919', 'AL071937', 'AL181933', 'AL011853', 'AL141974', 'AL021912', 'AL141976', 'AL091979', 'AL101959', 'AL091906', 'AL011927', 'AL101899', 'AL021878', 'AL021895', 'AL011984', 'AL092015', 'AL051879', 'AL021853', 'AL111974', 'AL031957', 'AL011900', 'AL111906', 'AL142005', 'AL061899', 'AL061962', 'AL072005', 'AL031961', 'AL021992', 'AL071965', 'AL041951', 'AL011946', 'AL182003', 'AL061963', 'AL111944', 'AL011968', 'AL051901', 'AL011888', 'AL172000', 'AL151974', 'AL111996', 'AL051867', 'AL102010', 'AL031945', 'AL111991', 'AL042001', 'AL071906', 'AL062015', 'AL062010', 'AL141916', 'AL021890', 'AL082013', 'AL081869', 'AL011920', 'AL161936', 'AL111886', 'AL161999', 'AL142016', 'AL021892', 'AL162018', 'AL011941', 'AL021972', 'AL051877', 'AL151989', 'AL141984', 'AL051855', 'AL051871', 'AL111937', 'AL051957', 'AL081999', 'AL041938', 'AL021868', 'AL032016', 'AL031851', 'AL152013', 'AL031863', 'AL112011', 'AL172011', 'AL071903', 'AL072022', 'AL101886', 'AL091933', 'AL041892', 'AL031932', 'AL091970', 'AL041887', 'AL101878', 'AL121974', 'AL012019', 'AL021971', 'AL292005', 'AL051852', 'AL092021', 'AL071990', 'AL021877', 'AL061901', 'AL031965', 'AL071916', 'AL091916', 'AL071982', 'AL031867', 'AL011942', 'AL061866', 'AL111945', 'AL051973', 'AL041918', 'AL031960', 'AL031952', 'AL041965', 'AL171980', 'AL052003', 'AL021962', 'AL041937', 'AL011934', 'AL081938', 'AL121950', 'AL071889', 'AL021975', 'AL062008', 'AL071979', 'AL161984', 'AL151887', 'AL012020', 'AL232020', 'AL051911', 'AL132019', 'AL031969', 'AL071892', 'AL041853', 'AL011924', 'AL011997', 'AL041878', 'AL091986', 'AL011857', 'AL021870', 'AL071942', 'AL041962', 'AL011940', 'AL061880', 'AL071999', 'AL041966', 'AL011977', 'AL102008', 'AL111956', 'AL031967', 'AL161887', 'AL061891', 'AL021927', 'AL082011', 'AL052005', 'AL131966', 'AL142021', 'AL071900', 'AL011978', 'AL071879', 'AL031927', 'AL142007', 'AL031934', 'AL061926', 'AL091887', 'AL082019', 'AL081955', 'AL031978', 'AL021944', 'AL111901', 'AL021882', 'AL051968', 'AL061918', 'AL161980', 'AL172008', 'AL102000', 'AL041879', 'AL031968', 'AL021886', 'AL011854', 'AL011873', 'AL061986', 'AL071932', 'AL061865', 'AL021970', 'AL011985', 'AL031858', 'AL072010', 'AL132000', 'AL242020', 'AL061923', 'AL111976', 'AL162008', 'AL061921', 'AL091998', 'AL021904', 'AL062019', 'AL021932', 'AL121951', 'AL011870', 'AL011911', 'AL041964', 'AL161972', 'AL141990', 'AL022004', 'AL051863', 'AL091968', 'AL011945', 'AL131933', 'AL151981', 'AL061893', 'AL052019', 'AL081889', 'AL061886', 'AL022010', 'AL031964', 'AL022007', 'AL071923', 'AL041877', 'AL021896', 'AL121987', 'AL091981', 'AL172003', 'AL072001', 'AL102012', 'AL011947', 'AL131949', 'AL081932', 'AL041946', 'AL041909', 'AL061898', 'AL011862', 'AL011898', 'AL012014', 'AL051943', 'AL152004', 'AL021872', 'AL011962', 'AL191970', 'AL081892', 'AL152011', 'AL052017', 'AL072012', 'AL021925', 'AL031890', 'AL041907', 'AL131934', 'AL061877', 'AL021900', 'AL031897', 'AL021930', 'AL061984', 'AL111954', 'AL121984', 'AL031998', 'AL031900', 'AL131975', 'AL052008', 'AL041900', 'AL111989', 'AL091898', 'AL142012', 'AL031995', 'AL231967', 'AL181978', 'AL131974', 'AL061928', 'AL111951', 'AL091989', 'AL212021', 'AL181971', 'AL122021', 'AL041971', 'AL081880', 'AL151950', 'AL051894', 'AL071952', 'AL062003', 'AL221981', 'AL021959', 'AL162007', 'AL091988', 'AL021998', 'AL111961', 'AL011864', 'AL041880', 'AL021924', 'AL111936', 'AL021996', 'AL071853', 'AL121887', 'AL142022', 'AL011855', 'AL141970', 'AL101870', 'AL021982', 'AL071931', 'AL092003', 'AL091948', 'AL131973', 'AL102001', 'AL071973', 'AL041928', 'AL031852', 'AL112008', 'AL171936', 'AL012009', 'AL222005', 'AL021917', 'AL122016', 'AL011929', 'AL021864', 'AL071977', 'AL141967', 'AL071987', 'AL132003', 'AL071898', 'AL182019', 'AL031892', 'AL091908', 'AL032017', 'AL061998', 'AL121999', 'AL081966', 'AL131959', 'AL112003', 'AL021851', 'AL081984', 'AL031938', 'AL052015', 'AL061862', 'AL091991', 'AL021946', 'AL111958', 'AL121959', 'AL022002', 'AL032008', 'AL151984', 'AL031886', 'AL272005', 'AL032020', 'AL101986', 'AL042009', 'AL312020', 'AL021854', 'AL071951', 'AL021915', 'AL201971', 'AL051892', 'AL091954', 'AL041972', 'AL081867', 'AL031901', 'AL041910', 'AL041872', 'AL041889', 'AL041931', 'AL051934', 'AL061956', 'AL101898', 'AL082005', 'AL112022', 'AL071899', 'AL032001', 'AL061894', 'AL122018', 'AL061879', 'AL011936', 'AL041970', 'AL071954', 'AL092005', 'AL051962', 'AL092006', 'AL091901', 'AL141950', 'AL011899', 'AL031988', 'AL102013', 'AL151999', 'AL081908', 'AL021903', 'AL061908', 'AL061896', 'AL022005', 'AL171972', 'AL051933', 'AL021855', 'AL061933', 'AL061858', 'AL032010', 'AL061983', 'AL111980', 'AL151978', 'AL102021', 'AL121977', 'AL041898', 'AL061939', 'AL031878', 'AL011910', 'AL051938', 'AL241969', 'AL092016', 'AL051872', 'AL061949', 'AL031993', 'AL231970', 'AL152005', 'AL191981', 'AL151932', 'AL192012', 'AL051880', 'AL061895', 'AL061859', 'AL031891', 'AL011986', 'AL031864', 'AL081949', 'AL161990', 'AL031999', 'AL021857', 'AL022021', 'AL021987', 'AL121995', 'AL061913', 'AL041924', 'AL061977', 'AL011998', 'AL131954', 'AL151969', 'AL142018', 'AL011894', 'AL152019', 'AL081945', 'AL082004', 'AL071927', 'AL111985', 'AL132020', 'AL051928', 'AL061945', 'AL111977', 'AL121971', 'AL161971', 'AL111975', 'AL061900', 'AL071994', 'AL131978', 'AL041996', 'AL072015', 'AL061882', 'AL041954', 'AL011895', 'AL132005', 'AL082020', 'AL011938', 'AL051906', 'AL051983', 'AL141985', 'AL051881', 'AL071961', 'AL101973', 'AL031881', 'AL051956', 'AL091923', 'AL072007', 'AL081863', 'AL051886', 'AL081891', 'AL031951', 'AL021997', 'AL081977', 'AL011887', 'AL061924', 'AL021965', 'AL011989', 'AL161988', 'AL101869', 'AL101933', 'AL041989', 'AL011881', 'AL071943', 'AL151933', 'AL031947', 'AL121958', 'AL071955', 'AL012022', 'AL131967', 'AL061911', 'AL031893', 'AL071908', 'AL031982', 'AL162019', 'AL081901', 'AL041881', 'AL021876', 'AL091926', 'AL081933', 'AL282005', 'AL041854', 'AL191971', 'AL051898', 'AL122005', 'AL061912', 'AL161954', 'AL111942', 'AL021869', 'AL121994', 'AL152000', 'AL131971', 'AL032019', 'AL171976', 'AL021939', 'AL041995', 'AL022012', 'AL051869', 'AL081964', 'AL041921', 'AL091973', 'AL062001', 'AL032002', 'AL081916', 'AL021940', 'AL071947', 'AL051909', 'AL061990', 'AL032003', 'AL251967', 'AL021948', 'AL022000', 'AL151972', 'AL051981', 'AL031979', 'AL072019', 'AL172022', 'AL131990', 'AL141987', 'AL081992', 'AL142020', 'AL081898', 'AL081974', 'AL091863', 'AL121980', 'AL121978', 'AL172021', 'AL071962', 'AL252020', 'AL021921', 'AL212020', 'AL141887', 'AL051932', 'AL111924', 'AL071984', 'AL011970', 'AL271967', 'AL012007', 'AL052009', 'AL022015', 'AL091995', 'AL052002', 'AL081888', 'AL072011', 'AL011921', 'AL011930', 'AL131984', 'AL031986', 'AL021901', 'AL182011', 'AL071981', 'AL101880', 'AL011893', 'AL041916', 'AL061853', 'AL031875', 'AL011916', 'AL021990', 'AL071956', 'AL021958', 'AL011868', 'AL221971', 'AL081995', 'AL132010', 'AL081924', 'AL212003', 'AL051978', 'AL031916', 'AL071969', 'AL142003', 'AL021913', 'AL161970', 'AL162012', 'AL031972', 'AL031928', 'AL061904', 'AL061915', 'AL091869', 'AL032018', 'AL151949', 'AL051959', 'AL071997', 'AL042018', 'AL041891', 'AL011926', 'AL051972', 'AL282020', 'AL052006', 'AL122013', 'AL192003', 'AL051951', 'AL271969', 'AL021949', 'AL082018', 'AL082022', 'AL071946', 'AL011954', 'AL041859', 'AL191933', 'AL011863', 'AL011917', 'AL051853', 'AL121975', 'AL091985', 'AL011995', 'AL011966', 'AL051989', 'AL152007', 'AL161975', 'AL171984', 'AL112009', 'AL041884', 'AL171978', 'AL101901', 'AL011993', 'AL031924', 'AL011876', 'AL111916', 'AL191975', 'AL121979', 'AL141953', 'AL061937', 'AL081937', 'AL101968', 'AL031997', 'AL122010', 'AL061946', 'AL031898', 'AL021916', 'AL041917', 'AL052000', 'AL042003', 'AL041955', 'AL011883', 'AL011860', 'AL012017', 'AL101971', 'AL132012', 'AL161976', 'AL132004', 'AL131998', 'AL041952', 'AL051924', 'AL011992', 'AL141978', 'AL031895', 'AL031915', 'AL051988', 'AL211967', 'AL012003', 'AL031985', 'AL141968', 'AL021936', 'AL091975', 'AL081973', 'AL172010', 'AL011979', 'AL071887', 'AL051976', 'AL281969', 'AL041929', 'AL051992', 'AL131995', 'AL081931', 'AL071949', 'AL021968', 'AL041902', 'AL191979', 'AL071874', 'AL041991', 'AL291969', 'AL031950', 'AL102003', 'AL051856', 'AL182010', 'AL102016', 'AL061988', 'AL061889', 'AL111933', 'AL031909', 'AL101965', 'AL041977', 'AL042014', 'AL011963', 'AL052022', 'AL052016', 'AL092004', 'AL011865', 'AL051958', 'AL172020', 'AL021909', 'AL051986', 'AL061878', 'AL111932', 'AL111998', 'AL091994', 'AL031974', 'AL101954', 'AL091899', 'AL141954', 'AL022017', 'AL211971', 'AL141949', 'AL131901', 'AL061916', 'AL091965', 'AL132021', 'AL071944', 'AL061955', 'AL041985', 'AL051980', 'AL011996', 'AL121878', 'AL021978', 'AL021898', 'AL062021', 'AL031917', 'AL011889', 'AL081940', 'AL012004', 'AL022022', 'AL121955', 'AL031963', 'AL011935', 'AL101955', 'AL101984', 'AL061887', 'AL052020', 'AL112021', 'AL061861', 'AL062006', 'AL151971', 'AL051927', 'AL021852', 'AL191967', 'AL051913', 'AL061951', 'AL051893', 'AL121886', 'AL051948', 'AL011856', 'AL171988', 'AL111926', 'AL011965', 'AL051985', 'AL091892', 'AL051875', 'AL141981', 'AL122017', 'AL051975', 'AL171973', 'AL011897', 'AL141979', 'AL062007', 'AL031944', 'AL061856', 'AL072013', 'AL072009', 'AL011880', 'AL081991', 'AL082001', 'AL061974', 'AL061999', 'AL041851', 'AL051866', 'AL111971', 'AL101978', 'AL051874', 'AL011877', 'AL041980', 'AL181972', 'AL082003', 'AL011907', 'AL111995', 'AL041860', 'AL021867', 'AL061992', 'AL131931', 'AL041927', 'AL022013', 'AL021963', 'AL061941', 'AL042007', 'AL021994', 'AL021956', 'AL041940', 'AL021937', 'AL081886', 'AL071933', 'AL111893', 'AL071866', 'AL151979', 'AL031981', 'AL272020', 'AL112016', 'AL011933', 'AL011953', 'AL091964', 'AL071993', 'AL021888', 'AL212005', 'AL072018', 'AL011952', 'AL021926', 'AL302005', 'AL071901', 'AL101956', 'AL082006', 'AL041984', 'AL041997', 'AL122020', 'AL131932', 'AL041944', 'AL101932', 'AL031931', 'AL241978', 'AL031913', 'AL032005', 'AL081923', 'AL152016', 'AL061954', 'AL071863', 'AL011951', 'AL022006', 'AL011858', 'AL021907', 'AL051903', 'AL081934', 'AL121969', 'AL051900', 'AL011971', 'AL081997', 'AL081944', 'AL141971', 'AL051902', 'AL071885', 'AL312005', 'AL051969', 'AL061980', 'AL091953', 'AL081859', 'AL151968', 'AL041897', 'AL011988', 'AL011896', 'AL031888', 'AL021974', 'AL211978', 'AL202003', 'AL061909', 'AL152021', 'AL051963', 'AL021980', 'AL011903', 'AL192017', 'AL011892', 'AL041901', 'AL051970', 'AL121968', 'AL021891', 'AL012008', 'AL021929', 'AL152012', 'AL122019', 'AL121901', 'AL101936', 'AL081853', 'AL021879', 'AL162017', 'AL081986', 'AL151980', 'AL131976', 'AL121936', 'AL011976', 'AL061993', 'AL162021', 'AL102020', 'AL111950', 'AL061953', 'AL191972', 'AL122015', 'AL022020', 'AL011925', 'AL201974', 'AL031912', 'AL081878', 'AL091947', 'AL031871', 'AL031937', 'AL031977', 'AL152020', 'AL141975', 'AL122004', 'AL091940', 'AL131955', 'AL111953', 'AL031990', 'AL141988', 'AL132022', 'AL221975', 'AL011909', 'AL031984', 'AL071924', 'AL091992', 'AL091938', 'AL081942', 'AL021964', 'AL122001', 'AL011913', 'AL132001', 'AL021999', 'AL021931', 'AL071936', 'AL211970', 'AL081970', 'AL022009', 'AL061875', 'AL081959', 'AL041890', 'AL031870', 'AL092009', 'AL021897', 'AL021899', 'AL072008', 'AL031983', 'AL011961', 'AL041981', 'AL122011', 'AL052013', 'AL192000', 'AL091999', 'AL111934', 'AL071998', 'AL071878', 'AL042017', 'AL041987', 'AL051941', 'AL041939', 'AL061940', 'AL011914', 'AL102007', 'AL162010', 'AL061959', 'AL021889', 'AL231975', 'AL081969', 'AL081893', 'AL092008', 'AL101952', 'AL011879', 'AL101924', 'AL171995', 'AL091870', 'AL061947', 'AL081961', 'AL202020', 'AL101995', 'AL072004', 'AL021947', 'AL031930', 'AL081988', 'AL191988', 'AL092013', 'AL051915', 'AL141972', 'AL031896', 'AL242005', 'AL031899', 'AL051947', 'AL062002', 'AL112010', 'AL051858', 'AL041935', 'AL061968', 'AL061997', 'AL251969', 'AL061881', 'AL221970', 'AL071971', 'AL061996', 'AL041990', 'AL112007', 'AL121916', 'AL041956', 'AL011901', 'AL061958', 'AL071995', 'AL082014', 'AL101963', 'AL152008', 'AL021983', 'AL172005', 'AL051952', 'AL012000', 'AL031971', 'AL071985', 'AL041974', 'AL051977', 'AL081903', 'AL031940', 'AL091996', 'AL111964', 'AL021943', 'AL011859', 'AL181974', 'AL011980', 'AL102011', 'AL031887', 'AL061987', 'AL131916', 'AL051922', 'AL051860', 'AL042012', 'AL021935', 'AL021985', 'AL111931', 'AL101976', 'AL121981', 'AL051979', 'AL021911', 'AL031894', 'AL041863', 'AL162016', 'AL052001', 'AL121956', 'AL131950', 'AL211976', 'AL121989', 'AL021977', 'AL062018', 'AL021934', 'AL011939', 'AL091980', 'AL031942', 'AL152001', 'AL051895', 'AL081956', 'AL101891', 'AL041906', 'AL081871', 'AL072000', 'AL091893', 'AL081996', 'AL081906', 'AL232005', 'AL201975', 'AL011869', 'AL051851', 'AL071970', 'AL121949', 'AL052021', 'AL131970', 'AL041875', 'AL071891', 'AL131980', 'AL041869', 'AL032011', 'AL051994', 'AL071869', 'AL101987', 'AL061885', 'AL162020', 'AL032014', 'AL172012', 'AL032007', 'AL091937', 'AL061991', 'AL041994', 'AL091886', 'AL041973', 'AL032013', 'AL042010', 'AL051946', 'AL142010', 'AL011871', 'AL121985', 'AL071870', 'AL021905', 'AL051987', 'AL041858', 'AL031936', 'AL092020', 'AL121972', 'AL071976', 'AL041933', 'AL041936', 'AL031943', 'AL111967', 'AL121961', 'AL021961', 'AL112004', 'AL071964', 'AL041958', 'AL131989', 'AL072014', 'AL101909', 'AL051876', 'AL041961', 'AL171979', 'AL061981', 'AL021919', 'AL011891', 'AL041953', 'AL011874', 'AL051936', 'AL071960', 'AL051931', 'AL171887', 'AL101934', 'AL211995', 'AL051953', 'AL061979', 'AL041862', 'AL051905', 'AL131981', 'AL091969', 'AL031907', 'AL051910', 'AL032021', 'AL061934', 'AL181988', 'AL021859', 'AL081975', 'AL161978', 'AL061982', 'AL081972', 'AL121976', 'AL041874', 'AL111887', 'AL021860', 'AL041857', 'AL011902', 'AL091972', 'AL041871', 'AL101974', 'AL121966', 'AL071975', 'AL012012', 'AL081998', 'AL052014', 'AL101893', 'AL071909', 'AL081987', 'AL071859', 'AL011852', 'AL011875', 'AL151966', 'AL041852', 'AL152018', 'AL121970', 'AL262020', 'AL071934', 'AL041873', 'AL021894', 'AL161969', 'AL182017', 'AL081885', 'AL021884', 'AL021995', 'AL071945', 'AL031872', 'AL041998', 'AL201978', 'AL082010', 'AL161949', 'AL051993', 'AL071877', 'AL031873', 'AL021885', 'AL122000', 'AL121964', 'AL081926', 'AL152003', 'AL021966', 'AL021981', 'AL011867', 'AL031973', 'AL041908', 'AL081899', 'AL032012', 'AL041943', 'AL101958', 'AL041986', 'AL041895', 'AL101906', 'AL171969', 'AL131979', 'AL071921', 'AL021951', 'AL132007', 'AL091993', 'AL261969', 'AL101926', 'AL051995', 'AL101975', 'AL131985', 'AL132002', 'AL111979', 'AL081943', 'AL092001', 'AL041941', 'AL021873', 'AL181984', 'AL021993', 'AL041988', 'AL161974', 'AL182012', 'AL041919', 'AL121932', 'AL202010', 'AL141932', 'AL041993', 'AL061851', 'AL061938', 'AL081993', 'AL031880', 'AL021920', 'AL051896', 'AL031966', 'AL071926', 'AL221978', 'AL161995', 'AL061874', 'AL052004', 'AL111999', 'AL032004', 'AL072016', 'AL211975', 'AL081951', 'AL051961', 'AL112018', 'AL031859', 'AL112020', 'AL081957', 'AL111984', 'AL071963', 'AL201933', 'AL101980', 'AL091958', 'AL031941', 'AL061903', 'AL101916', 'AL031976', 'AL101966', 'AL051997', 'AL201984', 'AL031911', 'AL072003', 'AL101999', 'AL081960', 'AL062022', 'AL032022', 'AL061966', 'AL192019', 'AL042020', 'AL051904', 'AL101988', 'AL021858', 'AL022003', 'AL061932', 'AL042011', 'AL031857', 'AL101903', 'AL091951', 'AL112002', 'AL021871', 'AL011964', 'AL091867', 'AL081870', 'AL021893', 'AL141933', 'AL051939', 'AL061960', 'AL141999', 'AL051937', 'AL021922', 'AL031882', 'AL102018', 'AL131999', 'AL041925', 'AL081978', 'AL031929', 'AL151995', 'AL092017', 'AL051991', 'AL151916', 'AL011956', 'AL061972', 'AL081948', 'AL062004', 'AL101972', 'AL051888', 'AL091909', 'AL181967', 'AL062020', 'AL021863', 'AL081950', 'AL171975', 'AL021918', 'AL011982', 'AL012001', 'AL051926', 'AL022001', 'AL091956', 'AL031918', 'AL111972', 'AL031994', 'AL151988', 'AL161966', 'AL151973', 'AL011987', 'AL031958', 'AL061965', 'AL191978', 'AL081985', 'AL052012', 'AL011975', 'AL022011', 'AL192020', 'AL011955', 'AL071881', 'AL132013', 'AL102019', 'AL061950', 'AL082021', 'AL111952', 'AL031926', 'AL131887', 'AL031975', 'AL051891', 'AL141977', 'AL041904', 'AL061978', 'AL031868', 'AL061871', 'AL062012', 'AL072017', 'AL111878', 'AL031996', 'AL121967', 'AL041903', 'AL051882', 'AL111955', 'AL031877', 'AL051964', 'AL161968', 'AL051870', 'AL071996', 'AL201976', 'AL162001', 'AL052011', 'AL081952', 'AL042021', 'AL191969', 'AL122012', 'AL091944', 'AL031925', 'AL061961', 'AL011967', 'AL021954', 'AL081936', 'AL051859', 'AL081887', 'AL111909', 'AL161981', 'AL012010', 'AL211981', 'AL092002', 'AL041979', 'AL071896', 'AL051923', 'AL061971', 'AL041905', 'AL101945', 'AL162011', 'AL131936', 'AL201970', 'AL212010', 'AL021976', 'AL142011', 'AL012006', 'AL031885', 'AL091959', 'AL222020', 'AL031883', 'AL012002', 'AL181980', 'AL302020', 'AL032006', 'AL051920', 'AL011931', 'AL121944', 'AL101887', 'AL091976', 'AL041949', 'AL041886', 'AL181970', 'AL011915', 'AL042015', 'AL031853', 'AL121933', 'AL021941', 'AL101947', 'AL101985', 'AL021950', 'AL082007', 'AL112015', 'AL071894', 'AL051885', 'AL031946', 'AL051935', 'AL031903', 'AL091931', 'AL051945', 'AL111987', 'AL152022', 'AL091974', 'AL021856', 'AL041975', 'AL091889', 'AL061948', 'AL172017', 'AL031921', 'AL051965', 'AL042000', 'AL041960', 'AL112017', 'AL011872', 'AL162005', 'AL091942', 'AL041963', 'AL182021', 'AL091932', 'AL101943', 'AL231978', 'AL171967', 'AL021957', 'AL021988', 'AL081954', 'AL081982', 'AL111870', 'AL031919', 'AL091977', 'AL151977', 'AL011972', 'AL141980', 'AL132008', 'AL021881', 'AL092022', 'AL011908', 'AL082008', 'AL172007', 'AL101977', 'AL101964', 'AL181975', 'AL091955', 'AL181995', 'AL071938', 'AL061943', 'AL031869', 'AL031949', 'AL011918', 'AL021883', 'AL142000', 'AL161950', 'AL051912', 'AL071940', 'AL121954', 'AL111978', 'AL011999', 'AL062014', 'AL161967', 'AL071966', 'AL091987', 'AL092011', 'AL031906', 'AL081968', 'AL071959', 'AL041922', 'AL031855', 'AL081981', 'AL051897', 'AL021874', 'AL041934', 'AL071992', 'AL091949', 'AL092018', 'AL051982', 'AL051950', 'AL071957', 'AL202011', 'AL031948', 'AL071986', 'AL101994', 'AL022014', 'AL032015', 'AL081909', 'AL012013', 'AL121909', 'AL011885', 'AL121991', 'AL122002', 'AL162004', 'AL061906', 'AL041982', 'AL062000', 'AL211969', 'AL131996', 'AL121996', 'AL102022', 'AL061975', 'AL101942', 'AL042004', 'AL171971', 'AL131944', 'AL051949', 'AL021953', 'AL152017', 'AL091963', 'AL111981', 'AL131953', 'AL301969', 'AL092007', 'AL021952', 'AL112000', 'AL081976', 'AL082015', 'AL101992', 'AL071867', 'AL111880', 'AL051940', 'AL031955', 'AL041978', 'AL061860', 'AL151967', 'AL082017', 'AL041868', 'AL041899', 'AL111994', 'AL092019', 'AL061935', 'AL011958', 'AL011919', 'AL021960', 'AL091945', 'AL111959', 'AL051929', 'AL041926', 'AL041915', 'AL041942', 'AL082012', 'AL082002', 'AL041957', 'AL142019', 'AL111966', 'AL061863', 'AL081990', 'AL142002', 'AL062005', 'AL031905', 'AL021973', 'AL031962', 'AL121990', 'AL101993', 'AL041912', 'AL012005', 'AL102005', 'AL061888', 'AL161933', 'AL042016', 'AL071974', 'AL051908', 'AL021861', 'AL011912', 'AL031884', 'AL041888', 'AL192010', 'AL041894', 'AL021989', 'AL101948', 'AL011960', 'AL181976', 'AL021880', 'AL062013', 'AL091943', 'AL131977', 'AL031933', 'AL181981', 'AL061869', 'AL031879', 'AL031956', 'AL041896', 'AL131969', 'AL031862', 'AL062009', 'AL081963', 'AL041866', 'AL071871', 'AL201969', 'AL091966', 'AL031939', 'AL031920', 'AL011994', 'AL081953', 'AL011866', 'AL061897', 'AL031922', 'AL041992', 'AL021979', 'AL151936', 'AL022016', 'AL191995', 'AL051944', 'AL101944', 'AL281967', 'AL102009', 'AL191974', 'AL071980', 'AL031910', 'AL041999', 'AL172001', 'AL182020', 'AL031908', 'AL202021', 'AL061952', 'AL081980', 'AL132018', 'AL231969', 'AL141989', 'AL101979', 'AL062016', 'AL052010', 'AL042006', 'AL221969', 'AL101981', 'AL032009', 'AL041911', 'AL122007', 'AL031889', 'AL031970', 'AL012018', 'AL151954', 'AL131968', 'AL101991', 'AL171966', 'AL051873', 'AL091888', 'AL101989', 'AL142001', 'AL051996', 'AL071988', 'AL031865', 'AL081947', 'AL061927', 'AL102006', 'AL252005', 'AL061994', 'AL042008', 'AL051887', 'AL011923', 'AL091978', 'AL172019', 'AL031866', 'AL012011', 'AL011943', 'AL122022', 'AL031935', 'AL092000', 'AL041867', 'AL161973', 'AL071893', 'AL191984', 'AL061942', 'AL201995', 'AL031923', 'AL042002', 'AL071861', 'AL031861', 'AL021865', 'AL071950', 'AL031987', 'AL092014', 'AL031959', 'AL011948', 'AL111970', 'AL101990', 'AL011928', 'AL091950', 'AL081879', 'AL071860', 'AL032000', 'AL101950', 'AL142004', 'AL041893', 'AL041948', 'AL082009', 'AL021942', 'AL182000', 'AL011974', 'AL091880', 'AL021908', 'AL192005', 'AL011944', 'AL051942', 'AL192011', 'AL041864', 'AL041855', 'AL011878', 'AL151990', 'AL051999', 'AL131972', 'AL072002', 'AL101908', 'AL021984', 'AL031856', 'AL081965', 'AL081877', 'AL142017', 'AL142013', 'AL131964', 'AL051984', 'AL081861', 'AL192021', 'AL092010', 'AL062011', 'AL021945', 'AL151970', 'AL011973', 'AL072006', 'AL111990', 'AL121973', 'AL162003', 'AL052007', 'AL042013', 'AL071978', 'AL041945', 'AL071991', 'AL041865', 'AL132011', 'AL101996', 'AL061870', 'AL051865', 'AL042019', 'AL091984', 'AL151976', 'AL191887', 'AL112013', 'AL012015', 'AL011983', 'AL011932', 'AL081958', 'AL011937', 'AL141936', 'AL092012', 'AL052018', 'AL081979', 'AL101961', 'AL021923', 'AL011886', 'AL041913', 'AL011882', 'AL061964', 'AL051960', 'AL021906', 'AL061867', 'AL091952', 'AL011851', 'AL061936', 'AL051854', 'AL101951', 'AL111949', 'AL021887', 'AL041883', 'AL101998', 'AL111973', 'AL071958', 'AL061892', 'AL041856', 'AL011906', 'AL181887', 'AL112001', 'AL112005', 'AL091961', 'AL031876', 'AL061989', 'AL021862', 'AL111898', 'AL081935', 'AL011950', 'AL241967', 'AL171981', 'AL012016', 'AL022018', 'AL051918', 'AL051998', 'AL071953', 'AL031874', 'AL091891', 'AL011905', 'AL162022', 'AL051864', 'AL101931', 'AL161979', 'AL292020', 'AL041876', 'AL051907', 'AL152010', 'AL062017', 'AL021902', 'AL101937', 'AL041882', 'AL131988', 'AL101953', 'AL051966', 'AL091971', 'AL071989', 'AL061973', 'AL041870', 'AL091936', 'AL131987', 'AL171974', 'AL061969', 'AL021866', 'AL031854', 'AL071912', 'AL011959', 'AL021910', 'AL031954', 'AL132016', 'AL051862', 'AL121988', 'AL071935', 'AL081927', 'AL031980', 'AL101970', 'AL141973', 'AL072020', 'AL051921', 'AL031992', 'AL071886', 'AL031904', 'AL021933', 'AL031991', 'AL011861', 'AL011957', 'AL041920', 'AL191976', 'AL081989', 'AL102002', 'AL042005', 'AL121998', 'AL082000', 'AL262005', 'AL031860', 'AL021955', 'AL132017', 'AL121931', 'AL051990', 'AL122008', 'AL121953', 'AL102004', 'AL041947', 'AL081971', 'AL072021'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC2DpnqwTA58"
      },
      "source": [
        "## Load Data<a id=\"Load\"></a>\n",
        "\n",
        "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zKKXK1yXTA59"
      },
      "outputs": [],
      "source": [
        "# Get all available model errors\n",
        "models = errors.models.keys()\n",
        "# Load model errors into hurricanes\n",
        "for id in storm_ids :\n",
        "    for model in models :\n",
        "        # Skip if this hurricane does not have the model\n",
        "        if id not in errors.models[model].storm :\n",
        "            continue\n",
        "        hurricanes[id].add_model(model, errors.models[model].storm[id])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrYTJ_s8jhZY",
        "outputId": "9da4a999-39b6-4603-f0a8-89f400771c32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['OFCL', 'BCD5'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7baivH-TA6D"
      },
      "source": [
        "## Feature Engineering & Data Augmentation<a id=\"FeatureEngineering\"></a>\n",
        "\n",
        "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
        "\n",
        "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
        "\n",
        "1. Date Information\n",
        "2. Zonal Speed Of The Storm (U) (kt)\n",
        "3. Meridional Speed Of The Storm (V) (kt)\n",
        "4. 12-h Change In Intensity (DVMX) (kt)\n",
        "\n",
        "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsKxUTh7TA6E",
        "outputId": "46672332-ae51-40c2-93a4-b9baa2f26677",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-15-931273366cdf>:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if len(x) is 0 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineered 1944/1952 hurricanes for 5 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Scaling Data . . . (1 timestep for unqiue data)\n",
            "Feature engineered 1952/1952 hurricanes for 1 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Done scaling.\n"
          ]
        }
      ],
      "source": [
        "def feature_extraction(timestep, previous) :\n",
        "    '''\n",
        "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
        "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
        "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
        "            previous - previous timestep dictionary of features in the hurricane object format\n",
        "    OUTPUT: Dictionary of features\n",
        "    \n",
        "    timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'entry-time' : datetime\n",
        "    }\n",
        "    '''\n",
        "    features = {\n",
        "        'lat' : timestep['lat'],\n",
        "        'long' : timestep['long'],\n",
        "        'max_wind' : timestep['max_wind'],\n",
        "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'min_pressure' : timestep['min_pressure'], \n",
        "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'year' : timestep['entry_time'].year,\n",
        "        'month' : timestep['entry_time'].month,\n",
        "        'day' : timestep['entry_time'].day,\n",
        "        'hour' : timestep['entry_time'].hour,\n",
        "        'delta_pressure': (timestep['min_pressure'] - previous['min_pressure']) /\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200)\n",
        "    }\n",
        "    return features\n",
        "    \n",
        "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
        "    '''\n",
        "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
        "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
        "    INPUT:  storm - hurricane object\n",
        "            timesteps - (default = 1) number of timesteps to calculate\n",
        "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
        "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
        "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
        "    '''\n",
        "    x = []\n",
        "    # Create testing data structure with a dictionary\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    y = dict([(time,[]) for time in times])\n",
        "    \n",
        "    # Sort by entry time\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
        "    \n",
        "    for index in range(len(entries)) :\n",
        "        if index < timesteps : # Flag for insufficient initial time steps\n",
        "            continue\n",
        "\n",
        "        # If we're not including None values, check to see if there will be any\n",
        "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
        "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
        "            \n",
        "        # Calculate time steps and their features for independent values\n",
        "        sample = []\n",
        "        for step in range(timesteps) :\n",
        "            # Training sample\n",
        "            timestep = entries[index - step]\n",
        "            previous = entries[index - step - 1]\n",
        "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
        "        x.append(sample) # Add our constructed sample\n",
        "        \n",
        "        # Calculate time steps and their features for dependent values\n",
        "        for future in times :\n",
        "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
        "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
        "            \n",
        "            if timestep and previous: \n",
        "                y[future].append(feature_extraction(timestep, previous))\n",
        "            else :\n",
        "                y[future].append(None)\n",
        "    \n",
        "    # Return output, if there is no output, return None.\n",
        "    if len(x) is 0 :\n",
        "        return None\n",
        "    else:\n",
        "        return {'x': x, 'y': y}\n",
        "def shape(hurricanes, timesteps, remove_missing = True) :\n",
        "    '''\n",
        "    PURPOSE: Shape our data for input into machine learning models\n",
        "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            timesteps - number of timesteps for the shape\n",
        "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
        "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
        "    '''\n",
        "    x = []\n",
        "    y = []\n",
        "    lag = 24 # lag time in hours\n",
        "    precision = np.float64 # defines the precision of our data type\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    count = 0\n",
        "    for hurricane in hurricanes.values() :\n",
        "        count += 1\n",
        "        result = storm_x_y(hurricane, timesteps, lag)\n",
        "        if result is None :\n",
        "            continue\n",
        "        # Extract only the values from the strom features using our specified precision\n",
        "        hurricane_x = np.array(\n",
        "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
        "            dtype = precision)\n",
        "        hurricane_y = np.array(\n",
        "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
        "            dtype = precision)\n",
        "        # Disregard if algorithm requires no missing values\n",
        "        if remove_missing :\n",
        "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
        "                continue\n",
        "        # Add to our results\n",
        "        x.extend(hurricane_x)\n",
        "        y.extend(hurricane_y)\n",
        "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
        "    print(\"\\nDone feature engineering hurricanes.\")\n",
        "    \n",
        "    return {'x': np.array(x), 'y': np.array(y)}\n",
        "def scaler(processed_data, hurricanes) :\n",
        "    '''\n",
        "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
        "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
        "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
        "            2) RobustScaler object fit with appropriate data\n",
        "    '''\n",
        "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
        "    # Create our scaler\n",
        "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
        "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
        "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(x)\n",
        "    \n",
        "    # Scale our data\n",
        "    for index in range(len(processed_data['x'])) :\n",
        "        # Scale our x\n",
        "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
        "        # Scale our y\n",
        "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
        "    print(\"Done scaling.\")\n",
        "    return processed_data, scaler\n",
        "# Finalize and scale procesed data into a dictionary\n",
        "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
        "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdVSf0gio3Mm",
        "outputId": "1614a088-3f91-4cc0-f786-da61cdaa626b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[[ -0.45535714,  -0.22053232,   0.25      , ...,   0.13333333,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.5       ,  -0.29277567,   0.25      , ...,   0.13333333,\n",
              "           -1.        ,   0.        ],\n",
              "         [ -0.54464286,  -0.36121673,   0.        , ...,   0.06666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.58035714,  -0.42965779,   0.        , ...,   0.06666667,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.60714286,  -0.48669202,  -0.25      , ...,   0.06666667,\n",
              "           -0.5       ,   0.        ]],\n",
              " \n",
              "        [[ -0.41071429,  -0.14448669,   0.5       , ...,   0.13333333,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.45535714,  -0.22053232,   0.25      , ...,   0.13333333,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.5       ,  -0.29277567,   0.25      , ...,   0.13333333,\n",
              "           -1.        ,   0.        ],\n",
              "         [ -0.54464286,  -0.36121673,   0.        , ...,   0.06666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.58035714,  -0.42965779,   0.        , ...,   0.06666667,\n",
              "            0.        ,   0.        ]],\n",
              " \n",
              "        [[ -0.39285714,  -0.07224335,   0.5       , ...,   0.13333333,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.41071429,  -0.14448669,   0.5       , ...,   0.13333333,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.45535714,  -0.22053232,   0.25      , ...,   0.13333333,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.5       ,  -0.29277567,   0.25      , ...,   0.13333333,\n",
              "           -1.        ,   0.        ],\n",
              "         [ -0.54464286,  -0.36121673,   0.        , ...,   0.06666667,\n",
              "            0.5       ,   0.        ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ -0.41964286,   0.67680608,  -0.25      , ...,   0.66666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.49107143,   0.65019011,  -0.25      , ...,   0.66666667,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.52678571,   0.60836502,  -0.25      , ...,   0.66666667,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.52678571,   0.56653992,  -0.25      , ...,   0.66666667,\n",
              "           -1.        ,   0.        ],\n",
              "         [ -0.54464286,   0.51330798,  -0.25      , ...,   0.6       ,\n",
              "            0.5       ,   0.        ]],\n",
              " \n",
              "        [[ -0.33035714,   0.70722433,   0.        , ...,   0.73333333,\n",
              "           -1.        , -24.        ],\n",
              "         [ -0.41964286,   0.67680608,  -0.25      , ...,   0.66666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.49107143,   0.65019011,  -0.25      , ...,   0.66666667,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.52678571,   0.60836502,  -0.25      , ...,   0.66666667,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.52678571,   0.56653992,  -0.25      , ...,   0.66666667,\n",
              "           -1.        ,   0.        ]],\n",
              " \n",
              "        [[ -0.25      ,   0.73764259,   0.375     , ...,   0.73333333,\n",
              "           -0.5       , -12.        ],\n",
              "         [ -0.33035714,   0.70722433,   0.        , ...,   0.73333333,\n",
              "           -1.        , -24.        ],\n",
              "         [ -0.41964286,   0.67680608,  -0.25      , ...,   0.66666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.49107143,   0.65019011,  -0.25      , ...,   0.66666667,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.52678571,   0.60836502,  -0.25      , ...,   0.66666667,\n",
              "           -0.5       ,   0.        ]]]),\n",
              " 'y': array([[[ -0.32142857,   0.06844106,   0.75      , ...,   0.2       ,\n",
              "           -0.5       ,   0.        ],\n",
              "         [ -0.1875    ,   0.33460076,   0.5       , ...,   0.26666667,\n",
              "           -0.5       ,   0.        ],\n",
              "         [  0.        ,   0.58174905,   0.5       , ...,   0.33333333,\n",
              "           -0.5       ,   0.        ],\n",
              "         [  0.24107143,   0.76806084,   0.25      , ...,   0.4       ,\n",
              "           -0.5       ,   0.        ],\n",
              "         [  0.45535714,   0.88212928,   0.75      , ...,   0.46666667,\n",
              "           -0.5       ,   0.        ]],\n",
              " \n",
              "        [[ -0.29464286,   0.14068441,   1.        , ...,   0.2       ,\n",
              "            0.        ,   0.        ],\n",
              "         [ -0.14285714,   0.39163498,   0.25      , ...,   0.26666667,\n",
              "            0.        ,   0.        ],\n",
              "         [  0.0625    ,   0.63498099,   0.5       , ...,   0.33333333,\n",
              "            0.        ,   0.        ],\n",
              "         [  0.30357143,   0.80988593,   0.5       , ...,   0.4       ,\n",
              "            0.        ,   0.        ],\n",
              "         [  0.50892857,   0.90114068,   1.        , ...,   0.46666667,\n",
              "            0.        ,   0.        ]],\n",
              " \n",
              "        [[ -0.25892857,   0.20152091,   1.        , ...,   0.2       ,\n",
              "            0.5       ,   0.        ],\n",
              "         [ -0.09821429,   0.45627376,   0.25      , ...,   0.26666667,\n",
              "            0.5       ,   0.        ],\n",
              "         [  0.125     ,   0.68821293,   0.5       , ...,   0.33333333,\n",
              "            0.5       ,   0.        ],\n",
              "         [  0.34821429,   0.8365019 ,   0.5       , ...,   0.4       ,\n",
              "            0.5       ,   0.        ],\n",
              "         [  0.5625    ,   0.91254753,   1.        , ...,   0.46666667,\n",
              "            0.5       ,   0.        ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ -0.07142857,   0.78707224,   0.75      , ...,   0.73333333,\n",
              "            0.5       , -13.5       ],\n",
              "         [  0.26785714,   0.79847909,   1.375     , ...,   0.8       ,\n",
              "            0.5       , -12.5       ],\n",
              "         [  0.54464286,   0.76425856,   2.125     , ...,   0.86666667,\n",
              "            0.5       ,  -6.5       ],\n",
              "         [  0.75      ,   0.67680608,   0.375     , ...,   0.93333333,\n",
              "            0.5       ,  24.        ],\n",
              "         [  1.14285714,   0.64258555,   0.5       , ...,   1.        ,\n",
              "            0.5       ,  -4.        ]],\n",
              " \n",
              "        [[  0.02678571,   0.79847909,   0.875     , ...,   0.8       ,\n",
              "           -1.        , -13.        ],\n",
              "         [  0.34821429,   0.78707224,   1.375     , ...,   0.86666667,\n",
              "           -1.        ,  -9.        ],\n",
              "         [  0.59821429,   0.73764259,   1.25      , ...,   0.93333333,\n",
              "           -1.        ,   6.5       ],\n",
              "         [  0.8125    ,   0.65019011,   0.5       , ...,   1.        ,\n",
              "           -1.        ,  13.        ],\n",
              "         [  1.24107143,   0.64638783,   0.        , ...,  -0.93333333,\n",
              "           -1.        ,   2.        ]],\n",
              " \n",
              "        [[  0.11607143,   0.80988593,   1.25      , ...,   0.8       ,\n",
              "           -0.5       , -14.5       ],\n",
              "         [  0.41964286,   0.78326996,   1.75      , ...,   0.86666667,\n",
              "           -0.5       ,  -5.5       ],\n",
              "         [  0.64285714,   0.7148289 ,   0.375     , ...,   0.93333333,\n",
              "           -0.5       ,  20.        ],\n",
              "         [  0.875     ,   0.63878327,   0.625     , ...,   1.        ,\n",
              "           -0.5       ,  -0.5       ],\n",
              "         [  1.32142857,   0.66159696,  -0.5       , ...,  -0.93333333,\n",
              "           -0.5       ,   7.5       ]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk1fyYBXTA6G"
      },
      "source": [
        "## Model Architecture<a id=\"ModelArchitecture\"></a>\n",
        "\n",
        "Following feature engineering, we are now ready to input our data into a machine learning algorithm. The scope of this project will attempt a deep learning approach to forecasting Atlantic tropical cyclones. We will experiment with nunermous different architectures but we will focus around a Recurrent Neural Network utilizing LSTM cells.\n",
        "\n",
        "Notes:\n",
        "- We will use 500 epochs for wind intensity because the validation loss is not decresing\n",
        "- We will use 1,000 epochs for latitute and longitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0ETjdPZJTA6H",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_IiSRrWcYNqO"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import RepeatVector\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Create our cross validation data structure\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(processed_data['x'], processed_data['y'],\n",
        "                                                                    test_size = 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQA_-scrYNqO",
        "outputId": "26e1518d-ca1b-4128-eec1-9a1c3b0bd47e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.2608 - val_loss: 1.2374\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.2603 - val_loss: 1.2368\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 1.2594 - val_loss: 1.2361\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.2586 - val_loss: 1.2355\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.2582 - val_loss: 1.2349\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.2579 - val_loss: 1.2343\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2572 - val_loss: 1.2337\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.2561 - val_loss: 1.2331\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 1.2550 - val_loss: 1.2325\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 1.2552 - val_loss: 1.2319\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.2542 - val_loss: 1.2312\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.2535 - val_loss: 1.2306\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 1.2531 - val_loss: 1.2300\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.2518 - val_loss: 1.2294\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.2515 - val_loss: 1.2288\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 1.2506 - val_loss: 1.2282\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2506 - val_loss: 1.2276\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.2494 - val_loss: 1.2270\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.2494 - val_loss: 1.2264\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.2484 - val_loss: 1.2257\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 1.2477 - val_loss: 1.2251\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.2475 - val_loss: 1.2245\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 1.2467 - val_loss: 1.2239\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 1.2453 - val_loss: 1.2233\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.2447 - val_loss: 1.2227\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2443 - val_loss: 1.2221\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.2436 - val_loss: 1.2215\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.2431 - val_loss: 1.2209\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.2429 - val_loss: 1.2203\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.2417 - val_loss: 1.2197\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.2413 - val_loss: 1.2190\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 1.2405 - val_loss: 1.2184\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 1.2399 - val_loss: 1.2178\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 1.2386 - val_loss: 1.2172\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.2382 - val_loss: 1.2166\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 1.2378 - val_loss: 1.2160\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 1.2373 - val_loss: 1.2154\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 1.2371 - val_loss: 1.2148\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 1.2358 - val_loss: 1.2142\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 1.2363 - val_loss: 1.2136\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 1.2352 - val_loss: 1.2130\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 1.2349 - val_loss: 1.2124\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.2333 - val_loss: 1.2118\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.2334 - val_loss: 1.2112\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.2324 - val_loss: 1.2106\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.2319 - val_loss: 1.2100\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2309 - val_loss: 1.2094\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 1.2308 - val_loss: 1.2088\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.2301 - val_loss: 1.2082\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.2289 - val_loss: 1.2076\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.2288 - val_loss: 1.2070\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.2279 - val_loss: 1.2064\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.2266 - val_loss: 1.2058\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.2263 - val_loss: 1.2052\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2262 - val_loss: 1.2046\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2255 - val_loss: 1.2040\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2238 - val_loss: 1.2034\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.2244 - val_loss: 1.2028\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.2237 - val_loss: 1.2022\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.2221 - val_loss: 1.2016\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.2220 - val_loss: 1.2010\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.2211 - val_loss: 1.2004\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 1.2206 - val_loss: 1.1998\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.2196 - val_loss: 1.1992\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 1.2198 - val_loss: 1.1986\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.2185 - val_loss: 1.1980\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 1.2181 - val_loss: 1.1974\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 1.2179 - val_loss: 1.1968\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.2173 - val_loss: 1.1962\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 1.2171 - val_loss: 1.1956\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.2154 - val_loss: 1.1950\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.2149 - val_loss: 1.1944\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2145 - val_loss: 1.1938\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.2144 - val_loss: 1.1933\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.2139 - val_loss: 1.1927\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.2127 - val_loss: 1.1921\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.2117 - val_loss: 1.1915\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.2118 - val_loss: 1.1909\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.2110 - val_loss: 1.1903\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.2102 - val_loss: 1.1897\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.2092 - val_loss: 1.1891\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 1.2091 - val_loss: 1.1885\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.2087 - val_loss: 1.1879\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.2077 - val_loss: 1.1874\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2073 - val_loss: 1.1868\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.2064 - val_loss: 1.1862\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.2058 - val_loss: 1.1856\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.2049 - val_loss: 1.1850\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2043 - val_loss: 1.1844\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.2043 - val_loss: 1.1838\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.2038 - val_loss: 1.1832\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.2018 - val_loss: 1.1827\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.2015 - val_loss: 1.1821\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.2014 - val_loss: 1.1815\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.2004 - val_loss: 1.1809\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.2003 - val_loss: 1.1803\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 1.1991 - val_loss: 1.1797\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 1.1989 - val_loss: 1.1791\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1987 - val_loss: 1.1786\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1979 - val_loss: 1.1780\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1964 - val_loss: 1.1774\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 1.1963 - val_loss: 1.1768\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1958 - val_loss: 1.1762\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1952 - val_loss: 1.1756\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1944 - val_loss: 1.1751\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1934 - val_loss: 1.1745\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1936 - val_loss: 1.1739\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1928 - val_loss: 1.1733\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1926 - val_loss: 1.1727\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1913 - val_loss: 1.1722\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1907 - val_loss: 1.1716\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1897 - val_loss: 1.1710\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1897 - val_loss: 1.1704\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1893 - val_loss: 1.1698\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.1883 - val_loss: 1.1693\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1882 - val_loss: 1.1687\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1868 - val_loss: 1.1681\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1862 - val_loss: 1.1675\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1862 - val_loss: 1.1670\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1852 - val_loss: 1.1664\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1849 - val_loss: 1.1658\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1843 - val_loss: 1.1652\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1835 - val_loss: 1.1647\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.1827 - val_loss: 1.1641\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.1835 - val_loss: 1.1635\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1819 - val_loss: 1.1629\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1807 - val_loss: 1.1624\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 1.1807 - val_loss: 1.1618\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1808 - val_loss: 1.1612\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.1795 - val_loss: 1.1606\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.1786 - val_loss: 1.1601\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1777 - val_loss: 1.1595\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 1.1772 - val_loss: 1.1589\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1769 - val_loss: 1.1583\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1769 - val_loss: 1.1578\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1758 - val_loss: 1.1572\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1749 - val_loss: 1.1566\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1744 - val_loss: 1.1561\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 1.1737 - val_loss: 1.1555\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1736 - val_loss: 1.1549\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.1729 - val_loss: 1.1544\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 1.1721 - val_loss: 1.1538\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1717 - val_loss: 1.1532\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1715 - val_loss: 1.1527\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1705 - val_loss: 1.1521\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 1.1709 - val_loss: 1.1515\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1688 - val_loss: 1.1510\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1684 - val_loss: 1.1504\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1679 - val_loss: 1.1498\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 1.1664 - val_loss: 1.1493\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1670 - val_loss: 1.1487\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 1.1665 - val_loss: 1.1481\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1662 - val_loss: 1.1476\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1648 - val_loss: 1.1470\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1648 - val_loss: 1.1464\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1634 - val_loss: 1.1459\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1627 - val_loss: 1.1453\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1626 - val_loss: 1.1447\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 1.1616 - val_loss: 1.1442\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.1614 - val_loss: 1.1436\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1606 - val_loss: 1.1430\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.1601 - val_loss: 1.1425\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1590 - val_loss: 1.1419\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1582 - val_loss: 1.1414\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1585 - val_loss: 1.1408\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1578 - val_loss: 1.1402\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1571 - val_loss: 1.1397\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1563 - val_loss: 1.1391\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1568 - val_loss: 1.1386\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1554 - val_loss: 1.1380\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 1.1545 - val_loss: 1.1374\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1539 - val_loss: 1.1369\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1539 - val_loss: 1.1363\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1539 - val_loss: 1.1358\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1527 - val_loss: 1.1352\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1516 - val_loss: 1.1346\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1520 - val_loss: 1.1341\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1507 - val_loss: 1.1335\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.1504 - val_loss: 1.1330\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1494 - val_loss: 1.1324\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 1.1485 - val_loss: 1.1319\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1478 - val_loss: 1.1313\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.1474 - val_loss: 1.1307\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.1474 - val_loss: 1.1302\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 1.1456 - val_loss: 1.1296\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 1.1466 - val_loss: 1.1291\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.1451 - val_loss: 1.1285\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.1455 - val_loss: 1.1280\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1445 - val_loss: 1.1274\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 1.1436 - val_loss: 1.1269\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1429 - val_loss: 1.1263\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1425 - val_loss: 1.1258\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 1.1419 - val_loss: 1.1252\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1411 - val_loss: 1.1247\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1407 - val_loss: 1.1241\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 1.1404 - val_loss: 1.1236\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 1.1393 - val_loss: 1.1230\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.1386 - val_loss: 1.1225\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1384 - val_loss: 1.1219\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1380 - val_loss: 1.1214\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1365 - val_loss: 1.1208\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1371 - val_loss: 1.1203\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1362 - val_loss: 1.1197\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 1.1357 - val_loss: 1.1192\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1345 - val_loss: 1.1186\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1343 - val_loss: 1.1181\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.1338 - val_loss: 1.1175\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1331 - val_loss: 1.1170\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1319 - val_loss: 1.1164\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1320 - val_loss: 1.1159\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.1316 - val_loss: 1.1153\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1303 - val_loss: 1.1148\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1306 - val_loss: 1.1142\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.1299 - val_loss: 1.1137\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.1296 - val_loss: 1.1131\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1297 - val_loss: 1.1126\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.1272 - val_loss: 1.1121\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 1.1277 - val_loss: 1.1115\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1272 - val_loss: 1.1110\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.1265 - val_loss: 1.1104\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.1264 - val_loss: 1.1099\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1252 - val_loss: 1.1093\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.1249 - val_loss: 1.1088\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1242 - val_loss: 1.1083\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1236 - val_loss: 1.1077\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1218 - val_loss: 1.1072\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1216 - val_loss: 1.1066\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1220 - val_loss: 1.1061\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1205 - val_loss: 1.1055\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1206 - val_loss: 1.1050\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1188 - val_loss: 1.1045\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.1191 - val_loss: 1.1039\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1184 - val_loss: 1.1034\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1184 - val_loss: 1.1028\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1185 - val_loss: 1.1023\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1171 - val_loss: 1.1018\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1169 - val_loss: 1.1012\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.1169 - val_loss: 1.1007\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1156 - val_loss: 1.1002\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1149 - val_loss: 1.0996\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.1144 - val_loss: 1.0991\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.1134 - val_loss: 1.0985\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1137 - val_loss: 1.0980\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1125 - val_loss: 1.0975\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.1117 - val_loss: 1.0969\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.1113 - val_loss: 1.0964\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 1.1108 - val_loss: 1.0959\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 1.1102 - val_loss: 1.0953\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.1098 - val_loss: 1.0948\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.1085 - val_loss: 1.0943\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.1096 - val_loss: 1.0937\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.1084 - val_loss: 1.0932\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 1.1070 - val_loss: 1.0927\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1073 - val_loss: 1.0921\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.1057 - val_loss: 1.0916\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.1052 - val_loss: 1.0911\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.1053 - val_loss: 1.0905\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1042 - val_loss: 1.0900\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.1040 - val_loss: 1.0895\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.1036 - val_loss: 1.0889\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.1032 - val_loss: 1.0884\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.1021 - val_loss: 1.0879\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1023 - val_loss: 1.0873\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.1014 - val_loss: 1.0868\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.1011 - val_loss: 1.0863\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.1003 - val_loss: 1.0858\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0999 - val_loss: 1.0852\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0991 - val_loss: 1.0847\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0984 - val_loss: 1.0842\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0978 - val_loss: 1.0836\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0974 - val_loss: 1.0831\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0965 - val_loss: 1.0826\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0961 - val_loss: 1.0821\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0964 - val_loss: 1.0815\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.0952 - val_loss: 1.0810\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 1.0955 - val_loss: 1.0805\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 1.0947 - val_loss: 1.0799\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.0941 - val_loss: 1.0794\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0935 - val_loss: 1.0789\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 1.0923 - val_loss: 1.0784\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0917 - val_loss: 1.0778\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0912 - val_loss: 1.0773\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0907 - val_loss: 1.0768\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0903 - val_loss: 1.0763\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.0904 - val_loss: 1.0757\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0895 - val_loss: 1.0752\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 1.0884 - val_loss: 1.0747\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0881 - val_loss: 1.0742\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0869 - val_loss: 1.0737\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0858 - val_loss: 1.0731\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0861 - val_loss: 1.0726\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0855 - val_loss: 1.0721\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0856 - val_loss: 1.0716\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0853 - val_loss: 1.0710\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0836 - val_loss: 1.0705\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0831 - val_loss: 1.0700\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0832 - val_loss: 1.0695\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.0830 - val_loss: 1.0690\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0817 - val_loss: 1.0684\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0811 - val_loss: 1.0679\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0807 - val_loss: 1.0674\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0805 - val_loss: 1.0669\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0790 - val_loss: 1.0664\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0788 - val_loss: 1.0658\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 1.0783 - val_loss: 1.0653\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0777 - val_loss: 1.0648\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 1.0773 - val_loss: 1.0643\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 1.0764 - val_loss: 1.0638\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.0763 - val_loss: 1.0633\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 1.0761 - val_loss: 1.0627\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0751 - val_loss: 1.0622\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0751 - val_loss: 1.0617\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0745 - val_loss: 1.0612\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0734 - val_loss: 1.0607\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0737 - val_loss: 1.0602\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0723 - val_loss: 1.0596\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.0723 - val_loss: 1.0591\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0710 - val_loss: 1.0586\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0711 - val_loss: 1.0581\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 1.0703 - val_loss: 1.0576\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0701 - val_loss: 1.0571\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0691 - val_loss: 1.0566\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0688 - val_loss: 1.0560\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0686 - val_loss: 1.0555\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0676 - val_loss: 1.0550\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0672 - val_loss: 1.0545\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0669 - val_loss: 1.0540\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0660 - val_loss: 1.0535\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0653 - val_loss: 1.0530\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 1.0659 - val_loss: 1.0525\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0646 - val_loss: 1.0519\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0640 - val_loss: 1.0514\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0642 - val_loss: 1.0509\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0626 - val_loss: 1.0504\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 1.0631 - val_loss: 1.0499\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.0617 - val_loss: 1.0494\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.0613 - val_loss: 1.0489\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 1.0609 - val_loss: 1.0484\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 1.0603 - val_loss: 1.0479\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 1.0596 - val_loss: 1.0474\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 1.0589 - val_loss: 1.0469\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0584 - val_loss: 1.0463\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0573 - val_loss: 1.0458\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0571 - val_loss: 1.0453\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0566 - val_loss: 1.0448\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0564 - val_loss: 1.0443\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0566 - val_loss: 1.0438\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0555 - val_loss: 1.0433\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0550 - val_loss: 1.0428\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0546 - val_loss: 1.0423\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0537 - val_loss: 1.0418\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0534 - val_loss: 1.0413\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0527 - val_loss: 1.0408\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0511 - val_loss: 1.0403\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0514 - val_loss: 1.0398\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0516 - val_loss: 1.0393\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0505 - val_loss: 1.0388\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 1.0499 - val_loss: 1.0383\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0485 - val_loss: 1.0377\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0489 - val_loss: 1.0372\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0479 - val_loss: 1.0367\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0482 - val_loss: 1.0362\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0474 - val_loss: 1.0357\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0469 - val_loss: 1.0352\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0458 - val_loss: 1.0347\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0457 - val_loss: 1.0342\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0451 - val_loss: 1.0337\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 1.0437 - val_loss: 1.0332\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0436 - val_loss: 1.0327\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0438 - val_loss: 1.0322\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 1.0432 - val_loss: 1.0317\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.0428 - val_loss: 1.0312\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0414 - val_loss: 1.0307\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0418 - val_loss: 1.0302\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0405 - val_loss: 1.0297\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0403 - val_loss: 1.0292\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0398 - val_loss: 1.0287\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0394 - val_loss: 1.0282\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0392 - val_loss: 1.0277\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0378 - val_loss: 1.0272\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0380 - val_loss: 1.0267\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0376 - val_loss: 1.0262\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 1.0369 - val_loss: 1.0257\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0360 - val_loss: 1.0252\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.0359 - val_loss: 1.0248\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.0353 - val_loss: 1.0243\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0340 - val_loss: 1.0238\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0351 - val_loss: 1.0233\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0333 - val_loss: 1.0228\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.0324 - val_loss: 1.0223\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0325 - val_loss: 1.0218\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0318 - val_loss: 1.0213\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0315 - val_loss: 1.0208\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.0317 - val_loss: 1.0203\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.0312 - val_loss: 1.0198\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0304 - val_loss: 1.0193\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0294 - val_loss: 1.0188\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 1.0297 - val_loss: 1.0183\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0280 - val_loss: 1.0178\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0283 - val_loss: 1.0173\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 1.0275 - val_loss: 1.0168\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 1.0271 - val_loss: 1.0163\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0262 - val_loss: 1.0159\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0255 - val_loss: 1.0154\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0252 - val_loss: 1.0149\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0246 - val_loss: 1.0144\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0245 - val_loss: 1.0139\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 1.0227 - val_loss: 1.0134\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0240 - val_loss: 1.0129\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0221 - val_loss: 1.0124\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0230 - val_loss: 1.0119\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0215 - val_loss: 1.0114\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0212 - val_loss: 1.0109\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0206 - val_loss: 1.0105\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0194 - val_loss: 1.0100\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 1.0191 - val_loss: 1.0095\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0187 - val_loss: 1.0090\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0193 - val_loss: 1.0085\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0180 - val_loss: 1.0080\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.0182 - val_loss: 1.0075\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0168 - val_loss: 1.0070\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.0157 - val_loss: 1.0066\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 1.0155 - val_loss: 1.0061\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0150 - val_loss: 1.0056\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0150 - val_loss: 1.0051\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 1.0146 - val_loss: 1.0046\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 1.0136 - val_loss: 1.0041\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.0138 - val_loss: 1.0036\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0124 - val_loss: 1.0032\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.0115 - val_loss: 1.0027\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0124 - val_loss: 1.0022\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0111 - val_loss: 1.0017\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.0110 - val_loss: 1.0012\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0101 - val_loss: 1.0007\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.0100 - val_loss: 1.0002\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0097 - val_loss: 0.9998\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0091 - val_loss: 0.9993\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.0087 - val_loss: 0.9988\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0089 - val_loss: 0.9983\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0079 - val_loss: 0.9978\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0058 - val_loss: 0.9973\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0065 - val_loss: 0.9969\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.0061 - val_loss: 0.9964\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0058 - val_loss: 0.9959\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.0052 - val_loss: 0.9954\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0043 - val_loss: 0.9949\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.0047 - val_loss: 0.9945\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0037 - val_loss: 0.9940\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.0025 - val_loss: 0.9935\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0029 - val_loss: 0.9930\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0015 - val_loss: 0.9925\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 1.0017 - val_loss: 0.9921\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0024 - val_loss: 0.9916\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 1.0004 - val_loss: 0.9911\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9996 - val_loss: 0.9906\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.9997 - val_loss: 0.9901\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9983 - val_loss: 0.9897\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.9986 - val_loss: 0.9892\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9983 - val_loss: 0.9887\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9966 - val_loss: 0.9882\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9973 - val_loss: 0.9878\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9960 - val_loss: 0.9873\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9958 - val_loss: 0.9868\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9954 - val_loss: 0.9863\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9947 - val_loss: 0.9858\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9940 - val_loss: 0.9854\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9926 - val_loss: 0.9849\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9929 - val_loss: 0.9844\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9936 - val_loss: 0.9839\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9925 - val_loss: 0.9835\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9915 - val_loss: 0.9830\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9901 - val_loss: 0.9825\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9906 - val_loss: 0.9820\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9905 - val_loss: 0.9816\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9902 - val_loss: 0.9811\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.9896 - val_loss: 0.9806\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9886 - val_loss: 0.9801\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9882 - val_loss: 0.9797\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9874 - val_loss: 0.9792\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9877 - val_loss: 0.9787\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9862 - val_loss: 0.9782\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9871 - val_loss: 0.9778\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9856 - val_loss: 0.9773\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9853 - val_loss: 0.9768\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9852 - val_loss: 0.9764\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.9848 - val_loss: 0.9759\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.9844 - val_loss: 0.9754\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9846 - val_loss: 0.9749\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9833 - val_loss: 0.9745\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9824 - val_loss: 0.9740\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9817 - val_loss: 0.9735\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.9816 - val_loss: 0.9731\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9813 - val_loss: 0.9726\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9806 - val_loss: 0.9721\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9798 - val_loss: 0.9717\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9805 - val_loss: 0.9712\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9790 - val_loss: 0.9707\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9788 - val_loss: 0.9702\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9785 - val_loss: 0.9698\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9778 - val_loss: 0.9693\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9770 - val_loss: 0.9688\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9763 - val_loss: 0.9684\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9765 - val_loss: 0.9679\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9756 - val_loss: 0.9674\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9751 - val_loss: 0.9670\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9736 - val_loss: 0.9665\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9742 - val_loss: 0.9660\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9734 - val_loss: 0.9656\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9734 - val_loss: 0.9651\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.9727 - val_loss: 0.9646\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9718 - val_loss: 0.9642\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9717 - val_loss: 0.9637\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9714 - val_loss: 0.9632\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9705 - val_loss: 0.9628\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9696 - val_loss: 0.9623\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9690 - val_loss: 0.9618\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.9696 - val_loss: 0.9614\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.9691 - val_loss: 0.9609\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9677 - val_loss: 0.9605\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.9675 - val_loss: 0.9600\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9677 - val_loss: 0.9595\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.9662 - val_loss: 0.9591\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9669 - val_loss: 0.9586\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9650 - val_loss: 0.9581\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9651 - val_loss: 0.9577\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9646 - val_loss: 0.9572\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9637 - val_loss: 0.9568\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9641 - val_loss: 0.9563\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9633 - val_loss: 0.9558\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9633 - val_loss: 0.9554\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9626 - val_loss: 0.9549\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9620 - val_loss: 0.9544\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9603 - val_loss: 0.9540\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9609 - val_loss: 0.9535\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9608 - val_loss: 0.9531\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9606 - val_loss: 0.9526\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9585 - val_loss: 0.9521\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9589 - val_loss: 0.9517\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9579 - val_loss: 0.9512\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9577 - val_loss: 0.9508\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9582 - val_loss: 0.9503\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9561 - val_loss: 0.9498\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9566 - val_loss: 0.9494\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9563 - val_loss: 0.9489\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9566 - val_loss: 0.9485\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9555 - val_loss: 0.9480\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9544 - val_loss: 0.9476\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9544 - val_loss: 0.9471\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9534 - val_loss: 0.9466\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9539 - val_loss: 0.9462\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.9531 - val_loss: 0.9457\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9516 - val_loss: 0.9453\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.9516 - val_loss: 0.9448\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9512 - val_loss: 0.9444\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9505 - val_loss: 0.9439\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9502 - val_loss: 0.9434\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9497 - val_loss: 0.9430\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9496 - val_loss: 0.9425\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.9485 - val_loss: 0.9421\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9488 - val_loss: 0.9416\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9485 - val_loss: 0.9412\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9472 - val_loss: 0.9407\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9474 - val_loss: 0.9403\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9466 - val_loss: 0.9398\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9465 - val_loss: 0.9393\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9460 - val_loss: 0.9389\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.9458 - val_loss: 0.9384\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9453 - val_loss: 0.9380\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9442 - val_loss: 0.9375\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9434 - val_loss: 0.9371\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9438 - val_loss: 0.9366\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9423 - val_loss: 0.9362\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9417 - val_loss: 0.9357\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9414 - val_loss: 0.9353\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9412 - val_loss: 0.9348\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9402 - val_loss: 0.9344\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9404 - val_loss: 0.9339\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9406 - val_loss: 0.9335\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9390 - val_loss: 0.9330\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9385 - val_loss: 0.9326\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9388 - val_loss: 0.9321\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9370 - val_loss: 0.9317\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9373 - val_loss: 0.9312\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9368 - val_loss: 0.9308\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.9359 - val_loss: 0.9303\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9362 - val_loss: 0.9299\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.9347 - val_loss: 0.9294\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9354 - val_loss: 0.9290\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9346 - val_loss: 0.9285\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9343 - val_loss: 0.9281\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9336 - val_loss: 0.9276\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9333 - val_loss: 0.9272\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9331 - val_loss: 0.9267\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.9327 - val_loss: 0.9263\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9321 - val_loss: 0.9258\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9311 - val_loss: 0.9254\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.9310 - val_loss: 0.9249\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9303 - val_loss: 0.9245\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9303 - val_loss: 0.9240\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9290 - val_loss: 0.9236\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9295 - val_loss: 0.9231\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9286 - val_loss: 0.9227\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9272 - val_loss: 0.9222\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9276 - val_loss: 0.9218\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9267 - val_loss: 0.9214\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9276 - val_loss: 0.9209\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9259 - val_loss: 0.9205\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.9261 - val_loss: 0.9200\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9254 - val_loss: 0.9196\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9254 - val_loss: 0.9191\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.9240 - val_loss: 0.9187\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9234 - val_loss: 0.9182\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9239 - val_loss: 0.9178\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9225 - val_loss: 0.9173\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9233 - val_loss: 0.9169\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.9222 - val_loss: 0.9165\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.9213 - val_loss: 0.9160\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9206 - val_loss: 0.9156\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9205 - val_loss: 0.9151\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.9207 - val_loss: 0.9147\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9199 - val_loss: 0.9142\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.9197 - val_loss: 0.9138\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.9179 - val_loss: 0.9134\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9187 - val_loss: 0.9129\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9177 - val_loss: 0.9125\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9167 - val_loss: 0.9120\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9170 - val_loss: 0.9116\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9160 - val_loss: 0.9112\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9157 - val_loss: 0.9107\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9150 - val_loss: 0.9103\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9149 - val_loss: 0.9098\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9142 - val_loss: 0.9094\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9137 - val_loss: 0.9090\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9139 - val_loss: 0.9085\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9135 - val_loss: 0.9081\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9132 - val_loss: 0.9076\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9118 - val_loss: 0.9072\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.9112 - val_loss: 0.9068\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9109 - val_loss: 0.9063\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.9110 - val_loss: 0.9059\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9107 - val_loss: 0.9054\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9093 - val_loss: 0.9050\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9095 - val_loss: 0.9046\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9091 - val_loss: 0.9041\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.9078 - val_loss: 0.9037\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.9079 - val_loss: 0.9032\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9079 - val_loss: 0.9028\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9075 - val_loss: 0.9024\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9069 - val_loss: 0.9019\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9064 - val_loss: 0.9015\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9063 - val_loss: 0.9011\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9052 - val_loss: 0.9006\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9045 - val_loss: 0.9002\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9046 - val_loss: 0.8997\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9039 - val_loss: 0.8993\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9028 - val_loss: 0.8989\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9029 - val_loss: 0.8984\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9018 - val_loss: 0.8980\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9017 - val_loss: 0.8976\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9013 - val_loss: 0.8971\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9013 - val_loss: 0.8967\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9011 - val_loss: 0.8963\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9000 - val_loss: 0.8958\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8991 - val_loss: 0.8954\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8998 - val_loss: 0.8950\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8984 - val_loss: 0.8945\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.8997 - val_loss: 0.8941\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8977 - val_loss: 0.8937\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.8971 - val_loss: 0.8932\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.8965 - val_loss: 0.8928\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8968 - val_loss: 0.8924\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.8963 - val_loss: 0.8919\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8961 - val_loss: 0.8915\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8963 - val_loss: 0.8911\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.8953 - val_loss: 0.8906\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8948 - val_loss: 0.8902\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8942 - val_loss: 0.8898\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8943 - val_loss: 0.8893\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8925 - val_loss: 0.8889\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8925 - val_loss: 0.8885\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8924 - val_loss: 0.8880\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.8921 - val_loss: 0.8876\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.8908 - val_loss: 0.8872\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.8907 - val_loss: 0.8868\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8910 - val_loss: 0.8863\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8896 - val_loss: 0.8859\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8894 - val_loss: 0.8855\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.8900 - val_loss: 0.8850\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8889 - val_loss: 0.8846\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8891 - val_loss: 0.8842\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8876 - val_loss: 0.8837\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8878 - val_loss: 0.8833\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8875 - val_loss: 0.8829\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8862 - val_loss: 0.8825\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8863 - val_loss: 0.8820\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.8854 - val_loss: 0.8816\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8853 - val_loss: 0.8812\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8842 - val_loss: 0.8807\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.8853 - val_loss: 0.8803\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8836 - val_loss: 0.8799\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8839 - val_loss: 0.8795\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.8827 - val_loss: 0.8790\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8814 - val_loss: 0.8786\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8812 - val_loss: 0.8782\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8804 - val_loss: 0.8778\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8804 - val_loss: 0.8773\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8803 - val_loss: 0.8769\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8801 - val_loss: 0.8765\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8797 - val_loss: 0.8761\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8800 - val_loss: 0.8756\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8781 - val_loss: 0.8752\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8782 - val_loss: 0.8748\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8775 - val_loss: 0.8743\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8778 - val_loss: 0.8739\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.8766 - val_loss: 0.8735\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.8770 - val_loss: 0.8731\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8759 - val_loss: 0.8727\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8750 - val_loss: 0.8722\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8763 - val_loss: 0.8718\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8749 - val_loss: 0.8714\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8753 - val_loss: 0.8710\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8751 - val_loss: 0.8705\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8741 - val_loss: 0.8701\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8731 - val_loss: 0.8697\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.8731 - val_loss: 0.8693\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.8725 - val_loss: 0.8688\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.8715 - val_loss: 0.8684\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.8705 - val_loss: 0.8680\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8708 - val_loss: 0.8676\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8698 - val_loss: 0.8672\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8698 - val_loss: 0.8667\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8697 - val_loss: 0.8663\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8681 - val_loss: 0.8659\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8690 - val_loss: 0.8655\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.8684 - val_loss: 0.8650\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8666 - val_loss: 0.8646\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8675 - val_loss: 0.8642\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8663 - val_loss: 0.8638\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.8664 - val_loss: 0.8634\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8662 - val_loss: 0.8629\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8641 - val_loss: 0.8625\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8662 - val_loss: 0.8621\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8650 - val_loss: 0.8617\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8641 - val_loss: 0.8613\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8629 - val_loss: 0.8608\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8638 - val_loss: 0.8604\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8625 - val_loss: 0.8600\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8622 - val_loss: 0.8596\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.8613 - val_loss: 0.8592\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8626 - val_loss: 0.8587\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8618 - val_loss: 0.8583\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8610 - val_loss: 0.8579\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8604 - val_loss: 0.8575\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8590 - val_loss: 0.8571\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8591 - val_loss: 0.8567\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8586 - val_loss: 0.8562\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8588 - val_loss: 0.8558\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8578 - val_loss: 0.8554\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8571 - val_loss: 0.8550\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.8576 - val_loss: 0.8546\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.8577 - val_loss: 0.8542\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.8567 - val_loss: 0.8537\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8562 - val_loss: 0.8533\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8553 - val_loss: 0.8529\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.8552 - val_loss: 0.8525\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8545 - val_loss: 0.8521\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8542 - val_loss: 0.8517\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8536 - val_loss: 0.8512\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.8534 - val_loss: 0.8508\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8523 - val_loss: 0.8504\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8523 - val_loss: 0.8500\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8528 - val_loss: 0.8496\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8516 - val_loss: 0.8492\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8517 - val_loss: 0.8488\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8518 - val_loss: 0.8483\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8496 - val_loss: 0.8479\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8503 - val_loss: 0.8475\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8493 - val_loss: 0.8471\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.8487 - val_loss: 0.8467\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8483 - val_loss: 0.8463\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8489 - val_loss: 0.8459\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8475 - val_loss: 0.8454\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8477 - val_loss: 0.8450\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8470 - val_loss: 0.8446\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8463 - val_loss: 0.8442\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8453 - val_loss: 0.8438\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8460 - val_loss: 0.8434\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.8458 - val_loss: 0.8430\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.8453 - val_loss: 0.8426\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.8455 - val_loss: 0.8421\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8434 - val_loss: 0.8417\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8433 - val_loss: 0.8413\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8426 - val_loss: 0.8409\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8426 - val_loss: 0.8405\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.8424 - val_loss: 0.8401\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8410 - val_loss: 0.8397\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.8414 - val_loss: 0.8393\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8400 - val_loss: 0.8389\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8411 - val_loss: 0.8385\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8411 - val_loss: 0.8380\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8395 - val_loss: 0.8376\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8395 - val_loss: 0.8372\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8389 - val_loss: 0.8368\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8380 - val_loss: 0.8364\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8369 - val_loss: 0.8360\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8378 - val_loss: 0.8356\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8382 - val_loss: 0.8352\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8363 - val_loss: 0.8348\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.8356 - val_loss: 0.8344\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8359 - val_loss: 0.8340\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8353 - val_loss: 0.8335\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8356 - val_loss: 0.8331\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8346 - val_loss: 0.8327\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8336 - val_loss: 0.8323\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8328 - val_loss: 0.8319\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8328 - val_loss: 0.8315\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8326 - val_loss: 0.8311\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8333 - val_loss: 0.8307\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8323 - val_loss: 0.8303\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8307 - val_loss: 0.8299\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.8309 - val_loss: 0.8295\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.8298 - val_loss: 0.8291\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.8304 - val_loss: 0.8287\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8294 - val_loss: 0.8282\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8285 - val_loss: 0.8278\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.8289 - val_loss: 0.8274\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8288 - val_loss: 0.8270\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.8278 - val_loss: 0.8266\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8264 - val_loss: 0.8262\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8270 - val_loss: 0.8258\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8279 - val_loss: 0.8254\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8262 - val_loss: 0.8250\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8260 - val_loss: 0.8246\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8259 - val_loss: 0.8242\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.8250 - val_loss: 0.8238\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8253 - val_loss: 0.8234\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8248 - val_loss: 0.8230\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8250 - val_loss: 0.8226\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8236 - val_loss: 0.8222\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8230 - val_loss: 0.8218\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8227 - val_loss: 0.8214\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8215 - val_loss: 0.8210\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8212 - val_loss: 0.8206\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8216 - val_loss: 0.8202\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8221 - val_loss: 0.8198\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8207 - val_loss: 0.8194\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8198 - val_loss: 0.8190\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8194 - val_loss: 0.8185\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8197 - val_loss: 0.8181\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8190 - val_loss: 0.8177\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.8186 - val_loss: 0.8173\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8172 - val_loss: 0.8169\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.8182 - val_loss: 0.8165\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8167 - val_loss: 0.8161\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8167 - val_loss: 0.8157\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.8155 - val_loss: 0.8153\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8161 - val_loss: 0.8149\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8156 - val_loss: 0.8145\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8159 - val_loss: 0.8141\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8140 - val_loss: 0.8137\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.8151 - val_loss: 0.8133\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.8134 - val_loss: 0.8129\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8128 - val_loss: 0.8125\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8137 - val_loss: 0.8121\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8128 - val_loss: 0.8117\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8122 - val_loss: 0.8113\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8108 - val_loss: 0.8109\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8121 - val_loss: 0.8105\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8119 - val_loss: 0.8101\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8109 - val_loss: 0.8097\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.8092 - val_loss: 0.8093\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8095 - val_loss: 0.8089\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8088 - val_loss: 0.8085\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8087 - val_loss: 0.8081\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8084 - val_loss: 0.8077\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.8089 - val_loss: 0.8073\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.8072 - val_loss: 0.8070\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.8078 - val_loss: 0.8066\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.8068 - val_loss: 0.8062\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.8063 - val_loss: 0.8058\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.8066 - val_loss: 0.8054\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.8048 - val_loss: 0.8050\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.8049 - val_loss: 0.8046\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.8050 - val_loss: 0.8042\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.8041 - val_loss: 0.8038\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8037 - val_loss: 0.8034\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.8038 - val_loss: 0.8030\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.8030 - val_loss: 0.8026\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.8021 - val_loss: 0.8022\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8019 - val_loss: 0.8018\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8016 - val_loss: 0.8014\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8015 - val_loss: 0.8010\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.8013 - val_loss: 0.8006\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.8008 - val_loss: 0.8002\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.8007 - val_loss: 0.7998\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.7996 - val_loss: 0.7994\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.7995 - val_loss: 0.7990\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.7995 - val_loss: 0.7986\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7984 - val_loss: 0.7982\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.7980 - val_loss: 0.7978\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.7980 - val_loss: 0.7975\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7972 - val_loss: 0.7971\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7966 - val_loss: 0.7967\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.7969 - val_loss: 0.7963\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7965 - val_loss: 0.7959\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7957 - val_loss: 0.7955\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7945 - val_loss: 0.7951\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.7943 - val_loss: 0.7947\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7942 - val_loss: 0.7943\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.7948 - val_loss: 0.7939\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7935 - val_loss: 0.7935\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7929 - val_loss: 0.7931\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.7929 - val_loss: 0.7927\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7927 - val_loss: 0.7923\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7914 - val_loss: 0.7919\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.7921 - val_loss: 0.7916\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.7916 - val_loss: 0.7912\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.7918 - val_loss: 0.7908\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7899 - val_loss: 0.7904\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.7889 - val_loss: 0.7900\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7897 - val_loss: 0.7896\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7886 - val_loss: 0.7892\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7892 - val_loss: 0.7888\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7875 - val_loss: 0.7884\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.7878 - val_loss: 0.7880\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.7877 - val_loss: 0.7876\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.7872 - val_loss: 0.7873\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.7865 - val_loss: 0.7869\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.7855 - val_loss: 0.7865\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7857 - val_loss: 0.7861\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.7851 - val_loss: 0.7857\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7850 - val_loss: 0.7853\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.7847 - val_loss: 0.7849\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7847 - val_loss: 0.7845\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7836 - val_loss: 0.7841\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7829 - val_loss: 0.7837\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7835 - val_loss: 0.7834\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.7823 - val_loss: 0.7830\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.7824 - val_loss: 0.7826\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.7822 - val_loss: 0.7822\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7815 - val_loss: 0.7818\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.7810 - val_loss: 0.7814\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7802 - val_loss: 0.7810\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.7805 - val_loss: 0.7806\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.7803 - val_loss: 0.7803\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.7803 - val_loss: 0.7799\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7785 - val_loss: 0.7795\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7789 - val_loss: 0.7791\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.7778 - val_loss: 0.7787\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.7776 - val_loss: 0.7783\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7776 - val_loss: 0.7779\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.7764 - val_loss: 0.7775\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7769 - val_loss: 0.7772\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.7763 - val_loss: 0.7768\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.7764 - val_loss: 0.7764\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7760 - val_loss: 0.7760\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7741 - val_loss: 0.7756\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.7736 - val_loss: 0.7752\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7747 - val_loss: 0.7748\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.7736 - val_loss: 0.7745\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.7726 - val_loss: 0.7741\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.7735 - val_loss: 0.7737\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7721 - val_loss: 0.7733\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7732 - val_loss: 0.7729\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7711 - val_loss: 0.7725\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.7705 - val_loss: 0.7721\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7705 - val_loss: 0.7718\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7704 - val_loss: 0.7714\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7702 - val_loss: 0.7710\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.7701 - val_loss: 0.7706\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7705 - val_loss: 0.7702\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.7694 - val_loss: 0.7698\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.7691 - val_loss: 0.7695\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7689 - val_loss: 0.7691\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7672 - val_loss: 0.7687\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.7690 - val_loss: 0.7683\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.7675 - val_loss: 0.7679\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.7670 - val_loss: 0.7675\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.7669 - val_loss: 0.7672\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7657 - val_loss: 0.7668\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.7653 - val_loss: 0.7664\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.7646 - val_loss: 0.7660\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 5, 1024)          2150400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 5, 256)            1311744   \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 5, 1)             257       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,462,401\n",
            "Trainable params: 3,462,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.5058 - val_loss: 0.4948\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.5058 - val_loss: 0.4947\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.5058 - val_loss: 0.4945\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5053 - val_loss: 0.4944\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.5054 - val_loss: 0.4943\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.5052 - val_loss: 0.4941\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.5048 - val_loss: 0.4940\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5046 - val_loss: 0.4939\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.5049 - val_loss: 0.4937\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5044 - val_loss: 0.4936\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.5042 - val_loss: 0.4935\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.5043 - val_loss: 0.4933\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5036 - val_loss: 0.4932\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5042 - val_loss: 0.4931\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5036 - val_loss: 0.4929\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.5035 - val_loss: 0.4928\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5034 - val_loss: 0.4927\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5033 - val_loss: 0.4925\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5033 - val_loss: 0.4924\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5033 - val_loss: 0.4923\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5029 - val_loss: 0.4921\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5028 - val_loss: 0.4920\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5031 - val_loss: 0.4919\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.5024 - val_loss: 0.4917\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.5027 - val_loss: 0.4916\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5022 - val_loss: 0.4915\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5022 - val_loss: 0.4913\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.5020 - val_loss: 0.4912\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5018 - val_loss: 0.4911\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.5019 - val_loss: 0.4909\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.5016 - val_loss: 0.4908\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.5015 - val_loss: 0.4907\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.5013 - val_loss: 0.4905\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.5014 - val_loss: 0.4904\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.5011 - val_loss: 0.4903\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.5010 - val_loss: 0.4901\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.5008 - val_loss: 0.4900\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.5008 - val_loss: 0.4899\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.5005 - val_loss: 0.4897\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.5005 - val_loss: 0.4896\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.5003 - val_loss: 0.4895\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5002 - val_loss: 0.4894\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.5004 - val_loss: 0.4892\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4999 - val_loss: 0.4891\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5000 - val_loss: 0.4890\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4997 - val_loss: 0.4888\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4994 - val_loss: 0.4887\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4993 - val_loss: 0.4886\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4990 - val_loss: 0.4884\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4991 - val_loss: 0.4883\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4988 - val_loss: 0.4882\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4990 - val_loss: 0.4880\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4987 - val_loss: 0.4879\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4986 - val_loss: 0.4878\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4984 - val_loss: 0.4876\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4983 - val_loss: 0.4875\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4983 - val_loss: 0.4874\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4978 - val_loss: 0.4873\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4978 - val_loss: 0.4871\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4980 - val_loss: 0.4870\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4978 - val_loss: 0.4869\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4978 - val_loss: 0.4867\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4973 - val_loss: 0.4866\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4972 - val_loss: 0.4865\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.4970 - val_loss: 0.4863\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4968 - val_loss: 0.4862\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.4969 - val_loss: 0.4861\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.4967 - val_loss: 0.4860\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4967 - val_loss: 0.4858\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4965 - val_loss: 0.4857\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4959 - val_loss: 0.4856\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4962 - val_loss: 0.4854\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4958 - val_loss: 0.4853\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4958 - val_loss: 0.4852\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4962 - val_loss: 0.4851\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4955 - val_loss: 0.4849\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4955 - val_loss: 0.4848\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4953 - val_loss: 0.4847\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4953 - val_loss: 0.4845\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4953 - val_loss: 0.4844\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.4951 - val_loss: 0.4843\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4946 - val_loss: 0.4842\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4950 - val_loss: 0.4840\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4948 - val_loss: 0.4839\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4943 - val_loss: 0.4838\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4946 - val_loss: 0.4836\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4942 - val_loss: 0.4835\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4942 - val_loss: 0.4834\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4938 - val_loss: 0.4833\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4940 - val_loss: 0.4831\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4939 - val_loss: 0.4830\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4934 - val_loss: 0.4829\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4934 - val_loss: 0.4827\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4935 - val_loss: 0.4826\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4931 - val_loss: 0.4825\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4930 - val_loss: 0.4824\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.4928 - val_loss: 0.4822\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4927 - val_loss: 0.4821\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4926 - val_loss: 0.4820\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4923 - val_loss: 0.4819\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4925 - val_loss: 0.4817\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4922 - val_loss: 0.4816\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4922 - val_loss: 0.4815\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4922 - val_loss: 0.4814\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4918 - val_loss: 0.4812\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4918 - val_loss: 0.4811\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4916 - val_loss: 0.4810\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4916 - val_loss: 0.4808\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4914 - val_loss: 0.4807\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4912 - val_loss: 0.4806\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.4913 - val_loss: 0.4805\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4911 - val_loss: 0.4803\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4910 - val_loss: 0.4802\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4904 - val_loss: 0.4801\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4906 - val_loss: 0.4800\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4904 - val_loss: 0.4798\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4902 - val_loss: 0.4797\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4902 - val_loss: 0.4796\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4900 - val_loss: 0.4795\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4902 - val_loss: 0.4793\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4899 - val_loss: 0.4792\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.4898 - val_loss: 0.4791\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4897 - val_loss: 0.4790\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4896 - val_loss: 0.4788\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4891 - val_loss: 0.4787\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4890 - val_loss: 0.4786\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4892 - val_loss: 0.4785\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4890 - val_loss: 0.4783\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4887 - val_loss: 0.4782\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4888 - val_loss: 0.4781\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4886 - val_loss: 0.4780\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4886 - val_loss: 0.4778\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4882 - val_loss: 0.4777\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4882 - val_loss: 0.4776\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4880 - val_loss: 0.4775\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4877 - val_loss: 0.4774\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4876 - val_loss: 0.4772\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4877 - val_loss: 0.4771\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4876 - val_loss: 0.4770\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4876 - val_loss: 0.4769\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4875 - val_loss: 0.4767\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4873 - val_loss: 0.4766\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4870 - val_loss: 0.4765\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4869 - val_loss: 0.4764\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4868 - val_loss: 0.4762\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4868 - val_loss: 0.4761\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4864 - val_loss: 0.4760\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4863 - val_loss: 0.4759\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4864 - val_loss: 0.4758\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4863 - val_loss: 0.4756\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4860 - val_loss: 0.4755\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4858 - val_loss: 0.4754\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4857 - val_loss: 0.4753\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4857 - val_loss: 0.4751\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4855 - val_loss: 0.4750\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4854 - val_loss: 0.4749\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4855 - val_loss: 0.4748\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4852 - val_loss: 0.4746\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4851 - val_loss: 0.4745\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4850 - val_loss: 0.4744\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4849 - val_loss: 0.4743\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4848 - val_loss: 0.4742\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4846 - val_loss: 0.4740\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4843 - val_loss: 0.4739\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4845 - val_loss: 0.4738\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4843 - val_loss: 0.4737\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4840 - val_loss: 0.4736\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4838 - val_loss: 0.4734\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4836 - val_loss: 0.4733\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4835 - val_loss: 0.4732\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4836 - val_loss: 0.4731\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4837 - val_loss: 0.4729\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4834 - val_loss: 0.4728\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4830 - val_loss: 0.4727\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4830 - val_loss: 0.4726\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4830 - val_loss: 0.4725\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4828 - val_loss: 0.4723\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4829 - val_loss: 0.4722\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4825 - val_loss: 0.4721\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4829 - val_loss: 0.4720\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4825 - val_loss: 0.4719\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4820 - val_loss: 0.4717\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4820 - val_loss: 0.4716\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4818 - val_loss: 0.4715\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4820 - val_loss: 0.4714\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4817 - val_loss: 0.4713\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4816 - val_loss: 0.4711\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4817 - val_loss: 0.4710\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4812 - val_loss: 0.4709\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4810 - val_loss: 0.4708\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4812 - val_loss: 0.4707\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4811 - val_loss: 0.4705\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4809 - val_loss: 0.4704\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4807 - val_loss: 0.4703\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4806 - val_loss: 0.4702\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4804 - val_loss: 0.4701\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4804 - val_loss: 0.4699\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4803 - val_loss: 0.4698\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4803 - val_loss: 0.4697\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4798 - val_loss: 0.4696\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4800 - val_loss: 0.4695\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4797 - val_loss: 0.4693\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4797 - val_loss: 0.4692\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4791 - val_loss: 0.4691\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.4795 - val_loss: 0.4690\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4792 - val_loss: 0.4689\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4790 - val_loss: 0.4688\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4790 - val_loss: 0.4686\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4787 - val_loss: 0.4685\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4789 - val_loss: 0.4684\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4787 - val_loss: 0.4683\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4785 - val_loss: 0.4682\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4785 - val_loss: 0.4680\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4785 - val_loss: 0.4679\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4784 - val_loss: 0.4678\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4779 - val_loss: 0.4677\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4779 - val_loss: 0.4676\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4777 - val_loss: 0.4675\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4776 - val_loss: 0.4673\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4774 - val_loss: 0.4672\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4774 - val_loss: 0.4671\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4773 - val_loss: 0.4670\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4773 - val_loss: 0.4669\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4772 - val_loss: 0.4667\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4771 - val_loss: 0.4666\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4769 - val_loss: 0.4665\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4765 - val_loss: 0.4664\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4768 - val_loss: 0.4663\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4764 - val_loss: 0.4662\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4766 - val_loss: 0.4660\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4763 - val_loss: 0.4659\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4762 - val_loss: 0.4658\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4761 - val_loss: 0.4657\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4759 - val_loss: 0.4656\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4758 - val_loss: 0.4655\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4757 - val_loss: 0.4653\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4756 - val_loss: 0.4652\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4754 - val_loss: 0.4651\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4753 - val_loss: 0.4650\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4751 - val_loss: 0.4649\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4754 - val_loss: 0.4648\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.4749 - val_loss: 0.4646\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4749 - val_loss: 0.4645\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4746 - val_loss: 0.4644\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4747 - val_loss: 0.4643\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4745 - val_loss: 0.4642\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.4746 - val_loss: 0.4641\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4741 - val_loss: 0.4639\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4740 - val_loss: 0.4638\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4740 - val_loss: 0.4637\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4739 - val_loss: 0.4636\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4736 - val_loss: 0.4635\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4737 - val_loss: 0.4634\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.4735 - val_loss: 0.4632\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4735 - val_loss: 0.4631\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4734 - val_loss: 0.4630\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4732 - val_loss: 0.4629\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4729 - val_loss: 0.4628\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4730 - val_loss: 0.4627\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4726 - val_loss: 0.4625\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4726 - val_loss: 0.4624\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4727 - val_loss: 0.4623\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4727 - val_loss: 0.4622\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4724 - val_loss: 0.4621\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4724 - val_loss: 0.4620\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4721 - val_loss: 0.4619\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4719 - val_loss: 0.4617\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4719 - val_loss: 0.4616\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4717 - val_loss: 0.4615\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4715 - val_loss: 0.4614\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4717 - val_loss: 0.4613\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4714 - val_loss: 0.4612\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4715 - val_loss: 0.4610\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4713 - val_loss: 0.4609\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.4712 - val_loss: 0.4608\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4709 - val_loss: 0.4607\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4708 - val_loss: 0.4606\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4708 - val_loss: 0.4605\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4707 - val_loss: 0.4604\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4707 - val_loss: 0.4602\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4705 - val_loss: 0.4601\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4702 - val_loss: 0.4600\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4701 - val_loss: 0.4599\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4700 - val_loss: 0.4598\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4698 - val_loss: 0.4597\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4698 - val_loss: 0.4596\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4698 - val_loss: 0.4594\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4695 - val_loss: 0.4593\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4694 - val_loss: 0.4592\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4692 - val_loss: 0.4591\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4692 - val_loss: 0.4590\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4691 - val_loss: 0.4589\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4692 - val_loss: 0.4588\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4689 - val_loss: 0.4586\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4690 - val_loss: 0.4585\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.4687 - val_loss: 0.4584\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4686 - val_loss: 0.4583\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4684 - val_loss: 0.4582\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4684 - val_loss: 0.4581\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4682 - val_loss: 0.4580\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4681 - val_loss: 0.4579\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4683 - val_loss: 0.4577\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4677 - val_loss: 0.4576\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4679 - val_loss: 0.4575\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4674 - val_loss: 0.4574\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4675 - val_loss: 0.4573\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4672 - val_loss: 0.4572\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4675 - val_loss: 0.4571\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4672 - val_loss: 0.4569\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4668 - val_loss: 0.4568\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4668 - val_loss: 0.4567\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4669 - val_loss: 0.4566\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4665 - val_loss: 0.4565\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4665 - val_loss: 0.4564\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4664 - val_loss: 0.4563\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4664 - val_loss: 0.4562\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4664 - val_loss: 0.4560\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.4661 - val_loss: 0.4559\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4660 - val_loss: 0.4558\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4660 - val_loss: 0.4557\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4659 - val_loss: 0.4556\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4656 - val_loss: 0.4555\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4656 - val_loss: 0.4554\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.4655 - val_loss: 0.4553\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4653 - val_loss: 0.4551\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4652 - val_loss: 0.4550\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4652 - val_loss: 0.4549\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4651 - val_loss: 0.4548\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4647 - val_loss: 0.4547\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4647 - val_loss: 0.4546\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4646 - val_loss: 0.4545\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4645 - val_loss: 0.4544\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4645 - val_loss: 0.4542\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4643 - val_loss: 0.4541\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4641 - val_loss: 0.4540\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4641 - val_loss: 0.4539\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4639 - val_loss: 0.4538\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4638 - val_loss: 0.4537\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4639 - val_loss: 0.4536\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4636 - val_loss: 0.4535\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4638 - val_loss: 0.4534\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4634 - val_loss: 0.4532\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4633 - val_loss: 0.4531\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4633 - val_loss: 0.4530\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4632 - val_loss: 0.4529\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4631 - val_loss: 0.4528\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4628 - val_loss: 0.4527\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4629 - val_loss: 0.4526\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4625 - val_loss: 0.4525\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4624 - val_loss: 0.4523\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.4625 - val_loss: 0.4522\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4622 - val_loss: 0.4521\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4624 - val_loss: 0.4520\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4621 - val_loss: 0.4519\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4617 - val_loss: 0.4518\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4616 - val_loss: 0.4517\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4618 - val_loss: 0.4516\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4618 - val_loss: 0.4515\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4615 - val_loss: 0.4513\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4612 - val_loss: 0.4512\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4611 - val_loss: 0.4511\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4611 - val_loss: 0.4510\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.4612 - val_loss: 0.4509\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.4609 - val_loss: 0.4508\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4607 - val_loss: 0.4507\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4609 - val_loss: 0.4506\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4607 - val_loss: 0.4505\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4604 - val_loss: 0.4504\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4602 - val_loss: 0.4502\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4604 - val_loss: 0.4501\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4601 - val_loss: 0.4500\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4600 - val_loss: 0.4499\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4600 - val_loss: 0.4498\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4596 - val_loss: 0.4497\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4598 - val_loss: 0.4496\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4597 - val_loss: 0.4495\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4597 - val_loss: 0.4494\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4595 - val_loss: 0.4493\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4594 - val_loss: 0.4491\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.4590 - val_loss: 0.4490\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4590 - val_loss: 0.4489\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4589 - val_loss: 0.4488\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4587 - val_loss: 0.4487\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4585 - val_loss: 0.4486\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4584 - val_loss: 0.4485\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4587 - val_loss: 0.4484\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4584 - val_loss: 0.4483\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4583 - val_loss: 0.4482\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4582 - val_loss: 0.4480\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4580 - val_loss: 0.4479\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4577 - val_loss: 0.4478\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.4577 - val_loss: 0.4477\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4576 - val_loss: 0.4476\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4574 - val_loss: 0.4475\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4574 - val_loss: 0.4474\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4573 - val_loss: 0.4473\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4572 - val_loss: 0.4472\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4571 - val_loss: 0.4471\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4572 - val_loss: 0.4470\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4571 - val_loss: 0.4468\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4571 - val_loss: 0.4467\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4566 - val_loss: 0.4466\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4565 - val_loss: 0.4465\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4563 - val_loss: 0.4464\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4564 - val_loss: 0.4463\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4561 - val_loss: 0.4462\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4562 - val_loss: 0.4461\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4559 - val_loss: 0.4460\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.4559 - val_loss: 0.4459\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.4558 - val_loss: 0.4458\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4556 - val_loss: 0.4456\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4556 - val_loss: 0.4455\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4553 - val_loss: 0.4454\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4553 - val_loss: 0.4453\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4551 - val_loss: 0.4452\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4550 - val_loss: 0.4451\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4550 - val_loss: 0.4450\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4549 - val_loss: 0.4449\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4549 - val_loss: 0.4448\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4547 - val_loss: 0.4447\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4547 - val_loss: 0.4446\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4545 - val_loss: 0.4445\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4546 - val_loss: 0.4443\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4544 - val_loss: 0.4442\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4543 - val_loss: 0.4441\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4540 - val_loss: 0.4440\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4539 - val_loss: 0.4439\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4537 - val_loss: 0.4438\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4537 - val_loss: 0.4437\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4538 - val_loss: 0.4436\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4535 - val_loss: 0.4435\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4535 - val_loss: 0.4434\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4535 - val_loss: 0.4433\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4532 - val_loss: 0.4432\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4531 - val_loss: 0.4430\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4527 - val_loss: 0.4429\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4527 - val_loss: 0.4428\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.4528 - val_loss: 0.4427\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4526 - val_loss: 0.4426\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4524 - val_loss: 0.4425\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4526 - val_loss: 0.4424\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4521 - val_loss: 0.4423\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4522 - val_loss: 0.4422\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4523 - val_loss: 0.4421\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4519 - val_loss: 0.4420\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4517 - val_loss: 0.4419\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4518 - val_loss: 0.4418\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4519 - val_loss: 0.4417\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4517 - val_loss: 0.4415\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4515 - val_loss: 0.4414\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4515 - val_loss: 0.4413\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4514 - val_loss: 0.4412\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4512 - val_loss: 0.4411\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4508 - val_loss: 0.4410\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4507 - val_loss: 0.4409\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4507 - val_loss: 0.4408\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4507 - val_loss: 0.4407\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4506 - val_loss: 0.4406\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4505 - val_loss: 0.4405\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4506 - val_loss: 0.4404\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4502 - val_loss: 0.4403\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4502 - val_loss: 0.4402\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4500 - val_loss: 0.4400\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4500 - val_loss: 0.4399\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4499 - val_loss: 0.4398\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4498 - val_loss: 0.4397\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4496 - val_loss: 0.4396\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4496 - val_loss: 0.4395\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.4495 - val_loss: 0.4394\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4491 - val_loss: 0.4393\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4492 - val_loss: 0.4392\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4491 - val_loss: 0.4391\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4488 - val_loss: 0.4390\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4491 - val_loss: 0.4389\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4488 - val_loss: 0.4388\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4486 - val_loss: 0.4387\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4486 - val_loss: 0.4386\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4484 - val_loss: 0.4384\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4484 - val_loss: 0.4383\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4482 - val_loss: 0.4382\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4480 - val_loss: 0.4381\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4480 - val_loss: 0.4380\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4480 - val_loss: 0.4379\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4479 - val_loss: 0.4378\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4476 - val_loss: 0.4377\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4477 - val_loss: 0.4376\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4474 - val_loss: 0.4375\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4474 - val_loss: 0.4374\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4473 - val_loss: 0.4373\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4470 - val_loss: 0.4372\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4470 - val_loss: 0.4371\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4470 - val_loss: 0.4370\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4467 - val_loss: 0.4369\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4467 - val_loss: 0.4368\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4466 - val_loss: 0.4366\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.4467 - val_loss: 0.4365\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4464 - val_loss: 0.4364\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4463 - val_loss: 0.4363\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4462 - val_loss: 0.4362\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4462 - val_loss: 0.4361\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4458 - val_loss: 0.4360\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4455 - val_loss: 0.4359\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4459 - val_loss: 0.4358\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4456 - val_loss: 0.4357\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4455 - val_loss: 0.4356\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.4453 - val_loss: 0.4355\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4452 - val_loss: 0.4354\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4454 - val_loss: 0.4353\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4452 - val_loss: 0.4352\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4450 - val_loss: 0.4351\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4449 - val_loss: 0.4350\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4449 - val_loss: 0.4349\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4445 - val_loss: 0.4348\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4447 - val_loss: 0.4346\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4445 - val_loss: 0.4345\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4442 - val_loss: 0.4344\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4444 - val_loss: 0.4343\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4442 - val_loss: 0.4342\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4440 - val_loss: 0.4341\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4441 - val_loss: 0.4340\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4437 - val_loss: 0.4339\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4436 - val_loss: 0.4338\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4437 - val_loss: 0.4337\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4433 - val_loss: 0.4336\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4435 - val_loss: 0.4335\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4434 - val_loss: 0.4334\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4432 - val_loss: 0.4333\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4431 - val_loss: 0.4332\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4429 - val_loss: 0.4331\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4430 - val_loss: 0.4330\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4428 - val_loss: 0.4329\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.4425 - val_loss: 0.4328\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4428 - val_loss: 0.4327\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4426 - val_loss: 0.4326\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4425 - val_loss: 0.4324\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4420 - val_loss: 0.4323\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4421 - val_loss: 0.4322\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4422 - val_loss: 0.4321\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4419 - val_loss: 0.4320\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4415 - val_loss: 0.4319\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4417 - val_loss: 0.4318\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4416 - val_loss: 0.4317\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4414 - val_loss: 0.4316\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4414 - val_loss: 0.4315\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4413 - val_loss: 0.4314\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4411 - val_loss: 0.4313\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4410 - val_loss: 0.4312\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4409 - val_loss: 0.4311\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4410 - val_loss: 0.4310\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4406 - val_loss: 0.4309\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4408 - val_loss: 0.4308\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4408 - val_loss: 0.4307\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4405 - val_loss: 0.4306\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4402 - val_loss: 0.4305\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4402 - val_loss: 0.4304\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.4403 - val_loss: 0.4303\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4398 - val_loss: 0.4302\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4398 - val_loss: 0.4301\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4397 - val_loss: 0.4300\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4398 - val_loss: 0.4298\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4397 - val_loss: 0.4297\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4396 - val_loss: 0.4296\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4395 - val_loss: 0.4295\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4394 - val_loss: 0.4294\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4390 - val_loss: 0.4293\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4389 - val_loss: 0.4292\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4391 - val_loss: 0.4291\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4388 - val_loss: 0.4290\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4388 - val_loss: 0.4289\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4387 - val_loss: 0.4288\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4386 - val_loss: 0.4287\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4383 - val_loss: 0.4286\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4385 - val_loss: 0.4285\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.4383 - val_loss: 0.4284\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4381 - val_loss: 0.4283\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4382 - val_loss: 0.4282\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4381 - val_loss: 0.4281\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4376 - val_loss: 0.4280\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4376 - val_loss: 0.4279\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4375 - val_loss: 0.4278\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4377 - val_loss: 0.4277\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4375 - val_loss: 0.4276\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4374 - val_loss: 0.4275\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4373 - val_loss: 0.4274\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4372 - val_loss: 0.4273\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4368 - val_loss: 0.4272\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4368 - val_loss: 0.4271\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4368 - val_loss: 0.4270\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4367 - val_loss: 0.4269\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4365 - val_loss: 0.4268\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4364 - val_loss: 0.4267\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4365 - val_loss: 0.4266\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4363 - val_loss: 0.4264\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4363 - val_loss: 0.4263\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4360 - val_loss: 0.4262\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4360 - val_loss: 0.4261\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4360 - val_loss: 0.4260\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4358 - val_loss: 0.4259\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4356 - val_loss: 0.4258\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4359 - val_loss: 0.4257\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4354 - val_loss: 0.4256\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4353 - val_loss: 0.4255\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.4351 - val_loss: 0.4254\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4352 - val_loss: 0.4253\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4354 - val_loss: 0.4252\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4350 - val_loss: 0.4251\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4349 - val_loss: 0.4250\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4346 - val_loss: 0.4249\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4347 - val_loss: 0.4248\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.4345 - val_loss: 0.4247\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4342 - val_loss: 0.4246\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4343 - val_loss: 0.4245\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4343 - val_loss: 0.4244\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4341 - val_loss: 0.4243\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4340 - val_loss: 0.4242\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4338 - val_loss: 0.4241\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4340 - val_loss: 0.4240\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4338 - val_loss: 0.4239\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.4335 - val_loss: 0.4238\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4332 - val_loss: 0.4237\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4334 - val_loss: 0.4236\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4334 - val_loss: 0.4235\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4332 - val_loss: 0.4234\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4331 - val_loss: 0.4233\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.4330 - val_loss: 0.4232\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4327 - val_loss: 0.4231\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4327 - val_loss: 0.4230\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4328 - val_loss: 0.4229\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4324 - val_loss: 0.4228\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4324 - val_loss: 0.4227\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4324 - val_loss: 0.4226\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4322 - val_loss: 0.4225\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4320 - val_loss: 0.4224\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4320 - val_loss: 0.4223\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4318 - val_loss: 0.4222\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4317 - val_loss: 0.4221\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4317 - val_loss: 0.4220\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4315 - val_loss: 0.4219\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.4315 - val_loss: 0.4218\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4314 - val_loss: 0.4217\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.4314 - val_loss: 0.4216\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4314 - val_loss: 0.4215\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4313 - val_loss: 0.4214\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4311 - val_loss: 0.4213\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4311 - val_loss: 0.4211\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4309 - val_loss: 0.4210\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4306 - val_loss: 0.4209\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4306 - val_loss: 0.4208\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4308 - val_loss: 0.4207\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4304 - val_loss: 0.4206\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4303 - val_loss: 0.4205\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4301 - val_loss: 0.4204\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4302 - val_loss: 0.4203\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.4300 - val_loss: 0.4202\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4299 - val_loss: 0.4201\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4297 - val_loss: 0.4200\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4293 - val_loss: 0.4199\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4296 - val_loss: 0.4198\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4296 - val_loss: 0.4197\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4293 - val_loss: 0.4196\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4292 - val_loss: 0.4195\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.4291 - val_loss: 0.4194\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4290 - val_loss: 0.4193\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4290 - val_loss: 0.4192\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4289 - val_loss: 0.4191\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4286 - val_loss: 0.4190\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.4288 - val_loss: 0.4189\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4288 - val_loss: 0.4188\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.4283 - val_loss: 0.4187\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4283 - val_loss: 0.4186\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4281 - val_loss: 0.4185\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4282 - val_loss: 0.4184\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4280 - val_loss: 0.4183\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4280 - val_loss: 0.4182\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4278 - val_loss: 0.4181\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4278 - val_loss: 0.4180\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4276 - val_loss: 0.4179\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4278 - val_loss: 0.4178\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4277 - val_loss: 0.4177\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4274 - val_loss: 0.4176\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4272 - val_loss: 0.4175\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4275 - val_loss: 0.4174\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4271 - val_loss: 0.4173\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4269 - val_loss: 0.4172\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4270 - val_loss: 0.4171\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4269 - val_loss: 0.4170\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4270 - val_loss: 0.4169\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4266 - val_loss: 0.4168\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4265 - val_loss: 0.4167\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4262 - val_loss: 0.4166\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4262 - val_loss: 0.4165\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4261 - val_loss: 0.4164\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4260 - val_loss: 0.4163\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4261 - val_loss: 0.4162\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4258 - val_loss: 0.4161\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.4259 - val_loss: 0.4160\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4256 - val_loss: 0.4159\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4256 - val_loss: 0.4158\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4253 - val_loss: 0.4157\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4254 - val_loss: 0.4156\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4253 - val_loss: 0.4155\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4251 - val_loss: 0.4154\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4251 - val_loss: 0.4153\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4249 - val_loss: 0.4152\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4248 - val_loss: 0.4151\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4248 - val_loss: 0.4150\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4246 - val_loss: 0.4149\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4246 - val_loss: 0.4148\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4244 - val_loss: 0.4147\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4242 - val_loss: 0.4146\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4242 - val_loss: 0.4145\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4241 - val_loss: 0.4144\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.4240 - val_loss: 0.4143\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4240 - val_loss: 0.4142\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4240 - val_loss: 0.4141\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4238 - val_loss: 0.4140\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4233 - val_loss: 0.4139\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4237 - val_loss: 0.4138\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4233 - val_loss: 0.4137\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4233 - val_loss: 0.4136\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4230 - val_loss: 0.4135\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4233 - val_loss: 0.4134\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4229 - val_loss: 0.4133\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4232 - val_loss: 0.4132\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4230 - val_loss: 0.4131\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4229 - val_loss: 0.4130\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.4226 - val_loss: 0.4129\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4225 - val_loss: 0.4128\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4224 - val_loss: 0.4127\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4223 - val_loss: 0.4126\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4222 - val_loss: 0.4126\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4220 - val_loss: 0.4125\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4220 - val_loss: 0.4124\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4220 - val_loss: 0.4123\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4221 - val_loss: 0.4122\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4217 - val_loss: 0.4121\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4218 - val_loss: 0.4120\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4214 - val_loss: 0.4119\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4215 - val_loss: 0.4118\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4212 - val_loss: 0.4117\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4212 - val_loss: 0.4116\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4210 - val_loss: 0.4115\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4214 - val_loss: 0.4114\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4208 - val_loss: 0.4113\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4208 - val_loss: 0.4112\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4209 - val_loss: 0.4111\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4206 - val_loss: 0.4110\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4207 - val_loss: 0.4109\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4207 - val_loss: 0.4108\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4204 - val_loss: 0.4107\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4202 - val_loss: 0.4106\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.4199 - val_loss: 0.4105\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4197 - val_loss: 0.4104\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4200 - val_loss: 0.4103\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4200 - val_loss: 0.4102\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4198 - val_loss: 0.4101\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4196 - val_loss: 0.4100\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4196 - val_loss: 0.4099\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4193 - val_loss: 0.4098\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4194 - val_loss: 0.4097\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4195 - val_loss: 0.4096\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4192 - val_loss: 0.4095\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4192 - val_loss: 0.4094\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4189 - val_loss: 0.4093\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4192 - val_loss: 0.4092\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4185 - val_loss: 0.4091\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4188 - val_loss: 0.4090\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4184 - val_loss: 0.4089\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4184 - val_loss: 0.4088\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4184 - val_loss: 0.4087\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4184 - val_loss: 0.4086\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4179 - val_loss: 0.4085\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4181 - val_loss: 0.4084\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4181 - val_loss: 0.4083\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4176 - val_loss: 0.4082\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4177 - val_loss: 0.4081\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4176 - val_loss: 0.4080\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4175 - val_loss: 0.4079\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4175 - val_loss: 0.4078\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4173 - val_loss: 0.4077\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4173 - val_loss: 0.4076\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4173 - val_loss: 0.4075\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4171 - val_loss: 0.4074\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4170 - val_loss: 0.4073\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4170 - val_loss: 0.4072\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.4169 - val_loss: 0.4071\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4168 - val_loss: 0.4070\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4166 - val_loss: 0.4069\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4165 - val_loss: 0.4069\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.4164 - val_loss: 0.4068\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4163 - val_loss: 0.4067\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4162 - val_loss: 0.4066\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4161 - val_loss: 0.4065\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4158 - val_loss: 0.4064\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4162 - val_loss: 0.4063\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4155 - val_loss: 0.4062\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4158 - val_loss: 0.4061\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4158 - val_loss: 0.4060\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4155 - val_loss: 0.4059\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4157 - val_loss: 0.4058\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4152 - val_loss: 0.4057\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4152 - val_loss: 0.4056\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.4153 - val_loss: 0.4055\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4148 - val_loss: 0.4054\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4148 - val_loss: 0.4053\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4149 - val_loss: 0.4052\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4146 - val_loss: 0.4051\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4147 - val_loss: 0.4050\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4142 - val_loss: 0.4049\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4145 - val_loss: 0.4048\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4142 - val_loss: 0.4047\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4146 - val_loss: 0.4046\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4140 - val_loss: 0.4045\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.4139 - val_loss: 0.4044\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4139 - val_loss: 0.4043\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4140 - val_loss: 0.4042\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4138 - val_loss: 0.4041\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4135 - val_loss: 0.4040\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4134 - val_loss: 0.4039\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4136 - val_loss: 0.4038\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4134 - val_loss: 0.4037\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4133 - val_loss: 0.4036\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4133 - val_loss: 0.4035\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4128 - val_loss: 0.4035\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4127 - val_loss: 0.4034\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4128 - val_loss: 0.4033\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4127 - val_loss: 0.4032\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4129 - val_loss: 0.4031\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4125 - val_loss: 0.4030\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4122 - val_loss: 0.4029\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4123 - val_loss: 0.4028\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4122 - val_loss: 0.4027\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4124 - val_loss: 0.4026\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4121 - val_loss: 0.4025\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4120 - val_loss: 0.4024\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.4117 - val_loss: 0.4023\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4117 - val_loss: 0.4022\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4119 - val_loss: 0.4021\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4114 - val_loss: 0.4020\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4114 - val_loss: 0.4019\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.4113 - val_loss: 0.4018\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4112 - val_loss: 0.4017\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.4112 - val_loss: 0.4016\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4111 - val_loss: 0.4015\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4109 - val_loss: 0.4014\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4109 - val_loss: 0.4013\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4107 - val_loss: 0.4012\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4108 - val_loss: 0.4011\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4106 - val_loss: 0.4010\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4104 - val_loss: 0.4009\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4103 - val_loss: 0.4008\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4106 - val_loss: 0.4008\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4103 - val_loss: 0.4007\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4102 - val_loss: 0.4006\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4100 - val_loss: 0.4005\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4100 - val_loss: 0.4004\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4100 - val_loss: 0.4003\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4098 - val_loss: 0.4002\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4098 - val_loss: 0.4001\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4096 - val_loss: 0.4000\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4094 - val_loss: 0.3999\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4096 - val_loss: 0.3998\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4092 - val_loss: 0.3997\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4094 - val_loss: 0.3996\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4091 - val_loss: 0.3995\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4091 - val_loss: 0.3994\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4091 - val_loss: 0.3993\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.4086 - val_loss: 0.3992\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4086 - val_loss: 0.3991\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.4088 - val_loss: 0.3990\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4083 - val_loss: 0.3989\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4084 - val_loss: 0.3988\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4084 - val_loss: 0.3987\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.4083 - val_loss: 0.3986\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4081 - val_loss: 0.3985\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4080 - val_loss: 0.3985\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.4078 - val_loss: 0.3984\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4078 - val_loss: 0.3983\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4078 - val_loss: 0.3982\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4076 - val_loss: 0.3981\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4076 - val_loss: 0.3980\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4075 - val_loss: 0.3979\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4073 - val_loss: 0.3978\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4070 - val_loss: 0.3977\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4070 - val_loss: 0.3976\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4068 - val_loss: 0.3975\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4070 - val_loss: 0.3974\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4069 - val_loss: 0.3973\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4069 - val_loss: 0.3972\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4068 - val_loss: 0.3971\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4066 - val_loss: 0.3970\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4063 - val_loss: 0.3969\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4062 - val_loss: 0.3968\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4060 - val_loss: 0.3967\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4060 - val_loss: 0.3966\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4060 - val_loss: 0.3965\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4060 - val_loss: 0.3964\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4059 - val_loss: 0.3964\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4058 - val_loss: 0.3963\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4057 - val_loss: 0.3962\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4054 - val_loss: 0.3961\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4055 - val_loss: 0.3960\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.4053 - val_loss: 0.3959\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4053 - val_loss: 0.3958\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4052 - val_loss: 0.3957\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.4048 - val_loss: 0.3956\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4053 - val_loss: 0.3955\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4050 - val_loss: 0.3954\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4049 - val_loss: 0.3953\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4048 - val_loss: 0.3952\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4047 - val_loss: 0.3951\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4044 - val_loss: 0.3950\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.4044 - val_loss: 0.3949\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4043 - val_loss: 0.3948\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.4043 - val_loss: 0.3947\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.4037 - val_loss: 0.3946\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4043 - val_loss: 0.3946\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4041 - val_loss: 0.3945\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.4041 - val_loss: 0.3944\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4037 - val_loss: 0.3943\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4037 - val_loss: 0.3942\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.4033 - val_loss: 0.3941\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.4034 - val_loss: 0.3940\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4034 - val_loss: 0.3939\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4035 - val_loss: 0.3938\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.4032 - val_loss: 0.3937\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4030 - val_loss: 0.3936\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.4029 - val_loss: 0.3935\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.4030 - val_loss: 0.3934\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.4028 - val_loss: 0.3933\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4026 - val_loss: 0.3932\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4026 - val_loss: 0.3931\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4027 - val_loss: 0.3930\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4023 - val_loss: 0.3929\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.4021 - val_loss: 0.3928\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.4025 - val_loss: 0.3928\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4020 - val_loss: 0.3927\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4023 - val_loss: 0.3926\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.4020 - val_loss: 0.3925\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.4020 - val_loss: 0.3924\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.4019 - val_loss: 0.3923\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.4019 - val_loss: 0.3922\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.4016 - val_loss: 0.3921\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.4016 - val_loss: 0.3920\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4012 - val_loss: 0.3919\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4017 - val_loss: 0.3918\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.4014 - val_loss: 0.3917\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4012 - val_loss: 0.3916\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4011 - val_loss: 0.3915\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.4012 - val_loss: 0.3914\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.4008 - val_loss: 0.3913\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.4004 - val_loss: 0.3912\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.4008 - val_loss: 0.3912\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.4006 - val_loss: 0.3911\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.4003 - val_loss: 0.3910\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4004 - val_loss: 0.3909\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4001 - val_loss: 0.3908\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.4000 - val_loss: 0.3907\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.4001 - val_loss: 0.3906\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.4001 - val_loss: 0.3905\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3996 - val_loss: 0.3904\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.4001 - val_loss: 0.3903\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3998 - val_loss: 0.3902\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3994 - val_loss: 0.3901\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3997 - val_loss: 0.3900\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3993 - val_loss: 0.3899\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.3992 - val_loss: 0.3898\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3990 - val_loss: 0.3897\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3991 - val_loss: 0.3897\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.3992 - val_loss: 0.3896\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3989 - val_loss: 0.3895\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3988 - val_loss: 0.3894\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.3987 - val_loss: 0.3893\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3986 - val_loss: 0.3892\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3984 - val_loss: 0.3891\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3982 - val_loss: 0.3890\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.3984 - val_loss: 0.3889\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3982 - val_loss: 0.3888\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.3984 - val_loss: 0.3887\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3982 - val_loss: 0.3886\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3979 - val_loss: 0.3885\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3980 - val_loss: 0.3884\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.3977 - val_loss: 0.3883\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.3978 - val_loss: 0.3883\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.3978 - val_loss: 0.3882\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.3975 - val_loss: 0.3881\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.3970 - val_loss: 0.3880\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.3974 - val_loss: 0.3879\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.3972 - val_loss: 0.3878\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3970 - val_loss: 0.3877\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.3969 - val_loss: 0.3876\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.3970 - val_loss: 0.3875\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3967 - val_loss: 0.3874\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.3968 - val_loss: 0.3873\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3967 - val_loss: 0.3872\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.3964 - val_loss: 0.3871\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.3964 - val_loss: 0.3870\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.3965 - val_loss: 0.3870\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3964 - val_loss: 0.3869\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.3965 - val_loss: 0.3868\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 5, 1024)          2150400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 5, 256)            1311744   \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 5, 1)             257       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,462,401\n",
            "Trainable params: 3,462,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.0103 - val_loss: 1.0019\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 1.0106 - val_loss: 1.0017\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.0102 - val_loss: 1.0014\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 1.0101 - val_loss: 1.0011\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 1.0099 - val_loss: 1.0008\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0098 - val_loss: 1.0005\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 1.0095 - val_loss: 1.0002\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0091 - val_loss: 0.9999\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 1.0091 - val_loss: 0.9996\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 1.0084 - val_loss: 0.9993\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0080 - val_loss: 0.9990\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0078 - val_loss: 0.9987\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.0072 - val_loss: 0.9984\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.0072 - val_loss: 0.9981\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 1.0070 - val_loss: 0.9978\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0067 - val_loss: 0.9975\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0066 - val_loss: 0.9972\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.0057 - val_loss: 0.9970\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 1.0059 - val_loss: 0.9967\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0055 - val_loss: 0.9964\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0056 - val_loss: 0.9961\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 1.0051 - val_loss: 0.9958\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.0046 - val_loss: 0.9955\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.0043 - val_loss: 0.9952\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.0041 - val_loss: 0.9949\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 1.0043 - val_loss: 0.9946\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 1.0034 - val_loss: 0.9943\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 1.0030 - val_loss: 0.9941\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0029 - val_loss: 0.9938\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0024 - val_loss: 0.9935\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.0020 - val_loss: 0.9932\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.0013 - val_loss: 0.9929\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 1.0018 - val_loss: 0.9926\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0013 - val_loss: 0.9923\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.0015 - val_loss: 0.9921\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 1.0010 - val_loss: 0.9918\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.0010 - val_loss: 0.9915\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.0005 - val_loss: 0.9912\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9996 - val_loss: 0.9909\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9996 - val_loss: 0.9907\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9996 - val_loss: 0.9904\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9995 - val_loss: 0.9901\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.9989 - val_loss: 0.9898\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9986 - val_loss: 0.9895\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9986 - val_loss: 0.9893\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9984 - val_loss: 0.9890\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9979 - val_loss: 0.9887\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9977 - val_loss: 0.9884\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.9973 - val_loss: 0.9881\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.9970 - val_loss: 0.9879\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.9967 - val_loss: 0.9876\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.9963 - val_loss: 0.9873\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.9961 - val_loss: 0.9870\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9961 - val_loss: 0.9868\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.9956 - val_loss: 0.9865\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9959 - val_loss: 0.9862\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.9949 - val_loss: 0.9860\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9946 - val_loss: 0.9857\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9949 - val_loss: 0.9854\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9945 - val_loss: 0.9851\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9944 - val_loss: 0.9849\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9937 - val_loss: 0.9846\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9938 - val_loss: 0.9843\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9933 - val_loss: 0.9841\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.9931 - val_loss: 0.9838\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9927 - val_loss: 0.9835\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9924 - val_loss: 0.9833\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9922 - val_loss: 0.9830\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9921 - val_loss: 0.9827\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.9920 - val_loss: 0.9825\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9916 - val_loss: 0.9822\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9913 - val_loss: 0.9819\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9909 - val_loss: 0.9817\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9907 - val_loss: 0.9814\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9905 - val_loss: 0.9811\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9904 - val_loss: 0.9809\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9900 - val_loss: 0.9806\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.9894 - val_loss: 0.9803\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9892 - val_loss: 0.9801\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9889 - val_loss: 0.9798\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.9888 - val_loss: 0.9796\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9884 - val_loss: 0.9793\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9884 - val_loss: 0.9790\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9882 - val_loss: 0.9788\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9878 - val_loss: 0.9785\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9878 - val_loss: 0.9783\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9873 - val_loss: 0.9780\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9870 - val_loss: 0.9778\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9871 - val_loss: 0.9775\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9866 - val_loss: 0.9772\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9863 - val_loss: 0.9770\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9860 - val_loss: 0.9767\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9858 - val_loss: 0.9765\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9854 - val_loss: 0.9762\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9857 - val_loss: 0.9760\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9850 - val_loss: 0.9757\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9846 - val_loss: 0.9755\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9848 - val_loss: 0.9752\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9840 - val_loss: 0.9750\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.9844 - val_loss: 0.9747\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9837 - val_loss: 0.9745\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9832 - val_loss: 0.9742\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9832 - val_loss: 0.9740\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9831 - val_loss: 0.9737\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9827 - val_loss: 0.9735\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.9827 - val_loss: 0.9732\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9825 - val_loss: 0.9730\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.9822 - val_loss: 0.9727\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9819 - val_loss: 0.9725\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9816 - val_loss: 0.9722\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9815 - val_loss: 0.9720\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9813 - val_loss: 0.9717\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9810 - val_loss: 0.9715\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9807 - val_loss: 0.9712\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9805 - val_loss: 0.9710\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9800 - val_loss: 0.9707\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9798 - val_loss: 0.9705\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9799 - val_loss: 0.9702\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9795 - val_loss: 0.9700\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9795 - val_loss: 0.9698\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9792 - val_loss: 0.9695\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9785 - val_loss: 0.9693\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9785 - val_loss: 0.9690\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9787 - val_loss: 0.9688\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9783 - val_loss: 0.9686\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9777 - val_loss: 0.9683\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9772 - val_loss: 0.9681\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9773 - val_loss: 0.9678\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9772 - val_loss: 0.9676\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.9768 - val_loss: 0.9674\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9768 - val_loss: 0.9671\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9765 - val_loss: 0.9669\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9763 - val_loss: 0.9667\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9761 - val_loss: 0.9664\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.9756 - val_loss: 0.9662\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9755 - val_loss: 0.9659\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9754 - val_loss: 0.9657\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9753 - val_loss: 0.9655\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9748 - val_loss: 0.9652\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9745 - val_loss: 0.9650\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9744 - val_loss: 0.9648\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9741 - val_loss: 0.9645\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9744 - val_loss: 0.9643\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9741 - val_loss: 0.9641\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9737 - val_loss: 0.9638\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9733 - val_loss: 0.9636\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9733 - val_loss: 0.9634\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9733 - val_loss: 0.9631\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9723 - val_loss: 0.9629\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9723 - val_loss: 0.9627\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9723 - val_loss: 0.9625\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9721 - val_loss: 0.9622\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9714 - val_loss: 0.9620\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.9717 - val_loss: 0.9618\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9717 - val_loss: 0.9615\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9712 - val_loss: 0.9613\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9713 - val_loss: 0.9611\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9708 - val_loss: 0.9609\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.9703 - val_loss: 0.9606\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.9702 - val_loss: 0.9604\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9699 - val_loss: 0.9602\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.9696 - val_loss: 0.9599\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9695 - val_loss: 0.9597\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9690 - val_loss: 0.9595\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9688 - val_loss: 0.9593\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9688 - val_loss: 0.9591\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9684 - val_loss: 0.9588\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.9682 - val_loss: 0.9586\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9679 - val_loss: 0.9584\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9677 - val_loss: 0.9582\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9673 - val_loss: 0.9579\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9675 - val_loss: 0.9577\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9672 - val_loss: 0.9575\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9671 - val_loss: 0.9573\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9668 - val_loss: 0.9571\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.9666 - val_loss: 0.9568\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9667 - val_loss: 0.9566\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9663 - val_loss: 0.9564\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9660 - val_loss: 0.9562\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9659 - val_loss: 0.9560\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.9655 - val_loss: 0.9557\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9653 - val_loss: 0.9555\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9654 - val_loss: 0.9553\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9650 - val_loss: 0.9551\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9648 - val_loss: 0.9549\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9648 - val_loss: 0.9546\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9643 - val_loss: 0.9544\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9641 - val_loss: 0.9542\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9637 - val_loss: 0.9540\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9635 - val_loss: 0.9538\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9636 - val_loss: 0.9536\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9632 - val_loss: 0.9533\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9627 - val_loss: 0.9531\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.9628 - val_loss: 0.9529\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9630 - val_loss: 0.9527\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9622 - val_loss: 0.9525\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9624 - val_loss: 0.9523\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9623 - val_loss: 0.9521\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9614 - val_loss: 0.9519\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9616 - val_loss: 0.9516\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9613 - val_loss: 0.9514\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.9610 - val_loss: 0.9512\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9613 - val_loss: 0.9510\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9606 - val_loss: 0.9508\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9609 - val_loss: 0.9506\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9601 - val_loss: 0.9504\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.9600 - val_loss: 0.9502\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9600 - val_loss: 0.9500\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9598 - val_loss: 0.9498\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9596 - val_loss: 0.9495\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9595 - val_loss: 0.9493\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9590 - val_loss: 0.9491\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9591 - val_loss: 0.9489\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9586 - val_loss: 0.9487\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9585 - val_loss: 0.9485\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9586 - val_loss: 0.9483\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9583 - val_loss: 0.9481\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9578 - val_loss: 0.9479\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9578 - val_loss: 0.9477\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9574 - val_loss: 0.9475\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9576 - val_loss: 0.9473\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9572 - val_loss: 0.9471\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9569 - val_loss: 0.9469\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.9565 - val_loss: 0.9467\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9565 - val_loss: 0.9465\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9561 - val_loss: 0.9463\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9565 - val_loss: 0.9461\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9561 - val_loss: 0.9458\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9558 - val_loss: 0.9456\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9558 - val_loss: 0.9454\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9556 - val_loss: 0.9452\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9552 - val_loss: 0.9450\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9551 - val_loss: 0.9448\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9550 - val_loss: 0.9446\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9548 - val_loss: 0.9444\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9547 - val_loss: 0.9442\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9544 - val_loss: 0.9440\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9540 - val_loss: 0.9438\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9537 - val_loss: 0.9436\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9534 - val_loss: 0.9434\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9537 - val_loss: 0.9432\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9535 - val_loss: 0.9430\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9528 - val_loss: 0.9428\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9528 - val_loss: 0.9426\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9527 - val_loss: 0.9424\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9527 - val_loss: 0.9422\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9525 - val_loss: 0.9420\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9520 - val_loss: 0.9419\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9517 - val_loss: 0.9417\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9517 - val_loss: 0.9415\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9516 - val_loss: 0.9413\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9516 - val_loss: 0.9411\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9513 - val_loss: 0.9409\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9508 - val_loss: 0.9407\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.9506 - val_loss: 0.9405\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9504 - val_loss: 0.9403\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9505 - val_loss: 0.9401\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9503 - val_loss: 0.9399\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9498 - val_loss: 0.9397\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9499 - val_loss: 0.9395\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9497 - val_loss: 0.9393\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9496 - val_loss: 0.9391\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9492 - val_loss: 0.9389\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9492 - val_loss: 0.9387\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9488 - val_loss: 0.9385\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9490 - val_loss: 0.9384\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9484 - val_loss: 0.9382\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9480 - val_loss: 0.9380\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9482 - val_loss: 0.9378\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9483 - val_loss: 0.9376\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.9477 - val_loss: 0.9374\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9476 - val_loss: 0.9372\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9474 - val_loss: 0.9370\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9474 - val_loss: 0.9368\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.9476 - val_loss: 0.9366\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9470 - val_loss: 0.9365\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9468 - val_loss: 0.9363\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9469 - val_loss: 0.9361\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9461 - val_loss: 0.9359\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.9464 - val_loss: 0.9357\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9460 - val_loss: 0.9355\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9459 - val_loss: 0.9353\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9455 - val_loss: 0.9351\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9454 - val_loss: 0.9350\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9454 - val_loss: 0.9348\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9452 - val_loss: 0.9346\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9450 - val_loss: 0.9344\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9448 - val_loss: 0.9342\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.9444 - val_loss: 0.9340\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.9446 - val_loss: 0.9338\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9440 - val_loss: 0.9336\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9437 - val_loss: 0.9335\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9438 - val_loss: 0.9333\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9437 - val_loss: 0.9331\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9434 - val_loss: 0.9329\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9432 - val_loss: 0.9327\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.9430 - val_loss: 0.9325\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9427 - val_loss: 0.9324\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9428 - val_loss: 0.9322\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9423 - val_loss: 0.9320\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9421 - val_loss: 0.9318\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9425 - val_loss: 0.9316\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9422 - val_loss: 0.9314\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9419 - val_loss: 0.9313\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9419 - val_loss: 0.9311\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9419 - val_loss: 0.9309\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 0.9414 - val_loss: 0.9307\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9412 - val_loss: 0.9305\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9409 - val_loss: 0.9304\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9407 - val_loss: 0.9302\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9406 - val_loss: 0.9300\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9402 - val_loss: 0.9298\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9404 - val_loss: 0.9296\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9397 - val_loss: 0.9295\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9398 - val_loss: 0.9293\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.9396 - val_loss: 0.9291\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9397 - val_loss: 0.9289\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9397 - val_loss: 0.9287\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9395 - val_loss: 0.9286\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9389 - val_loss: 0.9284\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9390 - val_loss: 0.9282\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9386 - val_loss: 0.9280\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9389 - val_loss: 0.9278\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9385 - val_loss: 0.9277\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9382 - val_loss: 0.9275\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9380 - val_loss: 0.9273\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.9377 - val_loss: 0.9271\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9374 - val_loss: 0.9270\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9375 - val_loss: 0.9268\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9375 - val_loss: 0.9266\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9374 - val_loss: 0.9264\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9373 - val_loss: 0.9263\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.9372 - val_loss: 0.9261\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9364 - val_loss: 0.9259\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9365 - val_loss: 0.9257\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9367 - val_loss: 0.9256\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9363 - val_loss: 0.9254\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9359 - val_loss: 0.9252\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9357 - val_loss: 0.9250\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9353 - val_loss: 0.9249\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9356 - val_loss: 0.9247\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9352 - val_loss: 0.9245\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9353 - val_loss: 0.9243\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9349 - val_loss: 0.9242\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9350 - val_loss: 0.9240\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9350 - val_loss: 0.9238\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9344 - val_loss: 0.9236\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9347 - val_loss: 0.9235\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9342 - val_loss: 0.9233\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9342 - val_loss: 0.9231\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9342 - val_loss: 0.9230\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9336 - val_loss: 0.9228\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9331 - val_loss: 0.9226\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9335 - val_loss: 0.9224\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9332 - val_loss: 0.9223\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9329 - val_loss: 0.9221\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.9329 - val_loss: 0.9219\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9327 - val_loss: 0.9218\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9327 - val_loss: 0.9216\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9326 - val_loss: 0.9214\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9322 - val_loss: 0.9212\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9316 - val_loss: 0.9211\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9318 - val_loss: 0.9209\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9317 - val_loss: 0.9207\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9315 - val_loss: 0.9206\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.9314 - val_loss: 0.9204\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9313 - val_loss: 0.9202\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.9312 - val_loss: 0.9201\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.9310 - val_loss: 0.9199\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9308 - val_loss: 0.9197\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9309 - val_loss: 0.9196\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9307 - val_loss: 0.9194\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9304 - val_loss: 0.9192\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9300 - val_loss: 0.9191\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9298 - val_loss: 0.9189\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9300 - val_loss: 0.9187\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9296 - val_loss: 0.9186\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.9294 - val_loss: 0.9184\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9295 - val_loss: 0.9182\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9295 - val_loss: 0.9181\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9289 - val_loss: 0.9179\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9290 - val_loss: 0.9177\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 462ms/step - loss: 0.9289 - val_loss: 0.9176\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9285 - val_loss: 0.9174\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9288 - val_loss: 0.9172\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9280 - val_loss: 0.9171\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9280 - val_loss: 0.9169\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9278 - val_loss: 0.9167\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9276 - val_loss: 0.9166\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9275 - val_loss: 0.9164\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9277 - val_loss: 0.9163\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9271 - val_loss: 0.9161\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9271 - val_loss: 0.9159\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9272 - val_loss: 0.9158\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.9270 - val_loss: 0.9156\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9271 - val_loss: 0.9154\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9263 - val_loss: 0.9153\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9263 - val_loss: 0.9151\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9261 - val_loss: 0.9150\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9255 - val_loss: 0.9148\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9261 - val_loss: 0.9146\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9257 - val_loss: 0.9145\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9261 - val_loss: 0.9143\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.9251 - val_loss: 0.9141\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.9253 - val_loss: 0.9140\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9250 - val_loss: 0.9138\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9250 - val_loss: 0.9137\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.9245 - val_loss: 0.9135\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.9247 - val_loss: 0.9133\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9244 - val_loss: 0.9132\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9242 - val_loss: 0.9130\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9244 - val_loss: 0.9129\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9238 - val_loss: 0.9127\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9241 - val_loss: 0.9125\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9240 - val_loss: 0.9124\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9234 - val_loss: 0.9122\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9235 - val_loss: 0.9121\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9230 - val_loss: 0.9119\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9230 - val_loss: 0.9117\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.9230 - val_loss: 0.9116\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9233 - val_loss: 0.9114\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9232 - val_loss: 0.9113\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9221 - val_loss: 0.9111\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9222 - val_loss: 0.9110\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9223 - val_loss: 0.9108\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.9218 - val_loss: 0.9106\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9218 - val_loss: 0.9105\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9213 - val_loss: 0.9103\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9216 - val_loss: 0.9102\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9212 - val_loss: 0.9100\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9215 - val_loss: 0.9099\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9213 - val_loss: 0.9097\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9209 - val_loss: 0.9095\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9205 - val_loss: 0.9094\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9206 - val_loss: 0.9092\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9204 - val_loss: 0.9091\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9204 - val_loss: 0.9089\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9205 - val_loss: 0.9088\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9203 - val_loss: 0.9086\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9196 - val_loss: 0.9084\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.9196 - val_loss: 0.9083\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9198 - val_loss: 0.9081\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.9192 - val_loss: 0.9080\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9193 - val_loss: 0.9078\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9193 - val_loss: 0.9077\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9187 - val_loss: 0.9075\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9186 - val_loss: 0.9074\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9186 - val_loss: 0.9072\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9186 - val_loss: 0.9071\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.9184 - val_loss: 0.9069\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.9185 - val_loss: 0.9067\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.9183 - val_loss: 0.9066\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9184 - val_loss: 0.9064\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9181 - val_loss: 0.9063\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.9181 - val_loss: 0.9061\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.9178 - val_loss: 0.9060\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.9175 - val_loss: 0.9058\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9170 - val_loss: 0.9057\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9170 - val_loss: 0.9055\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9169 - val_loss: 0.9054\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9167 - val_loss: 0.9052\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9166 - val_loss: 0.9051\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9170 - val_loss: 0.9049\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9163 - val_loss: 0.9048\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.9159 - val_loss: 0.9046\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9159 - val_loss: 0.9045\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9155 - val_loss: 0.9043\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9161 - val_loss: 0.9042\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9156 - val_loss: 0.9040\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.9158 - val_loss: 0.9039\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9155 - val_loss: 0.9037\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.9150 - val_loss: 0.9036\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9152 - val_loss: 0.9034\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.9150 - val_loss: 0.9033\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.9146 - val_loss: 0.9031\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9145 - val_loss: 0.9030\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9145 - val_loss: 0.9028\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.9142 - val_loss: 0.9027\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.9144 - val_loss: 0.9025\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9144 - val_loss: 0.9024\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.9140 - val_loss: 0.9022\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.9143 - val_loss: 0.9021\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 0.9136 - val_loss: 0.9019\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9136 - val_loss: 0.9018\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.9131 - val_loss: 0.9016\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.9132 - val_loss: 0.9015\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9130 - val_loss: 0.9013\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9129 - val_loss: 0.9012\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 0.9127 - val_loss: 0.9010\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.9125 - val_loss: 0.9009\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.9119 - val_loss: 0.9007\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.9122 - val_loss: 0.9006\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.9123 - val_loss: 0.9004\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.9123 - val_loss: 0.9003\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.9122 - val_loss: 0.9001\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.9117 - val_loss: 0.9000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.9120 - val_loss: 0.8998\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9120 - val_loss: 0.8997\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.9116 - val_loss: 0.8996\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.9113 - val_loss: 0.8994\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train for wind intensity\n",
        "y_train_wind = np.array([[[features[2]] for features in y] for y in y_train], dtype = np.float64)\n",
        "y_test_wind = np.array([[[features[2]] for features in y] for y in y_test], dtype = np.float64)\n",
        "\n",
        "# Train for latitude and longitude location\n",
        "y_train_lat = np.array([[[features[0]] for features in y] for y in y_train], dtype = np.float64)\n",
        "y_test_lat = np.array([[[features[0]] for features in y] for y in y_test], dtype = np.float64)\n",
        "y_train_long = np.array([[[features[1]] for features in y] for y in y_train], dtype = np.float64)\n",
        "y_test_long = np.array([[[features[1]] for features in y] for y in y_test], dtype = np.float64)\n",
        "\n",
        "# Train for min pressure\n",
        "y_train_pressure = np.array([[[features[4]] for features in y] for y in y_train], dtype = np.float64)\n",
        "y_test_pressure = np.array([[[features[4]] for features in y] for y in y_test], dtype = np.float64)\n",
        "\n",
        "def bd_lstm_td(X_train, y_train, X_test, y_test, n_epochs = 500) :    \n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units = 512, return_sequences = True, dropout = 0.05),\n",
        "                            input_shape = (X_train.shape[1],X_train.shape[2])))\n",
        "    model.add(LSTM(units = 256, return_sequences = True, dropout = 0.05))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    model.compile(loss='mse', optimizer='adadelta')\n",
        "    print(model.summary())\n",
        "    history = model.fit(X_train, y_train, batch_size = len(X_train), epochs = n_epochs,\n",
        "                        validation_data = (X_test, y_test))\n",
        "    return model, history\n",
        "\n",
        "def lstm_td(X_train, X_test, y_train, y_test) :\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = 1024, input_shape = (5,8), return_sequences = True))\n",
        "    model.add(TimeDistributed(Dense(8)))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    print(model.summary())\n",
        "    model.fit(X_train, y_train, batch_size = len(X_train), epochs = 300)\n",
        "    \n",
        "    return model\n",
        "\n",
        "model_wind, model_wind_history = bd_lstm_td(X_train, y_train_wind, X_test, y_test_wind, n_epochs = 500)\n",
        "model_lat, model_lat_history = bd_lstm_td(X_train, y_train_lat, X_test, y_test_lat, n_epochs = 1000)\n",
        "model_long, model_long_history = bd_lstm_td(X_train, y_train_long, X_test, y_test_long, n_epochs = 1000)\n",
        "model_pressure, model_pressure_history = bd_lstm_td(X_train, y_train_pressure, X_test, y_test_pressure, n_epochs = 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X94jTMXFTA6K"
      },
      "source": [
        "## Model Selection<a id=\"Selection\"></a>\n",
        "The following models were compared\n",
        "- Bidirectional LSTM with Time Distributed(Best performance)\n",
        "- LSTM with Time Distributed\n",
        "- MLP\n",
        "- Bidirectional GRU with Time Distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "68by3caOTA6L",
        "outputId": "2ea6c24f-60ee-4b79-9505-b2daedd7dadb",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 0s 3ms/step\n",
            "83/83 [==============================] - 0s 3ms/step\n",
            "83/83 [==============================] - 0s 4ms/step\n",
            "83/83 [==============================] - 0s 3ms/step\n",
            "Wind\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count  13245.000000\n",
              "mean     -13.409345\n",
              "std       26.477203\n",
              "min     -112.422066\n",
              "25%      -32.290502\n",
              "50%      -10.815530\n",
              "75%        6.653621\n",
              "max       58.496304"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d08ccd21-7ed3-4854-8cb9-ca544a842505\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13245.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-13.409345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>26.477203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-112.422066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-32.290502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-10.815530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.653621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>58.496304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d08ccd21-7ed3-4854-8cb9-ca544a842505')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d08ccd21-7ed3-4854-8cb9-ca544a842505 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d08ccd21-7ed3-4854-8cb9-ca544a842505');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "def ai_errors(predictions, observations, history = None) :\n",
        "    '''\n",
        "    PURPOSE: Provide descriptive statistics on the predicted output versus the observed measurments\n",
        "    METHOD:  Take the errors of the predictions and answers and then calculate standard descriptive statistics\n",
        "    INPUT:   predictions - 2D array of predictions of observed output\n",
        "             observations - 2D array measurements of observed output\n",
        "             history - Keras history model for displaying model loss, default is None if not available\n",
        "    OUTPUT:\n",
        "    '''\n",
        "    errors = []\n",
        "    for i in range(len(predictions)) :\n",
        "        for j in range(len(predictions[i])) :\n",
        "            # Calculate errors\n",
        "            error = predictions[i][j] - observations[i][j]\n",
        "            errors.append(error)\n",
        "    \n",
        "    # Display history and erros\n",
        "    plt.figure(1)\n",
        "    plt.hist(errors, bins = 50)\n",
        "    plt.title('error histogram')\n",
        "    plt.xlabel('error')\n",
        "    plt.ylabel('frequency')\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.figure(2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    return pd.DataFrame(errors)\n",
        "\n",
        "# Predict values\n",
        "wind_predictions = model_wind.predict(X_test)\n",
        "lat_predictions = model_lat.predict(X_test)\n",
        "long_predictions = model_long.predict(X_test)\n",
        "pressure_predictions = model_pressure.predict(X_test)\n",
        "# Scale back our predictions\n",
        "# Wind\n",
        "wind_predictions_scaled = [scaler.inverse_transform([[0,0,winds[0],0,0,0,0,0,0,0,0,0] for winds in prediction])\n",
        "                           for prediction in wind_predictions]\n",
        "y_wind_test_scaled = [scaler.inverse_transform([[0,0,winds[0],0,0,0,0,0,0,0,0,0] for winds in observation])\n",
        "                      for observation in y_test_wind]\n",
        "# Latitude\n",
        "lat_predictions_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0,0,0] for lat in prediction])\n",
        "                          for prediction in lat_predictions]\n",
        "y_lat_test_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0,0,0] for lat in observation])\n",
        "                     for observation in y_test_lat]\n",
        "# Longitude\n",
        "long_predictions_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0,0,0] for long in prediction])\n",
        "                           for prediction in long_predictions]\n",
        "y_long_test_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0,0,0] for long in observation])\n",
        "                      for observation in y_test_long]\n",
        "\n",
        "# Wind\n",
        "pressure_predictions_scaled = [scaler.inverse_transform([[0,0,0,0,pressure[0],0,0,0,0,0,0,0] for pressure in prediction])\n",
        "                           for prediction in pressure_predictions]\n",
        "y_pressure_test_scaled = [scaler.inverse_transform([[0,0,0,0,pressure[0],0,0,0,0,0,0,0] for pressure in observation])\n",
        "                      for observation in y_test_pressure]\n",
        "# Record wind predictions and observations\n",
        "print(\"Wind\")\n",
        "wind_predictions = [[pred[2] for pred in hurricanes_pred] for hurricanes_pred in wind_predictions_scaled]\n",
        "wind_observations = [[obsrv[2] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_wind_test_scaled]\n",
        "\n",
        "# Present Errors\n",
        "ai_errors(wind_predictions, wind_observations, model_wind_history).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oB2lPcNjTA6N",
        "outputId": "2e4d3cbd-5dbd-4b9e-f0f5-e7a39fb2cf70",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count  13245.000000\n",
              "mean      -4.894767\n",
              "std        8.493244\n",
              "min      -59.656236\n",
              "25%       -9.663905\n",
              "50%       -4.215882\n",
              "75%        1.152189\n",
              "max       22.164780"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d44edc3e-d161-4dda-a352-fe0d18c28b58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13245.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-4.894767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.493244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-59.656236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-9.663905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.215882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.152189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22.164780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44edc3e-d161-4dda-a352-fe0d18c28b58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d44edc3e-d161-4dda-a352-fe0d18c28b58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d44edc3e-d161-4dda-a352-fe0d18c28b58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "print(\"Lat\")\n",
        "lat_predictions = [[pred[0] for pred in hurricanes_pred] for hurricanes_pred in lat_predictions_scaled]\n",
        "lat_observations = [[obsrv[0] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_lat_test_scaled]\n",
        "ai_errors(lat_predictions, lat_observations, model_lat_history).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eSvYUSOdTA6R",
        "outputId": "f5e87d72-001c-44e5-80c9-3863e5efcf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count  13245.000000\n",
              "mean      -1.005967\n",
              "std       16.325717\n",
              "min     -302.636735\n",
              "25%      -13.290344\n",
              "50%       -2.466685\n",
              "75%       10.201249\n",
              "max       58.890999"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a94d27b-1ee1-4215-97fc-e675aa4afdbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13245.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-1.005967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.325717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-302.636735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-13.290344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.466685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.201249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>58.890999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a94d27b-1ee1-4215-97fc-e675aa4afdbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a94d27b-1ee1-4215-97fc-e675aa4afdbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a94d27b-1ee1-4215-97fc-e675aa4afdbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "print(\"Long\")\n",
        "long_predictions = [[pred[1] for pred in hurricanes_pred] for hurricanes_pred in long_predictions_scaled]\n",
        "long_observations = [[obsrv[1] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_long_test_scaled]\n",
        "ai_errors(long_predictions, long_observations, model_long_history).describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pressure\")\n",
        "pressure_predictions = [[pred[0] for pred in hurricanes_pred] for hurricanes_pred in pressure_predictions_scaled]\n",
        "pressure_observations = [[obsrv[0] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_pressure_test_scaled]\n",
        "ai_errors(pressure_predictions, pressure_observations, model_pressure_history).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aDj6RzPX_LL9",
        "outputId": "5691108e-0a38-4dc5-e2a1-f46eb267b9d0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pressure\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0\n",
              "count  13245.0\n",
              "mean       0.0\n",
              "std        0.0\n",
              "min        0.0\n",
              "25%        0.0\n",
              "50%        0.0\n",
              "75%        0.0\n",
              "max        0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c79098b-7228-43df-ab06-30f2ea1d95a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13245.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c79098b-7228-43df-ab06-30f2ea1d95a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c79098b-7228-43df-ab06-30f2ea1d95a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c79098b-7228-43df-ab06-30f2ea1d95a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynICeA8zTA6V"
      },
      "source": [
        "## Model Evaluation & Benchmarks<a id=\"Benchmarks\"></a>\n",
        "\n",
        "The machine learning neural network will use 2 main methods of applied evaluation. The first will be evaluated compared to the other models that predict Atlantic hurricanes. The forecast errors have been loaded into each hurricane object corresponding to their forecast model; both the OFCL (official track) and the BCD5 (model using multivariate regression). The BCD5 model is \"the CLP5 (track) and DSF5 (intensity) models merged\" that uses the best track as input. BCD5 is similar to OCD5 except for the inputs to the models. The *O* is for operational input while the *B* is for best track input. The best track is only available post-season and is better than the operational input.\n",
        "\n",
        "### References\n",
        "http://www.hurricanecity.com/models/models.cgi?page=models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKQPNFILTA6X",
        "outputId": "97a1cd70-f301-4342-c1c3-90e67fe43329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming 2017 HURDAT2 into objects . . .\n",
            "Transforming 50303/53976 entries from HURDAT2\n",
            "Done!\n",
            "Done with track processing 18/18 storms"
          ]
        }
      ],
      "source": [
        "test_data = hurdat2('data/hurdat2-1851-2017-050118.txt')\n",
        "\n",
        "# Parse in hurricanes\n",
        "hurricanes_2017 = dict()\n",
        "print(\"Transforming 2017 HURDAT2 into objects . . .\")\n",
        "for index, entry in test_data.hurricanes.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset.hurricanes)), end = \"\\r\")\n",
        "    # Filter to capture 2017 data\n",
        "    if entry['storm_id'][-4:] != '2017' :\n",
        "        continue\n",
        "    if entry['storm_id'] not in hurricanes_2017 :\n",
        "        hurricanes_2017[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes_2017[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")\n",
        "\n",
        "# Filter storms that have more than 6 entries. We need at least 6 to calculate 5 speed vectors\n",
        "storms_filter = [storm for storm in hurricanes_2017.values() if len(storm.entries) > 6]\n",
        "\n",
        "# Begin creating hurricane forecast and track predictions\n",
        "tracks = {\n",
        "    'storms' : [], # Reference storm\n",
        "    'inputs' : [], # The inputs for the ai\n",
        "    'valid_times' : [], # The valid time to compare to the error database\n",
        "}\n",
        "for index, storm in enumerate(storms_filter) :\n",
        "    # Create inputs to ai. ai requires scaled data as input\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())] # Extracts data from data structure\n",
        "    \n",
        "    # Scale the entries\n",
        "    for start_index in range(1, len(entries) - 5) : # Go through each entry\n",
        "        # Build feature extraction\n",
        "        extracted_features = []\n",
        "        valid_time = None # Going to be set to the last element in the series\n",
        "        for pivot in range(start_index, start_index + 5) :\n",
        "            extracted_features.append(np.array(list(feature_extraction(entries[pivot], entries[pivot - 1]).values())))\n",
        "            if pivot is start_index + 4 : # We're on the last element\n",
        "                valid_time = entries[pivot]['entry_time']\n",
        "        \n",
        "        # If there's an incomplete value we can't process, skip it\n",
        "        if any(None in entry for entry in extracted_features) :\n",
        "            continue\n",
        "            \n",
        "        # Scale extracted features        \n",
        "        scaled_entries = scaler.transform(extracted_features)\n",
        "        \n",
        "        # Add to our results\n",
        "        tracks['storms'].append(storm)\n",
        "        tracks['inputs'].append(scaled_entries.tolist())\n",
        "        tracks['valid_times'].append(valid_time)\n",
        "        \n",
        "    print(\"\\rDone with track processing {}/{} storms\".format(index + 1, len(storms_filter)), end = '')\n",
        "tracks['inputs'] = np.array(tracks['inputs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63CD4pbTA6b",
        "outputId": "6f3e5ea3-8a45-470e-fdb3-a7ebb9fc7c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 4ms/step\n",
            "16/16 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "tracks['wind_predictions_raw'] = model_wind.predict(tracks['inputs'])\n",
        "tracks['lat_predictions_raw'] = model_lat.predict(tracks['inputs'])\n",
        "tracks['long_predictions_raw'] = model_long.predict(tracks['inputs'])\n",
        "tracks['pressure_predictions_raw'] = model_pressure.predict(tracks['inputs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cGdhct5GTA6c"
      },
      "outputs": [],
      "source": [
        "# Define a function to return the distance between two coordinates in nautical miles\n",
        "import math\n",
        "\n",
        "def distance(origin, destination):\n",
        "    lat1, lon1 = origin\n",
        "    lat2, lon2 = destination\n",
        "    radius = 6371 # km\n",
        "\n",
        "    dlat = math.radians(lat2-lat1)\n",
        "    dlon = math.radians(lon2-lon1)\n",
        "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
        "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
        "    d = radius * c\n",
        "\n",
        "    return d * 0.539957 # km to nautical miles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2Ir6U5L-TA6e"
      },
      "outputs": [],
      "source": [
        "# Scale back and store our wind predictions and our lat, long predictions\n",
        "tracks['wind_predictions'] = []\n",
        "tracks['lat_predictions'] = []\n",
        "tracks['long_predictions'] = []\n",
        "tracks['pressure_predictions'] = []\n",
        "intensity_errors = {\n",
        "    '24' : [],\n",
        "    '48' : [],\n",
        "    '72' : [],\n",
        "    '96' : [],\n",
        "    '120' : []\n",
        "}\n",
        "track_errors = {\n",
        "    '24' : [],\n",
        "    '48' : [],\n",
        "    '72' : [],\n",
        "    '96' : [],\n",
        "    '120' : []\n",
        "}\n",
        "pressure_errors = {\n",
        "    '24' : [],\n",
        "    '48' : [],\n",
        "    '72' : [],\n",
        "    '96' : [],\n",
        "    '120' : []\n",
        "}\n",
        "for index, prediction in enumerate(tracks['wind_predictions_raw']) :\n",
        "    # Use our standard scaler to scale the raw predictions back\n",
        "    winds_scaled = [scaler.inverse_transform([[0,0,winds[0],0,0,0,0,0,0,0,0,0] for winds in prediction])] # Index 2 is winds\n",
        "    lat_scaled = [scaler.inverse_transform([[lats[0],0,0,0,0,0,0,0,0,0,0,0] for lats in tracks['lat_predictions_raw'][index]])] # Index 0 is lat\n",
        "    long_scaled = [scaler.inverse_transform([[0,longs[0],0,0,0,0,0,0,0,0,0,0] for longs in tracks['long_predictions_raw'][index]])] # Index 1 is long\n",
        "    pressure_scaled = [scaler.inverse_transform([[0,0,0,0,pressure[0],0,0,0,0,0,0,0] for pressure in tracks['pressure_predictions_raw'][index]])]\n",
        "    # Extract the wind prediction from data structure and store into new data structure\n",
        "    for i in range(len(winds_scaled)) :        \n",
        "        # The new data structure is a tuple of (wind, storm_id, valid_time, forecast_time)\n",
        "        wind_predictions = []\n",
        "        lat_predictions = []\n",
        "        long_predictions = []\n",
        "        pressure_predictions = []\n",
        "        for step, pred in enumerate(winds_scaled[i]) :\n",
        "            wind = pred[2]\n",
        "            lat = lat_scaled[i][step][0]\n",
        "            long = long_scaled[i][step][1]\n",
        "            pressure = pressure_scaled[i][step][4]\n",
        "            storm_id = tracks['storms'][index].id\n",
        "            valid_time = tracks['valid_times'][index]\n",
        "            forecast_time = valid_time + datetime.timedelta(days = step + 1)\n",
        "            \n",
        "            # See if we can find the error\n",
        "            if forecast_time in hurricanes_2017[storm_id].entries :\n",
        "                wind_truth = hurricanes_2017[storm_id].entries[forecast_time]['max_wind']\n",
        "                lat_truth = hurricanes_2017[storm_id].entries[forecast_time]['lat']\n",
        "                long_truth = hurricanes_2017[storm_id].entries[forecast_time]['long']\n",
        "                pressure_truth = hurricanes_2017[storm_id].entries[forecast_time]['min_pressure']\n",
        "                intensity_error = abs(wind_truth - wind)\n",
        "                track_error = distance((lat_truth,long_truth), (lat, long))\n",
        "                pressure_error = abs(pressure_truth - pressure)\n",
        "\n",
        "                wind_predictions.append({\n",
        "                    'ai-wind' : wind,\n",
        "                    'truth' : wind_truth,\n",
        "                    'storm_id' : storm_id,\n",
        "                    'valid_time' : valid_time,\n",
        "                    'forecast_time' : forecast_time\n",
        "                })\n",
        "                lat_predictions.append({\n",
        "                    'ai-lat' : lat,\n",
        "                    'truth' : lat_truth,\n",
        "                    'storm_id' : storm_id,\n",
        "                    'valid_time' : valid_time,\n",
        "                    'forecast_time' : forecast_time\n",
        "                })\n",
        "                long_predictions.append({\n",
        "                    'ai-long' : long,\n",
        "                    'truth' : long_truth,\n",
        "                    'storm_id' : storm_id,\n",
        "                    'valid_time' : valid_time,\n",
        "                    'forecast_time' : forecast_time\n",
        "                })\n",
        "                pressure_predictions.append({\n",
        "                    'ai-pressure' : pressure,\n",
        "                    'truth' : pressure_truth,\n",
        "                    'storm_id' : storm_id,\n",
        "                    'valid_time' : valid_time,\n",
        "                    'forecast_time' : forecast_time\n",
        "                })\n",
        "                if step == 0 :\n",
        "                    intensity_errors['24'].append(intensity_error)\n",
        "                    track_errors['24'].append(track_error)\n",
        "                    pressure_errors['24'].append(pressure_error)\n",
        "                if step == 1 :\n",
        "                    intensity_errors['48'].append(intensity_error)\n",
        "                    track_errors['48'].append(track_error)\n",
        "                    pressure_errors['48'].append(pressure_error)\n",
        "                if step == 2 :\n",
        "                    intensity_errors['72'].append(intensity_error)\n",
        "                    track_errors['72'].append(track_error)\n",
        "                    pressure_errors['72'].append(pressure_error)\n",
        "                if step == 3 :\n",
        "                    intensity_errors['96'].append(intensity_error)\n",
        "                    track_errors['96'].append(track_error)\n",
        "                    pressure_errors['96'].append(pressure_error)\n",
        "                if step == 4 :\n",
        "                    intensity_errors['120'].append(intensity_error)\n",
        "                    track_errors['120'].append(track_error)\n",
        "                    pressure_errors['120'].append(pressure_error)\n",
        "                    \n",
        "        tracks['wind_predictions'].append(wind_predictions)\n",
        "        tracks['lat_predictions'].append(lat_predictions)\n",
        "        tracks['long_predictions'].append(long_predictions)\n",
        "        tracks['pressure_predictions'].append(pressure_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TlOkSiHUTA6h",
        "outputId": "b0340acb-b114-44bc-bfbb-14489d20cc96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  432.000000\n",
              "mean    26.258872\n",
              "std     21.222358\n",
              "min      0.109277\n",
              "25%     12.284898\n",
              "50%     20.678690\n",
              "75%     32.092721\n",
              "max     97.282073"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3623c341-685a-493a-8f36-bac913fb6690\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>432.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.258872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>21.222358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.109277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.284898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20.678690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>32.092721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>97.282073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3623c341-685a-493a-8f36-bac913fb6690')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3623c341-685a-493a-8f36-bac913fb6690 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3623c341-685a-493a-8f36-bac913fb6690');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "pd.DataFrame(intensity_errors['24']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "epSK3WCiTA6j",
        "outputId": "b2febe50-50bb-42a6-d6d2-975ce0b01487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  378.000000\n",
              "mean    26.495488\n",
              "std     20.622115\n",
              "min      0.058209\n",
              "25%     11.813177\n",
              "50%     23.054299\n",
              "75%     32.213285\n",
              "max    100.619318"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5acd7efe-d49a-4ad1-87bc-b198b9e25aa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>378.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.495488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.622115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.058209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.813177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>23.054299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>32.213285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.619318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5acd7efe-d49a-4ad1-87bc-b198b9e25aa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5acd7efe-d49a-4ad1-87bc-b198b9e25aa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5acd7efe-d49a-4ad1-87bc-b198b9e25aa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "pd.DataFrame(intensity_errors['48']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-c_0j5MzTA6l",
        "outputId": "43c36241-43b4-4869-c779-bb5442d27b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  327.000000\n",
              "mean    26.351545\n",
              "std     20.785840\n",
              "min      0.045458\n",
              "25%     12.027475\n",
              "50%     22.979993\n",
              "75%     33.841660\n",
              "max    106.461050"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec2dbc5-65af-427f-85b8-27e32cd2a1ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>327.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.351545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.785840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.045458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.027475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.979993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>33.841660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>106.461050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec2dbc5-65af-427f-85b8-27e32cd2a1ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec2dbc5-65af-427f-85b8-27e32cd2a1ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec2dbc5-65af-427f-85b8-27e32cd2a1ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pd.DataFrame(intensity_errors['72']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6-IRvW50TA6o",
        "outputId": "fc258eb5-cd22-4bb7-d8cd-16a5d0edaccc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  285.000000\n",
              "mean    26.094815\n",
              "std     20.605806\n",
              "min      0.139327\n",
              "25%     10.659015\n",
              "50%     22.738690\n",
              "75%     35.412714\n",
              "max    103.568124"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee396c30-7394-4c61-bf1e-16614da92f7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>285.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.094815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.605806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.139327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.659015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.738690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.412714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>103.568124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee396c30-7394-4c61-bf1e-16614da92f7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee396c30-7394-4c61-bf1e-16614da92f7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee396c30-7394-4c61-bf1e-16614da92f7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pd.DataFrame(intensity_errors['96']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "G-ZM0xu8TA6s",
        "outputId": "2b46fcd9-0eec-4458-fb88-1c2b57e7313e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  249.000000\n",
              "mean    26.473893\n",
              "std     20.872034\n",
              "min      0.108917\n",
              "25%     12.095644\n",
              "50%     22.256831\n",
              "75%     34.335815\n",
              "max     96.576952"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d1a2d80-6659-4004-ad2c-dc7a6b6fe077\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>249.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.473893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.872034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.108917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.095644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.256831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>34.335815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.576952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d1a2d80-6659-4004-ad2c-dc7a6b6fe077')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d1a2d80-6659-4004-ad2c-dc7a6b6fe077 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d1a2d80-6659-4004-ad2c-dc7a6b6fe077');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pd.DataFrame(intensity_errors['120']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "lCERfJiJTA6w",
        "outputId": "9f52519a-f2d7-428c-ef45-e685be74474f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   432.000000\n",
              "mean   1120.597827\n",
              "std     530.597949\n",
              "min     170.722294\n",
              "25%     727.872449\n",
              "50%    1085.225060\n",
              "75%    1495.890501\n",
              "max    3097.377671"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77e68601-c8ab-46c6-87af-709fbd043ba8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>432.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1120.597827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>530.597949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>170.722294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>727.872449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1085.225060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1495.890501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3097.377671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77e68601-c8ab-46c6-87af-709fbd043ba8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77e68601-c8ab-46c6-87af-709fbd043ba8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77e68601-c8ab-46c6-87af-709fbd043ba8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "pd.DataFrame(track_errors['24']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_c4Jc9hBTA60",
        "outputId": "0a4e8585-2237-4c70-b919-9369b7c65738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   378.000000\n",
              "mean   1062.956288\n",
              "std     512.665605\n",
              "min     240.533054\n",
              "25%     671.473075\n",
              "50%     986.757976\n",
              "75%    1417.519458\n",
              "max    2913.495521"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e5adbcb-f606-4f52-bc83-22d81b97e2c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>378.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1062.956288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>512.665605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>240.533054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>671.473075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>986.757976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1417.519458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2913.495521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e5adbcb-f606-4f52-bc83-22d81b97e2c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e5adbcb-f606-4f52-bc83-22d81b97e2c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e5adbcb-f606-4f52-bc83-22d81b97e2c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "pd.DataFrame(track_errors['48']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40GaDhbcTA63"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(track_errors['72']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "GaulJVPBTA66",
        "outputId": "715d1899-d3e2-4a32-b43e-49ceac34a68c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   285.000000\n",
              "mean   1123.232716\n",
              "std     543.077360\n",
              "min     275.588315\n",
              "25%     672.551118\n",
              "50%     971.124601\n",
              "75%    1510.764970\n",
              "max    2784.702670"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66dddfe7-a7a4-4118-b234-085258c600e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>285.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1123.232716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>543.077360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>275.588315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>672.551118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>971.124601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1510.764970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2784.702670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66dddfe7-a7a4-4118-b234-085258c600e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66dddfe7-a7a4-4118-b234-085258c600e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66dddfe7-a7a4-4118-b234-085258c600e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "pd.DataFrame(track_errors['96']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "M_lHpN7tTA69",
        "outputId": "2270c441-27a3-4e34-f334-1e2369cd6ec0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   249.000000\n",
              "mean   1040.742563\n",
              "std     548.818147\n",
              "min     104.048288\n",
              "25%     648.050598\n",
              "50%     880.520179\n",
              "75%    1450.400398\n",
              "max    2722.075201"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27f49adb-e59b-4a22-84d9-69f02923bace\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>249.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1040.742563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>548.818147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>104.048288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>648.050598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>880.520179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1450.400398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2722.075201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27f49adb-e59b-4a22-84d9-69f02923bace')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27f49adb-e59b-4a22-84d9-69f02923bace button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27f49adb-e59b-4a22-84d9-69f02923bace');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "pd.DataFrame(track_errors['120']).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRbJiBIjTA6_",
        "outputId": "8d7f4302-6a22-4cc4-ea58-f43c5c68110c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found AL012017 at 2017-04-20 06:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 49.922380722127855, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 40.0, 46.3; AI forecast: 23.89686279296875, 62.11983085470274 ; AI error: 1254.5389965116417 BCD5 error: 391.5\n",
            "Found AL012017 at 2017-04-20 12:00:00\n",
            "Found AL012017 at 2017-04-20 18:00:00\n",
            "Found AL012017 at 2017-04-21 00:00:00\n",
            "Found AL012017 at 2017-04-21 06:00:00\n",
            "Found AL032017 at 2017-06-21 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 52.79898256063461, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 28.5, 93.4; AI forecast: 23.482796239852906, 63.98878446668386 ; AI error: 1611.3780048772726 BCD5 error: 42.6\n",
            "Found AL032017 at 2017-06-21 06:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 51.46492660045624, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 23.03698847293854, 64.09069722220302 ; AI error: 1629.947845976139 BCD5 error: 36.6\n",
            "Found AL032017 at 2017-06-21 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 52.06330478191376, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 30.5, 93.8; AI forecast: 23.251570320129396, 64.02738157510757 ; AI error: 1647.3670463056826 BCD5 error: 99.9\n",
            "Found AL032017 at 2017-06-21 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 51.29074230790138, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 31.6, 93.8; AI forecast: 23.000065565109253, 63.997475840896364 ; AI error: 1665.5511203559136 BCD5 error: 106.4\n",
            "Found AL032017 at 2017-06-22 00:00:00\n",
            "Found AL032017 at 2017-06-22 06:00:00\n",
            "Found AL032017 at 2017-06-22 12:00:00\n",
            "Found AL032017 at 2017-06-22 18:00:00\n",
            "Found AL062017 at 2017-07-31 18:00:00\n",
            "Found AL072017 at 2017-08-08 00:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 53.348022401332855, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 20.2, 90.9; AI forecast: 22.485240030288697, 63.50131261236965 ; AI error: 1536.2338206262252 BCD5 error: 24.0\n",
            "\tIntensity Truth: 75.0, AI forecast: 56.27919614315033, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 20.3, 95.5; AI forecast: 24.33876242637634, 64.35878893509506 ; AI error: 1742.9142033390565 BCD5 error: 133.4\n",
            "Found AL072017 at 2017-08-08 06:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 52.98505276441574, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 20.4, 92.2; AI forecast: 22.280921936035156, 63.54497709274292 ; AI error: 1604.1117718256376 BCD5 error: 28.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 55.94505786895752, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 20.0, 96.8; AI forecast: 23.975550174713135, 64.57640777751803 ; AI error: 1805.8940971508496 BCD5 error: 160.4\n",
            "Found AL072017 at 2017-08-08 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 52.83584117889404, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 20.2, 93.3; AI forecast: 22.19928722381592, 63.63517358973622 ; AI error: 1662.2915061522172 BCD5 error: 78.2\n",
            "Found AL072017 at 2017-08-08 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 52.118801176548004, BCD5 forecast: -31.0\n",
            "\tTrajectory Truth: 20.2, 94.4; AI forecast: 22.088651013374328, 63.75676719844341 ; AI error: 1716.874880091917 BCD5 error: 86.3\n",
            "Found AL072017 at 2017-08-09 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 49.40212469547987, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 20.3, 95.5; AI forecast: 21.175282937288284, 64.08004418984055 ; AI error: 1762.1619024340753 BCD5 error: 58.6\n",
            "Found AL072017 at 2017-08-09 06:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 48.8849775493145, BCD5 forecast: 19.0\n",
            "\tTrajectory Truth: 20.0, 96.8; AI forecast: 21.24984985589981, 63.9351277962327 ; AI error: 1844.9930464060392 BCD5 error: 41.1\n",
            "Found AL072017 at 2017-08-09 12:00:00\n",
            "Found AL082017 at 2017-08-13 06:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 49.654403291642666, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 29.2, 72.1; AI forecast: 21.865866959095, 62.61592069985345 ; AI error: 676.159149225803 BCD5 error: 16.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.25327576696873, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 31.5, 72.3; AI forecast: 23.048244571685792, 62.66553315268829 ; AI error: 721.7039649070351 BCD5 error: 73.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.107700660824776, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 35.4, 69.5; AI forecast: 24.144839763641357, 62.49949905155226 ; AI error: 767.3796284007063 BCD5 error: 7.7\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.542627818882465, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 40.7, 56.2; AI forecast: 25.342476654052735, 62.14071621419862 ; AI error: 968.7195196290312 BCD5 error: 529.1\n",
            "Found AL082017 at 2017-08-13 12:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 49.743566792458296, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 29.7, 72.2; AI forecast: 21.993938398361205, 62.43311173701659 ; AI error: 701.2410284748464 BCD5 error: 37.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.602054841816425, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 32.3, 72.1; AI forecast: 23.396144723892213, 62.30387956734048 ; AI error: 745.0453902830769 BCD5 error: 85.2\n",
            "\tIntensity Truth: 85.0, AI forecast: 49.95118161197752, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 36.8, 67.1; AI forecast: 24.92783064842224, 61.944071031361815 ; AI error: 760.3766055672346 BCD5 error: 80.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.638345800340176, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 42.2, 52.0; AI forecast: 25.97073702812195, 61.55746643990278 ; AI error: 1082.3946320263874 BCD5 error: 673.2\n",
            "Found AL082017 at 2017-08-13 18:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 50.00748404767364, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 30.2, 72.3; AI forecast: 22.248878145217894, 62.22707596817054 ; AI error: 721.9947964156505 BCD5 error: 52.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.36062214523554, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 33.2, 71.8; AI forecast: 24.12647318840027, 61.87751412186771 ; AI error: 754.1902424663875 BCD5 error: 71.7\n",
            "\tIntensity Truth: 95.0, AI forecast: 49.978022328577936, BCD5 forecast: -39.0\n",
            "\tTrajectory Truth: 38.2, 64.1; AI forecast: 25.516405868530274, 61.47802134230733 ; AI error: 773.0756620880484 BCD5 error: 213.5\n",
            "Found AL082017 at 2017-08-14 00:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.903670117259026, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 30.8, 72.3; AI forecast: 22.88056883811951, 61.9847514340654 ; AI error: 728.3108376567898 BCD5 error: 49.2\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.004393473267555, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 34.2, 71.0; AI forecast: 24.791255760192872, 61.540960421971974 ; AI error: 749.8372611568269 BCD5 error: 39.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 51.10110357403755, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 39.4, 60.4; AI forecast: 26.301140785217285, 61.093853294476865 ; AI error: 787.2324378833634 BCD5 error: 375.7\n",
            "Found AL082017 at 2017-08-14 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.55408027023077, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.5, 72.3; AI forecast: 22.73686628341675, 61.875445033982395 ; AI error: 765.4490973883669 BCD5 error: 31.2\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.101885959506035, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 35.4, 69.5; AI forecast: 24.671349477767944, 61.36832847930491 ; AI error: 769.7129451172378 BCD5 error: 74.5\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.82304635643959, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 40.7, 56.2; AI forecast: 26.23111515045166, 60.87192354612052 ; AI error: 899.3025465013757 BCD5 error: 577.1\n",
            "Found AL082017 at 2017-08-14 12:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.33919134736061, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 32.3, 72.1; AI forecast: 22.901000714302064, 61.77829793598502 ; AI error: 786.5522717107572 BCD5 error: 23.6\n",
            "\tIntensity Truth: 85.0, AI forecast: 52.75231510400772, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 36.8, 67.1; AI forecast: 24.9630343914032, 61.198287831991905 ; AI error: 772.5711970719402 BCD5 error: 208.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 55.71931064128876, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 42.2, 52.0; AI forecast: 27.316017818450927, 60.64554758816957 ; AI error: 988.8587793950315 BCD5 error: 783.0\n",
            "Found AL082017 at 2017-08-14 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 52.62855976819992, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 33.2, 71.8; AI forecast: 23.097464656829835, 61.65465400163084 ; AI error: 809.2086240450606 BCD5 error: 31.6\n",
            "\tIntensity Truth: 95.0, AI forecast: 56.677706837654114, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 38.2, 64.1; AI forecast: 26.047017812728882, 60.96937853097916 ; AI error: 746.6930873935675 BCD5 error: 320.0\n",
            "Found AL082017 at 2017-08-15 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 55.34978628158569, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 34.2, 71.0; AI forecast: 24.01602840423584, 61.56967232916504 ; AI error: 785.6306338437366 BCD5 error: 37.4\n",
            "\tIntensity Truth: 90.0, AI forecast: 59.89225089550018, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 39.4, 60.4; AI forecast: 27.209780406951904, 60.86812260076403 ; AI error: 732.2802077899827 BCD5 error: 436.5\n",
            "Found AL082017 at 2017-08-15 06:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 55.93783438205719, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 35.4, 69.5; AI forecast: 24.01796336174011, 61.52548534739762 ; AI error: 799.2213198830592 BCD5 error: 72.4\n",
            "\tIntensity Truth: 80.0, AI forecast: 61.43258452415466, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 40.7, 56.2; AI forecast: 27.3658540725708, 60.822047932073474 ; AI error: 832.6195458294866 BCD5 error: 559.8\n",
            "Found AL082017 at 2017-08-15 12:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 56.82120084762573, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 36.8, 67.1; AI forecast: 24.168900060653687, 61.50702075753361 ; AI error: 811.2764762103131 BCD5 error: 141.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 63.20681810379028, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 42.2, 52.0; AI forecast: 27.848410511016844, 60.75604512095451 ; AI error: 961.9272559515068 BCD5 error: 655.2\n",
            "Found AL082017 at 2017-08-15 18:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 57.576733231544495, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 38.2, 64.1; AI forecast: 24.508165502548216, 61.440845461189745 ; AI error: 833.1808804098326 BCD5 error: 208.2\n",
            "Found AL082017 at 2017-08-16 00:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 56.57330811023712, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 39.4, 60.4; AI forecast: 24.397934341430663, 61.31732585728168 ; AI error: 901.9290438866832 BCD5 error: 221.8\n",
            "Found AL082017 at 2017-08-16 06:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 57.2318559885025, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 40.7, 56.2; AI forecast: 24.769786310195922, 61.13330366834998 ; AI error: 987.9166699045976 BCD5 error: 196.0\n",
            "Found AL082017 at 2017-08-16 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 55.77611744403839, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 42.2, 52.0; AI forecast: 24.44555058479309, 60.869165644049644 ; AI error: 1153.4883240107556 BCD5 error: 155.3\n",
            "Found AL082017 at 2017-08-16 18:00:00\n",
            "Found AL082017 at 2017-08-17 00:00:00\n",
            "Found AL082017 at 2017-08-17 06:00:00\n",
            "Found AL082017 at 2017-08-17 12:00:00\n",
            "Found AL092017 at 2017-08-17 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 50.66109985113144, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 13.2, 62.2; AI forecast: 20.52633308507502, 63.26323587596416 ; AI error: 444.0913598366482 BCD5 error: 66.7\n",
            "Found AL092017 at 2017-08-18 00:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 50.185318905860186, BCD5 forecast: 21.0\n",
            "\tTrajectory Truth: 13.4, 64.0; AI forecast: 20.627551421523094, 63.23022648543119 ; AI error: 436.1865290629854 BCD5 error: 59.6\n",
            "Found AL092017 at 2017-08-18 06:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 51.75894379615784, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 13.5, 65.7; AI forecast: 20.922689205408098, 63.42438390813768 ; AI error: 464.34537716327645 BCD5 error: 34.3\n",
            "Found AL092017 at 2017-08-18 12:00:00\n",
            "Found AL092017 at 2017-08-18 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 45.29203563928604, BCD5 forecast: 52.0\n",
            "\tTrajectory Truth: 21.6, 92.4; AI forecast: 18.27697882652283, 66.34729129225015 ; AI error: 1482.1575834414305 BCD5 error: 314.4\n",
            "Found AL092017 at 2017-08-19 00:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 46.16486668586731, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 22.0, 92.5; AI forecast: 18.576288414001464, 66.27540105730294 ; AI error: 1489.2194983504335 BCD5 error: 282.0\n",
            "Found AL092017 at 2017-08-19 06:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.2849947810173, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 22.8, 92.6; AI forecast: 18.725899982452393, 66.33217568844556 ; AI error: 1492.783460193612 BCD5 error: 211.9\n",
            "Found AL092017 at 2017-08-23 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.25103719905019, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 24.4, 93.6; AI forecast: 21.694691479206085, 63.41556967310607 ; AI error: 1672.274918856144 BCD5 error: 87.0\n",
            "\tIntensity Truth: 105.0, AI forecast: 51.101718842983246, BCD5 forecast: -39.0\n",
            "\tTrajectory Truth: 27.1, 96.3; AI forecast: 22.967376399040223, 64.33889527991414 ; AI error: 1751.5863429900278 BCD5 error: 221.0\n",
            "\tIntensity Truth: 50.0, AI forecast: 51.899563670158386, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 29.0, 97.5; AI forecast: 23.987791109085084, 65.09104980230332 ; AI error: 1761.6770749684815 BCD5 error: 263.5\n",
            "\tIntensity Truth: 35.0, AI forecast: 53.169315457344055, BCD5 forecast: 20.0\n",
            "\tTrajectory Truth: 29.0, 97.2; AI forecast: 24.916116762161256, 65.62794962227345 ; AI error: 1702.2358546311157 BCD5 error: 231.1\n",
            "\tIntensity Truth: 40.0, AI forecast: 53.75972002744675, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 28.4, 95.9; AI forecast: 25.36715111732483, 65.96607709676027 ; AI error: 1609.207832518796 BCD5 error: 251.5\n",
            "Found AL092017 at 2017-08-24 00:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.22674874961376, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 25.0, 94.4; AI forecast: 22.206918239593506, 63.413018302619456 ; AI error: 1709.3887316166738 BCD5 error: 89.3\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.3561629652977, BCD5 forecast: -47.0\n",
            "\tTrajectory Truth: 27.8, 96.8; AI forecast: 23.646661806106568, 64.3437113456428 ; AI error: 1768.0560769982237 BCD5 error: 225.3\n",
            "\tIntensity Truth: 45.0, AI forecast: 53.94253611564636, BCD5 forecast: 21.0\n",
            "\tTrajectory Truth: 29.2, 97.4; AI forecast: 25.00704140663147, 65.0482544593513 ; AI error: 1741.8138967184802 BCD5 error: 243.4\n",
            "\tIntensity Truth: 35.0, AI forecast: 54.84551548957825, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 28.8, 96.8; AI forecast: 25.898386573791505, 65.5348381690681 ; AI error: 1671.6619959898474 BCD5 error: 272.5\n",
            "\tIntensity Truth: 40.0, AI forecast: 56.16823971271515, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.2, 95.4; AI forecast: 26.760128593444826, 65.73630345910787 ; AI error: 1578.5299961439277 BCD5 error: 347.6\n",
            "Found AL092017 at 2017-08-24 06:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 52.02941879630089, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 25.6, 95.1; AI forecast: 22.41166224479675, 63.38052543699741 ; AI error: 1746.1179543300864 BCD5 error: 92.7\n",
            "\tIntensity Truth: 105.0, AI forecast: 54.50552135705948, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 28.2, 97.1; AI forecast: 24.32081608772278, 64.21066091656685 ; AI error: 1780.710022060406 BCD5 error: 190.4\n",
            "\tIntensity Truth: 40.0, AI forecast: 56.38136684894562, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 29.3, 97.6; AI forecast: 25.827233409881593, 64.81244770884514 ; AI error: 1751.8757988843677 BCD5 error: 223.3\n",
            "\tIntensity Truth: 40.0, AI forecast: 58.811407685279846, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 28.6, 96.5; AI forecast: 27.410402488708495, 65.07608076930046 ; AI error: 1662.5529353267248 BCD5 error: 300.0\n",
            "\tIntensity Truth: 40.0, AI forecast: 62.25683093070984, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.1, 95.0; AI forecast: 29.195363235473632, 64.99717296734453 ; AI error: 1577.9541558515234 BCD5 error: 399.4\n",
            "Found AL092017 at 2017-08-24 12:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 54.0487739443779, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 26.3, 95.8; AI forecast: 23.073441076278687, 63.151284294202924 ; AI error: 1786.9161606529974 BCD5 error: 65.6\n",
            "\tIntensity Truth: 65.0, AI forecast: 57.464895248413086, BCD5 forecast: 20.0\n",
            "\tTrajectory Truth: 28.7, 97.3; AI forecast: 25.283989667892456, 63.77217907905578 ; AI error: 1799.5820287030658 BCD5 error: 100.0\n",
            "\tIntensity Truth: 35.0, AI forecast: 61.51372671127319, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 29.1, 97.5; AI forecast: 27.62142734527588, 64.01672090068459 ; AI error: 1765.3708643282253 BCD5 error: 129.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 66.67437791824341, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.5, 96.2; AI forecast: 30.345481681823728, 63.82473010011017 ; AI error: 1691.0347719449446 BCD5 error: 246.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 71.17041110992432, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 94.6; AI forecast: 32.825507736206056, 63.579040401801464 ; AI error: 1622.4737245946326 BCD5 error: 354.9\n",
            "Found AL092017 at 2017-08-24 18:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 54.79412704706192, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 27.1, 96.3; AI forecast: 23.10124478340149, 62.89613828081637 ; AI error: 1826.6569235250113 BCD5 error: 40.1\n",
            "\tIntensity Truth: 50.0, AI forecast: 60.184489488601685, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 29.0, 97.5; AI forecast: 25.896769046783447, 63.139212092012166 ; AI error: 1833.8821527863738 BCD5 error: 33.9\n",
            "\tIntensity Truth: 35.0, AI forecast: 66.71419858932495, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 29.0, 97.2; AI forecast: 29.19591865539551, 62.95242852289229 ; AI error: 1790.263141629022 BCD5 error: 88.5\n",
            "\tIntensity Truth: 40.0, AI forecast: 72.7074384689331, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.4, 95.9; AI forecast: 32.48729839324951, 62.641279506031424 ; AI error: 1731.9236643123277 BCD5 error: 239.6\n",
            "\tIntensity Truth: 45.0, AI forecast: 74.71654891967773, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.5, 94.2; AI forecast: 34.18338527679443, 62.76862148735672 ; AI error: 1640.6673700970057 BCD5 error: 342.7\n",
            "Found AL092017 at 2017-08-25 00:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 56.882450580596924, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 27.8, 96.8; AI forecast: 23.728565216064453, 62.53630468463525 ; AI error: 1862.774725064874 BCD5 error: 42.3\n",
            "\tIntensity Truth: 45.0, AI forecast: 64.7909688949585, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 29.2, 97.4; AI forecast: 27.546001720428468, 62.3780296263285 ; AI error: 1846.0009120718457 BCD5 error: 79.4\n",
            "\tIntensity Truth: 35.0, AI forecast: 72.09391832351685, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 28.8, 96.8; AI forecast: 31.44199342727661, 62.11525375032797 ; AI error: 1800.8485511481451 BCD5 error: 188.1\n",
            "\tIntensity Truth: 40.0, AI forecast: 75.41271448135376, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 95.4; AI forecast: 33.85119075775147, 62.263553614181 ; AI error: 1730.570003366502 BCD5 error: 337.7\n",
            "\tIntensity Truth: 45.0, AI forecast: 76.18032455444336, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.9, 93.8; AI forecast: 34.983358192443845, 62.74380732495337 ; AI error: 1616.9358373725318 BCD5 error: 409.9\n",
            "Found AL092017 at 2017-08-25 06:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 59.838687777519226, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 28.2, 97.1; AI forecast: 24.66055850982666, 62.17026384929195 ; AI error: 1883.5601309418696 BCD5 error: 32.0\n",
            "\tIntensity Truth: 40.0, AI forecast: 69.03865575790405, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 29.3, 97.6; AI forecast: 29.22111415863037, 61.929832672420886 ; AI error: 1860.9793104528542 BCD5 error: 90.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 74.16213035583496, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.6, 96.5; AI forecast: 32.41491756439209, 62.00620683738961 ; AI error: 1791.2159910872485 BCD5 error: 263.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 76.65884256362915, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.1, 95.0; AI forecast: 34.44626712799072, 62.37814592281356 ; AI error: 1709.0109567911206 BCD5 error: 415.5\n",
            "\tIntensity Truth: 40.0, AI forecast: 78.41570854187012, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 35.745222091674805, 62.73780086133629 ; AI error: 1600.1673077329554 BCD5 error: 450.7\n",
            "Found AL092017 at 2017-08-25 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 62.05214738845825, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 28.7, 97.3; AI forecast: 25.562284088134767, 62.10622573355212 ; AI error: 1883.2329713392705 BCD5 error: 28.9\n",
            "\tIntensity Truth: 35.0, AI forecast: 70.23627996444702, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 29.1, 97.5; AI forecast: 29.77228097915649, 61.98744401121512 ; AI error: 1849.96796831355 BCD5 error: 139.5\n",
            "\tIntensity Truth: 40.0, AI forecast: 75.52263021469116, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.5, 96.2; AI forecast: 32.980345726013184, 62.05191733250394 ; AI error: 1774.7737113754854 BCD5 error: 329.1\n",
            "\tIntensity Truth: 40.0, AI forecast: 79.8864483833313, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 94.6; AI forecast: 35.649461555480954, 62.02648984575644 ; AI error: 1710.4770479643387 BCD5 error: 473.7\n",
            "\tIntensity Truth: 40.0, AI forecast: 83.6741042137146, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 30.1, 93.4; AI forecast: 37.750342750549315, 62.32780178860994 ; AI error: 1606.3196020380017 BCD5 error: 456.3\n",
            "Found AL092017 at 2017-08-25 18:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 60.758235454559326, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 29.0, 97.5; AI forecast: 24.86249737739563, 62.36160674029961 ; AI error: 1890.3617624080714 BCD5 error: 49.5\n",
            "\tIntensity Truth: 35.0, AI forecast: 68.6211609840393, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 29.0, 97.2; AI forecast: 28.70555095672607, 62.50720053398982 ; AI error: 1817.8096667131435 BCD5 error: 202.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 75.291006565094, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.4, 95.9; AI forecast: 32.22868900299072, 62.438111800048496 ; AI error: 1742.5004110127309 BCD5 error: 396.3\n",
            "\tIntensity Truth: 45.0, AI forecast: 81.10558271408081, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.5, 94.2; AI forecast: 35.45368137359619, 62.467222172114994 ; AI error: 1661.3781518536675 BCD5 error: 526.4\n",
            "\tIntensity Truth: 35.0, AI forecast: 80.79752445220947, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 30.6, 93.1; AI forecast: 36.367400550842284, 63.05949957128614 ; AI error: 1537.0116408024578 BCD5 error: 485.9\n",
            "Found AL092017 at 2017-08-26 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 59.67137813568115, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 29.2, 97.4; AI forecast: 24.433185148239136, 62.67565702134743 ; AI error: 1875.691053217847 BCD5 error: 71.1\n",
            "\tIntensity Truth: 35.0, AI forecast: 68.46751928329468, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 28.8, 96.8; AI forecast: 28.561637783050536, 62.834879719652236 ; AI error: 1782.9365649254564 BCD5 error: 236.8\n",
            "\tIntensity Truth: 40.0, AI forecast: 76.36503458023071, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 95.4; AI forecast: 32.72635192871094, 62.94550804924219 ; AI error: 1694.7193083515876 BCD5 error: 462.1\n",
            "\tIntensity Truth: 45.0, AI forecast: 77.74621963500977, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.9, 93.8; AI forecast: 34.51670398712158, 63.50607057884335 ; AI error: 1577.4209138085664 BCD5 error: 587.5\n",
            "Found AL092017 at 2017-08-26 06:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 61.71044588088989, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 29.3, 97.6; AI forecast: 26.221525478363038, 63.2259214580059 ; AI error: 1829.137348926043 BCD5 error: 55.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 67.00416803359985, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.6, 96.5; AI forecast: 29.985282516479494, 64.03487373366951 ; AI error: 1696.3634943058155 BCD5 error: 243.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 69.65257167816162, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.1, 95.0; AI forecast: 32.576998710632324, 64.87562952190638 ; AI error: 1578.5577666823397 BCD5 error: 452.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 72.30454206466675, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 34.475477409362796, 65.11368617340922 ; AI error: 1477.8958544382408 BCD5 error: 539.4\n",
            "Found AL092017 at 2017-08-26 12:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 55.82458317279816, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 29.1, 97.5; AI forecast: 24.010954523086546, 63.72536567784846 ; AI error: 1833.1078447935463 BCD5 error: 82.2\n",
            "\tIntensity Truth: 40.0, AI forecast: 59.10211741924286, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.5, 96.2; AI forecast: 26.88650131225586, 65.01099569126963 ; AI error: 1656.3049346253376 BCD5 error: 245.0\n",
            "\tIntensity Truth: 40.0, AI forecast: 62.285014390945435, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 94.6; AI forecast: 29.43287935256958, 65.24540668800473 ; AI error: 1541.934515176622 BCD5 error: 389.4\n",
            "\tIntensity Truth: 40.0, AI forecast: 61.70028209686279, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 30.1, 93.4; AI forecast: 32.19230766296387, 66.05471872836351 ; AI error: 1406.985521719995 BCD5 error: 381.2\n",
            "Found AL092017 at 2017-08-26 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 51.94792926311493, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 29.0, 97.2; AI forecast: 23.223754930496217, 63.69329459518194 ; AI error: 1833.0840849270369 BCD5 error: 80.7\n",
            "\tIntensity Truth: 40.0, AI forecast: 54.701977372169495, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.4, 95.9; AI forecast: 25.908915519714355, 63.92251467332244 ; AI error: 1709.906409163534 BCD5 error: 219.0\n",
            "\tIntensity Truth: 45.0, AI forecast: 54.548590779304504, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.5, 94.2; AI forecast: 28.999356746673584, 64.71185134723783 ; AI error: 1548.472768679611 BCD5 error: 335.8\n",
            "\tIntensity Truth: 35.0, AI forecast: 55.42008817195892, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 30.6, 93.1; AI forecast: 31.985495185852052, 63.16077289208769 ; AI error: 1533.4366015377598 BCD5 error: 291.8\n",
            "Found AL092017 at 2017-08-27 00:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 51.51856005191803, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 28.8, 96.8; AI forecast: 23.236089658737182, 62.529083182383324 ; AI error: 1872.4371193359086 BCD5 error: 91.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 51.10411785542965, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 95.4; AI forecast: 26.71155204772949, 63.041428645513946 ; AI error: 1721.239577361437 BCD5 error: 216.6\n",
            "\tIntensity Truth: 45.0, AI forecast: 52.05543398857117, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.9, 93.8; AI forecast: 30.105799961090085, 61.704972953163086 ; AI error: 1673.1921832375774 BCD5 error: 288.9\n",
            "Found AL092017 at 2017-08-27 06:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 48.14716309309006, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.6, 96.5; AI forecast: 24.15575489997864, 61.704821679554875 ; AI error: 1883.931123956933 BCD5 error: 86.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 48.50567787885666, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.1, 95.0; AI forecast: 27.862047004699708, 60.217572800070045 ; AI error: 1837.8734116249595 BCD5 error: 182.2\n",
            "\tIntensity Truth: 40.0, AI forecast: 46.677826046943665, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 29.1213228225708, 59.86465715467929 ; AI error: 1760.8642921199928 BCD5 error: 202.7\n",
            "Found AL092017 at 2017-08-27 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.14679028093815, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.5, 96.2; AI forecast: 24.986207818984987, 61.30676266811788 ; AI error: 1876.2603276999348 BCD5 error: 49.5\n",
            "\tIntensity Truth: 40.0, AI forecast: 46.56374216079712, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 28.2, 94.6; AI forecast: 27.049286079406738, 60.66594777479767 ; AI error: 1800.6031907344104 BCD5 error: 134.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 43.82340669631958, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 30.1, 93.4; AI forecast: 27.468363094329835, 61.01191374994814 ; AI error: 1705.977978858079 BCD5 error: 109.9\n",
            "Found AL092017 at 2017-08-27 18:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 46.412553787231445, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 28.4, 95.9; AI forecast: 22.74565553665161, 62.328880788770036 ; AI error: 1843.4610231557976 BCD5 error: 48.0\n",
            "\tIntensity Truth: 45.0, AI forecast: 43.21409523487091, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 28.5, 94.2; AI forecast: 23.74727592468262, 62.671146736014634 ; AI error: 1718.3834300300316 BCD5 error: 120.5\n",
            "\tIntensity Truth: 35.0, AI forecast: 41.04955494403839, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 30.6, 93.1; AI forecast: 24.172236251831055, 63.23133007735014 ; AI error: 1633.1820142889528 BCD5 error: 99.4\n",
            "Found AL092017 at 2017-08-28 00:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 47.15059131383896, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 28.2, 95.4; AI forecast: 21.92535605430603, 62.93213620688766 ; AI error: 1799.8830258229818 BCD5 error: 42.3\n",
            "\tIntensity Truth: 45.0, AI forecast: 44.94179129600525, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 28.9, 93.8; AI forecast: 22.902047634124756, 63.61977973654866 ; AI error: 1664.482321274614 BCD5 error: 72.8\n",
            "Found AL092017 at 2017-08-28 06:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 47.884586453437805, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 28.1, 95.0; AI forecast: 21.850138545036316, 63.106176640093324 ; AI error: 1770.5491384321415 BCD5 error: 47.0\n",
            "\tIntensity Truth: 40.0, AI forecast: 47.18368798494339, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 22.87158098220825, 64.0453325793147 ; AI error: 1635.7030937078544 BCD5 error: 44.8\n",
            "Found AL092017 at 2017-08-28 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.548121467232704, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 28.2, 94.6; AI forecast: 21.976133251190184, 63.254291138052935 ; AI error: 1739.7462009905453 BCD5 error: 52.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.45013094693422, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 30.1, 93.4; AI forecast: 23.158831882476807, 64.18119900971651 ; AI error: 1617.6454603499992 BCD5 error: 12.0\n",
            "Found AL092017 at 2017-08-28 18:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 49.81077270582318, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 28.5, 94.2; AI forecast: 22.057925176620483, 63.26034521758556 ; AI error: 1718.5356056884232 BCD5 error: 19.8\n",
            "\tIntensity Truth: 35.0, AI forecast: 50.20749190822244, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 30.6, 93.1; AI forecast: 23.54880542755127, 64.17756138890981 ; AI error: 1598.095702365011 BCD5 error: 39.2\n",
            "Found AL092017 at 2017-08-29 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.440574176609516, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 28.9, 93.8; AI forecast: 22.443053483963013, 63.24559946991503 ; AI error: 1693.1465702692776 BCD5 error: 24.6\n",
            "Found AL092017 at 2017-08-29 06:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.85854981467128, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 29.4, 93.6; AI forecast: 22.23636484146118, 63.310320472344756 ; AI error: 1687.2864181487441 BCD5 error: 30.5\n",
            "Found AL092017 at 2017-08-29 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.83968898653984, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 30.1, 93.4; AI forecast: 22.156060433387758, 63.12988387942314 ; AI error: 1694.2025757071706 BCD5 error: 31.8\n",
            "Found AL092017 at 2017-08-29 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 50.198667608201504, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 30.6, 93.1; AI forecast: 22.204056692123412, 63.079306763410564 ; AI error: 1685.3413843193664 BCD5 error: 19.6\n",
            "Found AL092017 at 2017-08-30 00:00:00\n",
            "Found AL092017 at 2017-08-30 06:00:00\n",
            "Found AL092017 at 2017-08-30 12:00:00\n",
            "Found AL092017 at 2017-08-30 18:00:00\n",
            "Found AL112017 at 2017-08-31 06:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 52.47562035918236, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 17.9, 36.1; AI forecast: 21.42353357076645, 61.75139602143317 ; AI error: 1463.978405664956 BCD5 error: 12.0\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.76585805416107, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 19.1, 41.1; AI forecast: 22.459383964538574, 61.141646447032684 ; AI error: 1142.0279903756962 BCD5 error: 84.7\n",
            "\tIntensity Truth: 95.0, AI forecast: 57.34165012836456, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 18.2, 46.7; AI forecast: 23.644367361068724, 60.54790596067905 ; AI error: 841.9937026398239 BCD5 error: 310.6\n",
            "\tIntensity Truth: 105.0, AI forecast: 60.96890568733215, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 17.0, 51.5; AI forecast: 25.427542686462402, 60.158690723776814 ; AI error: 700.1677713745154 BCD5 error: 581.4\n",
            "\tIntensity Truth: 135.0, AI forecast: 63.31009387969971, BCD5 forecast: -59.0\n",
            "\tTrajectory Truth: 16.6, 56.4; AI forecast: 26.853262901306152, 60.037318146973846 ; AI error: 648.050598164764 BCD5 error: 848.5\n",
            "Found AL112017 at 2017-08-31 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.116911590099335, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 18.4, 37.3; AI forecast: 21.917056298255922, 61.628456773236394 ; AI error: 1385.8499614576244 BCD5 error: 18.1\n",
            "\tIntensity Truth: 95.0, AI forecast: 58.338884711265564, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 18.9, 42.6; AI forecast: 23.553018808364868, 60.8331360720098 ; AI error: 1057.0633002591119 BCD5 error: 168.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 63.622329235076904, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 17.9, 47.9; AI forecast: 25.915148639678954, 60.14986806288361 ; AI error: 834.1733205206539 BCD5 error: 423.4\n",
            "\tIntensity Truth: 110.0, AI forecast: 67.8125011920929, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 16.8, 52.6; AI forecast: 28.14537057876587, 59.71558975055814 ; AI error: 786.8028655663973 BCD5 error: 712.6\n",
            "\tIntensity Truth: 150.0, AI forecast: 72.11409568786621, BCD5 forecast: -68.0\n",
            "\tTrajectory Truth: 16.7, 57.8; AI forecast: 30.659160423278806, 59.63083244115114 ; AI error: 844.0918753665563 BCD5 error: 987.4\n",
            "Found AL112017 at 2017-08-31 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 56.38945698738098, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 18.8, 38.5; AI forecast: 22.48971109390259, 61.32312216423452 ; AI error: 1299.9446147357917 BCD5 error: 48.8\n",
            "\tIntensity Truth: 95.0, AI forecast: 63.52696180343628, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 18.7, 44.1; AI forecast: 25.303764152526856, 60.30580587536096 ; AI error: 984.355198706446 BCD5 error: 242.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 69.4578492641449, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 17.6, 49.2; AI forecast: 28.09356231689453, 59.51294679939747 ; AI error: 849.1295162246531 BCD5 error: 515.9\n",
            "\tIntensity Truth: 115.0, AI forecast: 75.49683809280396, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 16.7, 53.9; AI forecast: 31.361829376220705, 59.011610777676104 ; AI error: 923.4763006457159 BCD5 error: 810.4\n",
            "\tIntensity Truth: 155.0, AI forecast: 78.62075805664062, BCD5 forecast: -66.0\n",
            "\tTrajectory Truth: 16.9, 59.2; AI forecast: 33.691520881652835, 59.1717601493001 ; AI error: 1008.1721084481394 BCD5 error: 1087.7\n",
            "Found AL112017 at 2017-09-01 00:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 58.870389461517334, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 19.1, 39.7; AI forecast: 23.507653951644897, 61.199304813891644 ; AI error: 1230.0509071147846 BCD5 error: 51.3\n",
            "\tIntensity Truth: 95.0, AI forecast: 66.30294442176819, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 18.5, 45.5; AI forecast: 26.627263736724853, 60.16324676349759 ; AI error: 947.0246306308245 BCD5 error: 277.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 73.64036321640015, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 17.3, 50.4; AI forecast: 30.288925647735596, 59.41053260713815 ; AI error: 922.7521498800236 BCD5 error: 555.4\n",
            "\tIntensity Truth: 125.0, AI forecast: 77.97691822052002, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 16.6, 55.1; AI forecast: 33.04422168731689, 59.26890210360288 ; AI error: 1012.8282767546629 BCD5 error: 848.4\n",
            "\tIntensity Truth: 155.0, AI forecast: 76.93533658981323, BCD5 forecast: -65.0\n",
            "\tTrajectory Truth: 17.3, 60.6; AI forecast: 33.598253059387204, 59.40010628923773 ; AI error: 980.690236786112 BCD5 error: 1113.5\n",
            "Found AL112017 at 2017-09-01 06:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 59.006107449531555, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 19.1, 41.1; AI forecast: 23.604280996322633, 61.30662373937666 ; AI error: 1160.676008585118 BCD5 error: 75.1\n",
            "\tIntensity Truth: 95.0, AI forecast: 67.99561738967896, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 18.2, 46.7; AI forecast: 27.69440965652466, 60.41978485658765 ; AI error: 947.5823989423311 BCD5 error: 309.7\n",
            "\tIntensity Truth: 105.0, AI forecast: 73.83755683898926, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 17.0, 51.5; AI forecast: 30.975456047058103, 60.02444205880165 ; AI error: 959.6531967700721 BCD5 error: 600.4\n",
            "\tIntensity Truth: 135.0, AI forecast: 73.97761821746826, BCD5 forecast: -46.0\n",
            "\tTrajectory Truth: 16.6, 56.4; AI forecast: 31.860159873962402, 59.89885831475257 ; AI error: 935.8517696829621 BCD5 error: 891.6\n",
            "\tIntensity Truth: 155.0, AI forecast: 72.89093017578125, BCD5 forecast: -64.0\n",
            "\tTrajectory Truth: 17.7, 61.9; AI forecast: 31.89558525085449, 59.75253382250666 ; AI error: 860.2419281817901 BCD5 error: 1148.3\n",
            "Found AL112017 at 2017-09-01 12:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 60.67633628845215, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 18.9, 42.6; AI forecast: 24.701678609848024, 61.51390096340328 ; AI error: 1109.1638861784852 BCD5 error: 106.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 68.30494999885559, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 17.9, 47.9; AI forecast: 28.468295860290528, 60.93389311283826 ; AI error: 957.8523479865358 BCD5 error: 345.4\n",
            "\tIntensity Truth: 110.0, AI forecast: 69.82904434204102, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 16.8, 52.6; AI forecast: 29.69001007080078, 60.528987158089876 ; AI error: 888.2479913158897 BCD5 error: 629.5\n",
            "\tIntensity Truth: 150.0, AI forecast: 69.62535977363586, BCD5 forecast: -59.0\n",
            "\tTrajectory Truth: 16.7, 57.8; AI forecast: 29.936260032653806, 60.182346428185696 ; AI error: 805.4191081312761 BCD5 error: 914.6\n",
            "\tIntensity Truth: 155.0, AI forecast: 68.91422510147095, BCD5 forecast: -62.0\n",
            "\tTrajectory Truth: 18.1, 63.3; AI forecast: 29.82348575592041, 59.96051112785935 ; AI error: 727.2104293253028 BCD5 error: 1164.7\n",
            "Found AL112017 at 2017-09-01 18:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 59.29372787475586, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 18.7, 44.1; AI forecast: 24.299672079086303, 61.79510454162955 ; AI error: 1043.0574620145744 BCD5 error: 135.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 62.49966621398926, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 17.6, 49.2; AI forecast: 25.742264842987062, 61.18745687678456 ; AI error: 827.665254901931 BCD5 error: 356.6\n",
            "\tIntensity Truth: 115.0, AI forecast: 63.32460641860962, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 16.7, 53.9; AI forecast: 26.18180694580078, 60.74417435564101 ; AI error: 685.4775120843664 BCD5 error: 627.4\n",
            "\tIntensity Truth: 155.0, AI forecast: 63.45946788787842, BCD5 forecast: -63.0\n",
            "\tTrajectory Truth: 16.9, 59.2; AI forecast: 26.25017366409302, 60.46282592117786 ; AI error: 565.785018174098 BCD5 error: 893.9\n",
            "\tIntensity Truth: 150.0, AI forecast: 62.96142816543579, BCD5 forecast: -56.0\n",
            "\tTrajectory Truth: 18.6, 64.7; AI forecast: 26.01912064552307, 60.40729224309325 ; AI error: 505.12914157380055 BCD5 error: 1131.6\n",
            "Found AL112017 at 2017-09-02 00:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 53.584914803504944, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 18.5, 45.5; AI forecast: 21.230777823925017, 61.72269920241087 ; AI error: 930.1459354518372 BCD5 error: 119.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.913634061813354, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 17.3, 50.4; AI forecast: 21.441389620304108, 61.318972035497424 ; AI error: 666.3149340055287 BCD5 error: 313.3\n",
            "\tIntensity Truth: 125.0, AI forecast: 55.70797860622406, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 16.6, 55.1; AI forecast: 21.549388921260835, 61.05571167245507 ; AI error: 449.89882725743547 BCD5 error: 558.1\n",
            "\tIntensity Truth: 155.0, AI forecast: 56.07038676738739, BCD5 forecast: -64.0\n",
            "\tTrajectory Truth: 17.3, 60.6; AI forecast: 21.549312818050385, 60.983774213492865 ; AI error: 256.0539542757975 BCD5 error: 780.3\n",
            "\tIntensity Truth: 150.0, AI forecast: 56.06727600097656, BCD5 forecast: -56.0\n",
            "\tTrajectory Truth: 19.2, 66.2; AI forecast: 21.723560214042664, 61.04488208889961 ; AI error: 327.1441472707629 BCD5 error: 1005.7\n",
            "Found AL112017 at 2017-09-02 06:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 51.45042046904564, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 18.2, 46.7; AI forecast: 20.357062920928, 61.937088367994875 ; AI error: 872.8547688013991 BCD5 error: 78.0\n",
            "\tIntensity Truth: 105.0, AI forecast: 52.5119423866272, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 17.0, 51.5; AI forecast: 20.248828634619713, 61.63956387136131 ; AI error: 608.8171222442388 BCD5 error: 240.0\n",
            "\tIntensity Truth: 135.0, AI forecast: 53.28319638967514, BCD5 forecast: -40.0\n",
            "\tTrajectory Truth: 16.6, 56.4; AI forecast: 20.142450219392778, 61.509348352812225 ; AI error: 360.4915804095541 BCD5 error: 439.3\n",
            "\tIntensity Truth: 155.0, AI forecast: 53.808503448963165, BCD5 forecast: -62.0\n",
            "\tTrajectory Truth: 17.7, 61.9; AI forecast: 20.277701562643053, 61.5065700719133 ; AI error: 156.3695772462425 BCD5 error: 597.1\n",
            "\tIntensity Truth: 145.0, AI forecast: 53.83305877447128, BCD5 forecast: -48.0\n",
            "\tTrajectory Truth: 19.7, 67.6; AI forecast: 20.353476202487947, 61.73650918956846 ; AI error: 333.0591557118011 BCD5 error: 793.3\n",
            "Found AL112017 at 2017-09-02 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.92617250978947, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 17.9, 47.9; AI forecast: 20.15099405646324, 62.2473676350899 ; AI error: 825.2104007619275 BCD5 error: 71.9\n",
            "\tIntensity Truth: 110.0, AI forecast: 51.489945501089096, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 16.8, 52.6; AI forecast: 19.84435502886772, 62.25162059791619 ; AI error: 579.5392656232837 BCD5 error: 210.3\n",
            "\tIntensity Truth: 150.0, AI forecast: 51.7432576417923, BCD5 forecast: -56.0\n",
            "\tTrajectory Truth: 16.7, 57.8; AI forecast: 19.821431189775467, 62.3377397494507 ; AI error: 319.43383336256636 BCD5 error: 372.2\n",
            "\tIntensity Truth: 155.0, AI forecast: 51.43187552690506, BCD5 forecast: -61.0\n",
            "\tTrajectory Truth: 18.1, 63.3; AI forecast: 19.767080187797546, 62.63943985141813 ; AI error: 106.89093706169233 BCD5 error: 491.2\n",
            "\tIntensity Truth: 145.0, AI forecast: 49.030738174915314, BCD5 forecast: -44.0\n",
            "\tTrajectory Truth: 20.2, 69.0; AI forecast: 19.6941236615181, 62.930355704762036 ; AI error: 343.8856226882777 BCD5 error: 673.6\n",
            "Found AL112017 at 2017-09-02 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.78716114163399, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 17.6, 49.2; AI forecast: 20.020131248235703, 62.44695231691003 ; AI error: 766.5233477247318 BCD5 error: 77.4\n",
            "\tIntensity Truth: 115.0, AI forecast: 51.23559832572937, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 16.7, 53.9; AI forecast: 19.829842805862427, 62.58549653021618 ; AI error: 529.5437104568388 BCD5 error: 203.2\n",
            "\tIntensity Truth: 155.0, AI forecast: 51.13817676901817, BCD5 forecast: -60.0\n",
            "\tTrajectory Truth: 16.9, 59.2; AI forecast: 19.627210164070128, 62.92514813039452 ; AI error: 268.15964358631953 BCD5 error: 348.0\n",
            "\tIntensity Truth: 150.0, AI forecast: 48.97361107170582, BCD5 forecast: -55.0\n",
            "\tTrajectory Truth: 18.6, 64.7; AI forecast: 19.429125022888183, 63.22879790998995 ; AI error: 97.22237959224628 BCD5 error: 450.6\n",
            "\tIntensity Truth: 145.0, AI forecast: 48.42304825782776, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 20.7, 70.4; AI forecast: 19.044139742851257, 63.471103253215546 ; AI error: 403.63122155819417 BCD5 error: 640.5\n",
            "Found AL112017 at 2017-09-03 00:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.67394696176052, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 17.3, 50.4; AI forecast: 20.21007697582245, 62.598904819320886 ; AI error: 714.9785488022134 BCD5 error: 74.0\n",
            "\tIntensity Truth: 125.0, AI forecast: 50.79203583300114, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 16.6, 55.1; AI forecast: 19.902375799417495, 63.003115273080766 ; AI error: 492.2191666072408 BCD5 error: 180.8\n",
            "\tIntensity Truth: 155.0, AI forecast: 48.902584090828896, BCD5 forecast: -59.0\n",
            "\tTrajectory Truth: 17.3, 60.6; AI forecast: 19.633378529548644, 63.30869575068354 ; AI error: 208.36903733984568 BCD5 error: 298.4\n",
            "\tIntensity Truth: 150.0, AI forecast: 48.65900248289108, BCD5 forecast: -55.0\n",
            "\tTrajectory Truth: 19.2, 66.2; AI forecast: 19.14761198759079, 63.6036515597254 ; AI error: 147.2707078546524 BCD5 error: 413.0\n",
            "\tIntensity Truth: 140.0, AI forecast: 48.56848701834679, BCD5 forecast: -39.0\n",
            "\tTrajectory Truth: 21.1, 71.8; AI forecast: 19.060613250732423, 63.839614188671106 ; AI error: 465.21937732661115 BCD5 error: 625.9\n",
            "Found AL112017 at 2017-09-03 06:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 50.28191298246384, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 17.0, 51.5; AI forecast: 19.978224915266036, 62.904084358178075 ; AI error: 673.3362765784958 BCD5 error: 60.3\n",
            "\tIntensity Truth: 135.0, AI forecast: 48.587278723716736, BCD5 forecast: -40.0\n",
            "\tTrajectory Truth: 16.6, 56.4; AI forecast: 19.563867008686067, 63.276859220489854 ; AI error: 430.88167719401633 BCD5 error: 144.5\n",
            "\tIntensity Truth: 155.0, AI forecast: 48.53894978761673, BCD5 forecast: -61.0\n",
            "\tTrajectory Truth: 17.7, 61.9; AI forecast: 18.94221684932709, 63.64447005838156 ; AI error: 124.2912667332593 BCD5 error: 247.0\n",
            "\tIntensity Truth: 145.0, AI forecast: 48.700146079063416, BCD5 forecast: -53.0\n",
            "\tTrajectory Truth: 19.7, 67.6; AI forecast: 18.74755334854126, 63.94283638186752 ; AI error: 215.06901671106675 BCD5 error: 377.0\n",
            "\tIntensity Truth: 135.0, AI forecast: 48.7137670814991, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 21.5, 73.2; AI forecast: 18.710585713386536, 64.20621147379279 ; AI error: 533.9015752861553 BCD5 error: 598.0\n",
            "Found AL112017 at 2017-09-03 12:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 48.92087176442146, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 16.8, 52.6; AI forecast: 20.110424077510835, 62.79596492685377 ; AI error: 613.5867279410221 BCD5 error: 58.7\n",
            "\tIntensity Truth: 150.0, AI forecast: 49.52794250100851, BCD5 forecast: -50.0\n",
            "\tTrajectory Truth: 16.7, 57.8; AI forecast: 19.518342101573943, 63.201904421299695 ; AI error: 351.61095561453806 BCD5 error: 114.1\n",
            "\tIntensity Truth: 155.0, AI forecast: 50.4116990044713, BCD5 forecast: -58.0\n",
            "\tTrajectory Truth: 18.1, 63.3; AI forecast: 19.373659551143646, 63.51855496242642 ; AI error: 77.47417978308738 BCD5 error: 201.8\n",
            "\tIntensity Truth: 145.0, AI forecast: 51.29429891705513, BCD5 forecast: -51.0\n",
            "\tTrajectory Truth: 20.2, 69.0; AI forecast: 19.41047673225403, 63.801764042675494 ; AI error: 297.4305108147347 BCD5 error: 322.4\n",
            "\tIntensity Truth: 135.0, AI forecast: 53.748126327991486, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 21.8, 74.7; AI forecast: 20.248237854242326, 64.1259284928441 ; AI error: 599.7546184474313 BCD5 error: 559.5\n",
            "Found AL112017 at 2017-09-03 18:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.34227567911148, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 16.7, 53.9; AI forecast: 20.23983103632927, 62.72948571164161 ; AI error: 545.7475321094611 BCD5 error: 47.9\n",
            "\tIntensity Truth: 155.0, AI forecast: 54.38068240880966, BCD5 forecast: -54.0\n",
            "\tTrajectory Truth: 16.9, 59.2; AI forecast: 20.313048040866853, 63.01133367232978 ; AI error: 298.33938107862053 BCD5 error: 84.2\n",
            "\tIntensity Truth: 150.0, AI forecast: 56.15168571472168, BCD5 forecast: -52.0\n",
            "\tTrajectory Truth: 18.6, 64.7; AI forecast: 20.50369224175811, 63.240399341657756 ; AI error: 141.00726537785675 BCD5 error: 153.7\n",
            "\tIntensity Truth: 145.0, AI forecast: 59.483094811439514, BCD5 forecast: -50.0\n",
            "\tTrajectory Truth: 20.7, 70.4; AI forecast: 21.51746212244034, 63.51521038524806 ; AI error: 388.7048964488334 BCD5 error: 282.3\n",
            "\tIntensity Truth: 140.0, AI forecast: 61.71429753303528, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 22.0, 76.0; AI forecast: 22.344833612442017, 63.87939601242542 ; AI error: 674.0500672489184 BCD5 error: 531.2\n",
            "Found AL112017 at 2017-09-04 00:00:00\n",
            "\tIntensity Truth: 125.0, AI forecast: 53.462553918361664, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 16.6, 55.1; AI forecast: 20.867285233736037, 62.53656441671774 ; AI error: 494.2674927417974 BCD5 error: 30.5\n",
            "\tIntensity Truth: 155.0, AI forecast: 56.4799040555954, BCD5 forecast: -55.0\n",
            "\tTrajectory Truth: 17.3, 60.6; AI forecast: 21.31280723810196, 62.66989608341828 ; AI error: 267.94861361774264 BCD5 error: 66.4\n",
            "\tIntensity Truth: 150.0, AI forecast: 61.009860038757324, BCD5 forecast: -51.0\n",
            "\tTrajectory Truth: 19.2, 66.2; AI forecast: 22.593574619293214, 62.83608334418386 ; AI error: 277.6708681488222 BCD5 error: 145.2\n",
            "\tIntensity Truth: 140.0, AI forecast: 64.59456443786621, BCD5 forecast: -44.0\n",
            "\tTrajectory Truth: 21.1, 71.8; AI forecast: 23.76387276649475, 63.10222015921026 ; AI error: 508.38533368137365 BCD5 error: 302.5\n",
            "\tIntensity Truth: 145.0, AI forecast: 67.72076845169067, BCD5 forecast: -47.0\n",
            "\tTrajectory Truth: 22.1, 77.2; AI forecast: 25.21154341697693, 63.4602399662137 ; AI error: 777.9492176892508 BCD5 error: 541.0\n",
            "Found AL112017 at 2017-09-04 06:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 54.72040444612503, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 16.6, 56.4; AI forecast: 21.188650357723237, 62.38578504407778 ; AI error: 437.52142882896663 BCD5 error: 29.5\n",
            "\tIntensity Truth: 155.0, AI forecast: 60.61774134635925, BCD5 forecast: -50.0\n",
            "\tTrajectory Truth: 17.7, 61.9; AI forecast: 22.729126119613646, 62.434093643818045 ; AI error: 303.4455554370323 BCD5 error: 82.0\n",
            "\tIntensity Truth: 145.0, AI forecast: 65.53611040115356, BCD5 forecast: -44.0\n",
            "\tTrajectory Truth: 19.7, 67.6; AI forecast: 24.22537531852722, 62.58652100721374 ; AI error: 389.47488056038054 BCD5 error: 172.0\n",
            "\tIntensity Truth: 135.0, AI forecast: 70.1517391204834, BCD5 forecast: -38.0\n",
            "\tTrajectory Truth: 21.5, 73.2; AI forecast: 26.096940517425537, 62.82727312613278 ; AI error: 632.8199077321158 BCD5 error: 334.1\n",
            "\tIntensity Truth: 130.0, AI forecast: 73.03071737289429, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 22.4, 78.3; AI forecast: 27.63831157684326, 63.261714714020485 ; AI error: 875.7151624141297 BCD5 error: 559.6\n",
            "Found AL112017 at 2017-09-04 12:00:00\n",
            "\tIntensity Truth: 150.0, AI forecast: 57.76460289955139, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 16.7, 57.8; AI forecast: 22.293142008781434, 62.24141437197104 ; AI error: 419.3902577385089 BCD5 error: 29.5\n",
            "\tIntensity Truth: 155.0, AI forecast: 64.23171401023865, BCD5 forecast: -46.0\n",
            "\tTrajectory Truth: 18.1, 63.3; AI forecast: 24.084799337387086, 62.22593038165942 ; AI error: 364.3260979038215 BCD5 error: 75.1\n",
            "\tIntensity Truth: 145.0, AI forecast: 70.27334928512573, BCD5 forecast: -41.0\n",
            "\tTrajectory Truth: 20.2, 69.0; AI forecast: 26.27402534484863, 62.30425914750667 ; AI error: 518.8772210238956 BCD5 error: 157.4\n",
            "\tIntensity Truth: 135.0, AI forecast: 74.64908838272095, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 21.8, 74.7; AI forecast: 28.231532096862793, 62.57147633740678 ; AI error: 763.8851987289906 BCD5 error: 337.3\n",
            "\tIntensity Truth: 110.0, AI forecast: 76.80734157562256, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 22.7, 79.3; AI forecast: 29.487705039978025, 63.00239505786448 ; AI error: 967.3529258097049 BCD5 error: 543.8\n",
            "Found AL112017 at 2017-09-04 18:00:00\n",
            "\tIntensity Truth: 155.0, AI forecast: 57.71792709827423, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 16.9, 59.2; AI forecast: 22.10907738208771, 62.34020544068189 ; AI error: 359.6798652889551 BCD5 error: 16.6\n",
            "\tIntensity Truth: 150.0, AI forecast: 65.10536432266235, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 18.6, 64.7; AI forecast: 24.348139476776122, 62.44033074090257 ; AI error: 367.46249636152345 BCD5 error: 63.7\n",
            "\tIntensity Truth: 145.0, AI forecast: 70.84880828857422, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 20.7, 70.4; AI forecast: 26.46684217453003, 62.718409230746325 ; AI error: 546.1391650496626 BCD5 error: 147.7\n",
            "\tIntensity Truth: 140.0, AI forecast: 74.27111625671387, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 22.0, 76.0; AI forecast: 27.870520496368407, 63.180145907402036 ; AI error: 781.2286918683247 BCD5 error: 326.6\n",
            "\tIntensity Truth: 95.0, AI forecast: 73.73993873596191, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 23.1, 80.2; AI forecast: 27.7139741897583, 63.787517870217556 ; AI error: 931.295176216442 BCD5 error: 510.9\n",
            "Found AL112017 at 2017-09-05 00:00:00\n",
            "\tIntensity Truth: 155.0, AI forecast: 58.71488153934479, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 17.3, 60.6; AI forecast: 22.687635016441345, 62.51395102078095 ; AI error: 341.0076851890315 BCD5 error: 23.7\n",
            "\tIntensity Truth: 150.0, AI forecast: 65.96032738685608, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 19.2, 66.2; AI forecast: 24.97105793952942, 62.84990214910358 ; AI error: 393.3870221675556 BCD5 error: 92.4\n",
            "\tIntensity Truth: 140.0, AI forecast: 70.83515882492065, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 21.1, 71.8; AI forecast: 26.587575912475586, 63.37546404153108 ; AI error: 567.6884336906476 BCD5 error: 163.2\n",
            "\tIntensity Truth: 145.0, AI forecast: 71.575026512146, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 22.1, 77.2; AI forecast: 26.584737396240236, 64.1200870193541 ; AI error: 763.9724583894692 BCD5 error: 343.2\n",
            "\tIntensity Truth: 100.0, AI forecast: 71.81503772735596, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 23.4, 80.9; AI forecast: 26.751953506469725, 64.67097886428236 ; AI error: 904.4894541604441 BCD5 error: 501.2\n",
            "Found AL112017 at 2017-09-05 06:00:00\n",
            "\tIntensity Truth: 155.0, AI forecast: 59.225836992263794, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 17.7, 61.9; AI forecast: 22.982181477546693, 62.67820604043081 ; AI error: 320.15335460491275 BCD5 error: 13.3\n",
            "\tIntensity Truth: 145.0, AI forecast: 66.40772819519043, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 19.7, 67.6; AI forecast: 25.268676900863646, 63.128855728358026 ; AI error: 416.2148121085139 BCD5 error: 74.2\n",
            "\tIntensity Truth: 135.0, AI forecast: 69.46769952774048, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 21.5, 73.2; AI forecast: 26.066830682754517, 63.81127076596022 ; AI error: 583.9052012383765 BCD5 error: 149.3\n",
            "\tIntensity Truth: 130.0, AI forecast: 72.07135200500488, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 22.4, 78.3; AI forecast: 27.068096923828126, 64.24211113080382 ; AI error: 815.5936239667788 BCD5 error: 336.0\n",
            "\tIntensity Truth: 115.0, AI forecast: 76.20007753372192, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 23.7, 81.3; AI forecast: 29.36909885406494, 64.44582828134298 ; AI error: 965.9911379896057 BCD5 error: 478.1\n",
            "Found AL112017 at 2017-09-05 12:00:00\n",
            "\tIntensity Truth: 155.0, AI forecast: 58.660410046577454, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 18.1, 63.3; AI forecast: 22.639152097702027, 62.93572856318205 ; AI error: 273.3024703021034 BCD5 error: 13.3\n",
            "\tIntensity Truth: 145.0, AI forecast: 63.37894320487976, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 20.2, 69.0; AI forecast: 23.55389666557312, 63.752356357872486 ; AI error: 354.9537475282243 BCD5 error: 59.2\n",
            "\tIntensity Truth: 135.0, AI forecast: 67.5725269317627, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 21.8, 74.7; AI forecast: 24.737505197525024, 64.32671246379614 ; AI error: 598.514726993536 BCD5 error: 166.2\n",
            "\tIntensity Truth: 110.0, AI forecast: 73.49329948425293, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 22.7, 79.3; AI forecast: 27.46720485687256, 64.56487884745002 ; AI error: 850.1178762834347 BCD5 error: 356.7\n",
            "\tIntensity Truth: 115.0, AI forecast: 74.88133430480957, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 24.5, 81.5; AI forecast: 28.366807556152345, 65.20610023960471 ; AI error: 905.4083108270801 BCD5 error: 466.9\n",
            "Found AL112017 at 2017-09-05 18:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 61.00835561752319, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 20.7, 70.4; AI forecast: 22.154749822616576, 63.925280707329506 ; AI error: 372.2285273112862 BCD5 error: 80.5\n",
            "\tIntensity Truth: 140.0, AI forecast: 68.51157307624817, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 22.0, 76.0; AI forecast: 25.107508993148805, 64.28842730820179 ; AI error: 670.7517198861774 BCD5 error: 237.3\n",
            "\tIntensity Truth: 95.0, AI forecast: 71.68681621551514, BCD5 forecast: 35.0\n",
            "\tTrajectory Truth: 23.1, 80.2; AI forecast: 26.366717720031737, 64.95815476179122 ; AI error: 853.406350380403 BCD5 error: 430.3\n",
            "\tIntensity Truth: 100.0, AI forecast: 73.15567970275879, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 25.6, 81.7; AI forecast: 26.97740058898926, 65.40357461050152 ; AI error: 880.5201786075982 BCD5 error: 503.7\n",
            "Found AL112017 at 2017-09-06 00:00:00\n",
            "\tIntensity Truth: 150.0, AI forecast: 57.315751910209656, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 19.2, 66.2; AI forecast: 22.03263654708862, 62.87814563717693 ; AI error: 252.5080036435432 BCD5 error: 25.6\n",
            "\tIntensity Truth: 140.0, AI forecast: 66.63211345672607, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 21.1, 71.8; AI forecast: 25.444394207000734, 63.133945144712925 ; AI error: 544.3014554780572 BCD5 error: 124.0\n",
            "\tIntensity Truth: 145.0, AI forecast: 71.72932624816895, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 22.1, 77.2; AI forecast: 27.448440074920654, 63.56939171254635 ; AI error: 808.7977114352819 BCD5 error: 320.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 75.27135610580444, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 23.4, 80.9; AI forecast: 28.903861904144286, 63.73854088410735 ; AI error: 980.9455453030266 BCD5 error: 504.9\n",
            "\tIntensity Truth: 80.0, AI forecast: 79.48594093322754, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 26.8, 81.7; AI forecast: 31.224294185638428, 63.8721772044897 ; AI error: 971.7440770069068 BCD5 error: 519.5\n",
            "Found AL112017 at 2017-09-06 06:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 57.75237560272217, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 19.7, 67.6; AI forecast: 22.08997313976288, 62.88298237565905 ; AI error: 300.96076032967864 BCD5 error: 28.9\n",
            "\tIntensity Truth: 135.0, AI forecast: 63.9300012588501, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 21.5, 73.2; AI forecast: 23.58960041999817, 63.3231694214046 ; AI error: 561.7355317033267 BCD5 error: 136.3\n",
            "\tIntensity Truth: 130.0, AI forecast: 71.03320121765137, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 22.4, 78.3; AI forecast: 26.354915714263917, 63.62599488720298 ; AI error: 836.2733818898449 BCD5 error: 327.9\n",
            "\tIntensity Truth: 115.0, AI forecast: 72.22043037414551, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 23.7, 81.3; AI forecast: 26.566615486145018, 64.50249847099185 ; AI error: 928.3855021105693 BCD5 error: 488.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 72.34375476837158, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 28.2, 82.2; AI forecast: 26.4323260307312, 65.23519473969937 ; AI error: 910.4330861603105 BCD5 error: 469.8\n",
            "Found AL112017 at 2017-09-06 12:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 58.74261200428009, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 20.2, 69.0; AI forecast: 22.819821786880492, 62.98371227737516 ; AI error: 370.9953254352048 BCD5 error: 23.3\n",
            "\tIntensity Truth: 135.0, AI forecast: 61.70730113983154, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 21.8, 74.7; AI forecast: 23.001499509811403, 64.03104623705148 ; AI error: 596.4697905122578 BCD5 error: 152.7\n",
            "\tIntensity Truth: 110.0, AI forecast: 63.27105760574341, BCD5 forecast: 26.0\n",
            "\tTrajectory Truth: 22.7, 79.3; AI forecast: 22.846285343170166, 65.08033053874969 ; AI error: 786.9454035596332 BCD5 error: 335.2\n",
            "\tIntensity Truth: 115.0, AI forecast: 63.81490707397461, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 24.5, 81.5; AI forecast: 22.53887026309967, 66.06112238317728 ; AI error: 857.5949931600425 BCD5 error: 457.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 61.81250333786011, BCD5 forecast: 40.0\n",
            "\tTrajectory Truth: 29.6, 82.7; AI forecast: 22.142116022109985, 67.03513003736734 ; AI error: 956.0776843208683 BCD5 error: 440.6\n",
            "Found AL112017 at 2017-09-06 18:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 51.62107527256012, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 20.7, 70.4; AI forecast: 19.549652898311614, 63.659642879664894 ; AI error: 386.17734702490674 BCD5 error: 32.8\n",
            "\tIntensity Truth: 140.0, AI forecast: 52.97208845615387, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 22.0, 76.0; AI forecast: 18.80590965747833, 64.91497320085763 ; AI error: 652.386946734355 BCD5 error: 187.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.34171524643898, BCD5 forecast: 40.0\n",
            "\tTrajectory Truth: 23.1, 80.2; AI forecast: 18.438382720947267, 66.12712235301733 ; AI error: 837.616338555273 BCD5 error: 372.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 53.1432381272316, BCD5 forecast: 20.0\n",
            "\tTrajectory Truth: 25.6, 81.7; AI forecast: 17.98995089530945, 66.72738426029682 ; AI error: 950.4890477257875 BCD5 error: 451.9\n",
            "\tIntensity Truth: 45.0, AI forecast: 52.661241590976715, BCD5 forecast: 42.0\n",
            "\tTrajectory Truth: 30.9, 83.5; AI forecast: 17.53237533569336, 67.29961783289909 ; AI error: 1193.4999459258497 BCD5 error: 463.4\n",
            "Found AL112017 at 2017-09-07 00:00:00\n",
            "\tIntensity Truth: 140.0, AI forecast: 51.23114585876465, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 21.1, 71.8; AI forecast: 19.49973111152649, 63.69409083910286 ; AI error: 466.39190664146537 BCD5 error: 39.7\n",
            "\tIntensity Truth: 145.0, AI forecast: 50.76340898871422, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 22.1, 77.2; AI forecast: 18.980677843093872, 65.00413625612855 ; AI error: 710.5396337174698 BCD5 error: 205.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.97094604372978, BCD5 forecast: 34.0\n",
            "\tTrajectory Truth: 23.4, 80.9; AI forecast: 18.330347537994385, 65.76594250500202 ; AI error: 901.3068058493493 BCD5 error: 372.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.10964322090149, BCD5 forecast: 39.0\n",
            "\tTrajectory Truth: 26.8, 81.7; AI forecast: 17.724556136131287, 66.46859273910522 ; AI error: 1005.1491627178741 BCD5 error: 397.1\n",
            "\tIntensity Truth: 35.0, AI forecast: 53.22809487581253, BCD5 forecast: 37.0\n",
            "\tTrajectory Truth: 31.9, 84.4; AI forecast: 17.674704360961915, 67.05555589348077 ; AI error: 1270.6445965133016 BCD5 error: 461.1\n",
            "Found AL112017 at 2017-09-07 06:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 49.02544267475605, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 21.5, 73.2; AI forecast: 19.737196910381318, 63.758588556200266 ; AI error: 540.907797280425 BCD5 error: 49.1\n",
            "\tIntensity Truth: 130.0, AI forecast: 49.929340607486665, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 22.4, 78.3; AI forecast: 18.79177565574646, 64.77205628380179 ; AI error: 790.189136364336 BCD5 error: 205.4\n",
            "\tIntensity Truth: 115.0, AI forecast: 50.04193787928671, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 23.7, 81.3; AI forecast: 17.997249960899353, 65.69630687385798 ; AI error: 939.2774179582295 BCD5 error: 347.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.25470221042633, BCD5 forecast: 50.0\n",
            "\tTrajectory Truth: 28.2, 82.2; AI forecast: 17.702501726150512, 66.53510022014379 ; AI error: 1069.288360089175 BCD5 error: 319.1\n",
            "Found AL112017 at 2017-09-07 12:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 51.39815375208855, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 21.8, 74.7; AI forecast: 19.481694400310516, 63.48779400326311 ; AI error: 644.9850810479968 BCD5 error: 61.8\n",
            "\tIntensity Truth: 110.0, AI forecast: 51.60076528787613, BCD5 forecast: 26.0\n",
            "\tTrajectory Truth: 22.7, 79.3; AI forecast: 18.523336601257324, 64.6055939823389 ; AI error: 862.5007044057063 BCD5 error: 208.6\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.972619235515594, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 24.5, 81.5; AI forecast: 18.051594495773315, 65.60398999899625 ; AI error: 969.0005274552777 BCD5 error: 306.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 52.75684952735901, BCD5 forecast: 62.0\n",
            "\tTrajectory Truth: 29.6, 82.7; AI forecast: 17.7547776222229, 66.53856932371855 ; AI error: 1135.8732146428188 BCD5 error: 269.4\n",
            "Found AL112017 at 2017-09-07 18:00:00\n",
            "\tIntensity Truth: 140.0, AI forecast: 49.94256590958685, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 22.0, 76.0; AI forecast: 19.327860605716705, 63.4505623742938 ; AI error: 722.764480333694 BCD5 error: 63.4\n",
            "\tIntensity Truth: 95.0, AI forecast: 51.31262093782425, BCD5 forecast: 38.0\n",
            "\tTrajectory Truth: 23.1, 80.2; AI forecast: 18.60571665763855, 64.58634931445121 ; AI error: 916.0229140914404 BCD5 error: 186.7\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.28968894481659, BCD5 forecast: 24.0\n",
            "\tTrajectory Truth: 25.6, 81.7; AI forecast: 18.118838524818422, 65.66334137618541 ; AI error: 998.9490039233326 BCD5 error: 230.3\n",
            "\tIntensity Truth: 45.0, AI forecast: 52.10380718111992, BCD5 forecast: 65.0\n",
            "\tTrajectory Truth: 30.9, 83.5; AI forecast: 17.7262966632843, 66.4702257886529 ; AI error: 1219.2465755101991 BCD5 error: 201.2\n",
            "Found AL112017 at 2017-09-08 00:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 51.99293553829193, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 22.1, 77.2; AI forecast: 19.970279014110567, 63.47746850177646 ; AI error: 779.263224149613 BCD5 error: 69.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 52.420949786901474, BCD5 forecast: 31.0\n",
            "\tTrajectory Truth: 23.4, 80.9; AI forecast: 19.54359151124954, 64.59767190888523 ; AI error: 939.1903753248662 BCD5 error: 159.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.86212915182114, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 26.8, 81.7; AI forecast: 19.17630056142807, 65.4590308882296 ; AI error: 1006.3192798341382 BCD5 error: 144.1\n",
            "\tIntensity Truth: 35.0, AI forecast: 55.209075808525085, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 31.9, 84.4; AI forecast: 18.974078726768493, 66.16236831992865 ; AI error: 1253.6289926795848 BCD5 error: 150.3\n",
            "Found AL112017 at 2017-09-08 06:00:00\n",
            "\tIntensity Truth: 130.0, AI forecast: 51.104407235980034, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 22.4, 78.3; AI forecast: 19.776592004299165, 63.772042501717806 ; AI error: 828.5696332212483 BCD5 error: 60.0\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.132304310798645, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 23.7, 81.3; AI forecast: 19.26409629583359, 65.08389075919986 ; AI error: 943.6132686520417 BCD5 error: 139.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 54.19818013906479, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 28.2, 82.2; AI forecast: 19.344403874874114, 66.09061446636915 ; AI error: 1030.9583780810044 BCD5 error: 79.2\n",
            "Found AL112017 at 2017-09-08 12:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 50.89361719787121, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 22.7, 79.3; AI forecast: 19.785412967205048, 63.79774823784828 ; AI error: 884.5183558380403 BCD5 error: 47.5\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.94803202152252, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 24.5, 81.5; AI forecast: 19.627088415622712, 65.0223768748343 ; AI error: 961.6003350948785 BCD5 error: 112.8\n",
            "\tIntensity Truth: 50.0, AI forecast: 51.850048154592514, BCD5 forecast: 68.0\n",
            "\tTrajectory Truth: 29.6, 82.7; AI forecast: 19.524327218532562, 66.46528470665216 ; AI error: 1071.3033603680062 BCD5 error: 127.3\n",
            "Found AL112017 at 2017-09-08 18:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.34458640217781, BCD5 forecast: 46.0\n",
            "\tTrajectory Truth: 23.1, 80.2; AI forecast: 20.29156611561775, 63.693381989002226 ; AI error: 935.6036165776185 BCD5 error: 25.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.46904796361923, BCD5 forecast: 26.0\n",
            "\tTrajectory Truth: 25.6, 81.7; AI forecast: 20.156749027967454, 65.26686128303409 ; AI error: 965.0579040531854 BCD5 error: 108.4\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.77750891447067, BCD5 forecast: 72.0\n",
            "\tTrajectory Truth: 30.9, 83.5; AI forecast: 19.930081957578658, 66.42483273297547 ; AI error: 1133.8732549566205 BCD5 error: 188.8\n",
            "Found AL112017 at 2017-09-09 00:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 48.88297259807587, BCD5 forecast: 44.0\n",
            "\tTrajectory Truth: 23.4, 80.9; AI forecast: 20.181338730454446, 63.88412576206028 ; AI error: 967.4692395325001 BCD5 error: 30.0\n",
            "\tIntensity Truth: 80.0, AI forecast: 48.43413859605789, BCD5 forecast: 46.0\n",
            "\tTrajectory Truth: 26.8, 81.7; AI forecast: 19.84484590291977, 65.17266132608056 ; AI error: 1001.1095988749381 BCD5 error: 137.6\n",
            "\tIntensity Truth: 35.0, AI forecast: 49.30905416607857, BCD5 forecast: 79.0\n",
            "\tTrajectory Truth: 31.9, 84.4; AI forecast: 19.301284146308898, 66.26536409258843 ; AI error: 1236.2272693972782 BCD5 error: 194.0\n",
            "Found AL112017 at 2017-09-09 06:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 51.182197481393814, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 23.7, 81.3; AI forecast: 20.02024056315422, 64.07839154526592 ; AI error: 984.0181918968585 BCD5 error: 48.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 53.81161421537399, BCD5 forecast: 56.0\n",
            "\tTrajectory Truth: 28.2, 82.2; AI forecast: 20.046117573976517, 65.6225061237812 ; AI error: 1030.3672687375276 BCD5 error: 135.4\n",
            "Found AL112017 at 2017-09-09 12:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.23173946142197, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 24.5, 81.5; AI forecast: 20.430661145597696, 64.098304207623 ; AI error: 995.122610928915 BCD5 error: 54.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 53.609526455402374, BCD5 forecast: 52.0\n",
            "\tTrajectory Truth: 29.6, 82.7; AI forecast: 20.6569034576416, 65.58308210521936 ; AI error: 1072.3540846462906 BCD5 error: 169.6\n",
            "Found AL112017 at 2017-09-09 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.12069584429264, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 25.6, 81.7; AI forecast: 20.650625506043433, 63.810872790962456 ; AI error: 1030.4457353951234 BCD5 error: 69.7\n",
            "\tIntensity Truth: 45.0, AI forecast: 51.493059545755386, BCD5 forecast: 38.0\n",
            "\tTrajectory Truth: 30.9, 83.5; AI forecast: 20.93167297244072, 64.9191471375525 ; AI error: 1165.7594559379395 BCD5 error: 211.6\n",
            "Found AL112017 at 2017-09-10 00:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 50.396974347531796, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 26.8, 81.7; AI forecast: 20.93006963133812, 63.452501106262204 ; AI error: 1060.7778537132274 BCD5 error: 107.6\n",
            "\tIntensity Truth: 35.0, AI forecast: 49.20606128871441, BCD5 forecast: 58.0\n",
            "\tTrajectory Truth: 31.9, 84.4; AI forecast: 22.432054233551025, 64.28163821920752 ; AI error: 1212.7819084629875 BCD5 error: 263.2\n",
            "Found AL112017 at 2017-09-10 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.49266991019249, BCD5 forecast: 33.0\n",
            "\tTrajectory Truth: 28.2, 82.2; AI forecast: 22.19689531326294, 63.037203957699234 ; AI error: 1100.0934648808393 BCD5 error: 109.2\n",
            "Found AL112017 at 2017-09-10 12:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 49.56743959337473, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 29.6, 82.7; AI forecast: 21.823686170578004, 62.85103660319 ; AI error: 1168.638086348555 BCD5 error: 98.7\n",
            "Found AL112017 at 2017-09-10 18:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 55.62645375728607, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 30.9, 83.5; AI forecast: 22.291560029983522, 63.09958095401525 ; AI error: 1208.3756497397087 BCD5 error: 142.7\n",
            "Found AL112017 at 2017-09-11 00:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 49.47461728006601, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 31.9, 84.4; AI forecast: 20.72941220998764, 62.70945031093433 ; AI error: 1342.3083291173195 BCD5 error: 174.4\n",
            "Found AL112017 at 2017-09-11 06:00:00\n",
            "Found AL112017 at 2017-09-11 12:00:00\n",
            "Found AL112017 at 2017-09-11 18:00:00\n",
            "Found AL112017 at 2017-09-12 00:00:00\n",
            "Found AL122017 at 2017-09-05 12:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 49.95281314011663, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 13.1, 43.9; AI forecast: 20.430550798028708, 61.80677244942635 ; AI error: 1118.426090755733 BCD5 error: 44.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 49.651796258985996, BCD5 forecast: -31.0\n",
            "\tTrajectory Truth: 14.7, 49.9; AI forecast: 20.351329812407492, 61.04015684612095 ; AI error: 722.073772151929 BCD5 error: 135.5\n",
            "\tIntensity Truth: 130.0, AI forecast: 49.84960785135627, BCD5 forecast: -68.0\n",
            "\tTrajectory Truth: 16.1, 56.4; AI forecast: 20.612617439031602, 60.26937440931797 ; AI error: 349.274048488072 BCD5 error: 286.0\n",
            "\tIntensity Truth: 125.0, AI forecast: 50.01499911304563, BCD5 forecast: -67.0\n",
            "\tTrajectory Truth: 17.9, 60.8; AI forecast: 20.940662622451782, 59.66486959084868 ; AI error: 193.54396754645666 BCD5 error: 314.4\n",
            "\tIntensity Truth: 115.0, AI forecast: 49.67840064316988, BCD5 forecast: -52.0\n",
            "\tTrajectory Truth: 21.2, 65.3; AI forecast: 21.111932939291002, 59.228491867333645 ; AI error: 339.9873720317079 BCD5 error: 363.9\n",
            "Found AL122017 at 2017-09-05 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.237025152891874, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 13.7, 45.2; AI forecast: 20.447196174412966, 61.70924251358956 ; AI error: 1029.5944680111897 BCD5 error: 37.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.79157181084156, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 15.1, 51.5; AI forecast: 20.716768395900726, 60.946350063383576 ; AI error: 636.0943974946692 BCD5 error: 101.9\n",
            "\tIntensity Truth: 135.0, AI forecast: 51.250859797000885, BCD5 forecast: -69.0\n",
            "\tTrajectory Truth: 16.4, 57.8; AI forecast: 21.058378601074217, 60.27715500667691 ; AI error: 313.13256846952 BCD5 error: 202.4\n",
            "\tIntensity Truth: 120.0, AI forecast: 51.181446239352226, BCD5 forecast: -56.0\n",
            "\tTrajectory Truth: 18.6, 61.8; AI forecast: 21.240945446491242, 59.742511162161826 ; AI error: 196.5393340154158 BCD5 error: 189.4\n",
            "\tIntensity Truth: 105.0, AI forecast: 51.88301831483841, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 22.2, 66.5; AI forecast: 21.551296842098235, 59.500952487438916 ; AI error: 391.87122319358735 BCD5 error: 266.9\n",
            "Found AL122017 at 2017-09-06 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.20984695851803, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 14.1, 46.7; AI forecast: 20.913062065839767, 61.75241569764912 ; AI error: 953.2389448871804 BCD5 error: 56.8\n",
            "\tIntensity Truth: 105.0, AI forecast: 52.150857746601105, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 15.5, 53.2; AI forecast: 21.347230088710784, 61.13108159229159 ; AI error: 571.9145395602127 BCD5 error: 114.8\n",
            "\tIntensity Truth: 135.0, AI forecast: 52.4983286857605, BCD5 forecast: -63.0\n",
            "\tTrajectory Truth: 16.7, 58.9; AI forecast: 21.59820545911789, 60.564035607129334 ; AI error: 308.85216209647035 BCD5 error: 179.2\n",
            "\tIntensity Truth: 115.0, AI forecast: 53.59479635953903, BCD5 forecast: -45.0\n",
            "\tTrajectory Truth: 19.4, 62.9; AI forecast: 21.99072687625885, 60.2485070772469 ; AI error: 215.3320695355037 BCD5 error: 176.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.374626874923706, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 23.3, 67.6; AI forecast: 22.459684371948242, 60.158763421326874 ; AI error: 414.65553095128524 BCD5 error: 272.9\n",
            "Found AL122017 at 2017-09-06 06:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.66789531707764, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 14.4, 48.3; AI forecast: 20.97630441784859, 61.88729635123163 ; AI error: 871.117016874037 BCD5 error: 40.7\n",
            "\tIntensity Truth: 115.0, AI forecast: 52.629174292087555, BCD5 forecast: -43.0\n",
            "\tTrajectory Truth: 15.9, 54.9; AI forecast: 21.289417350292204, 61.359559998661275 ; AI error: 489.5710824857363 BCD5 error: 152.8\n",
            "\tIntensity Truth: 130.0, AI forecast: 54.293918907642365, BCD5 forecast: -54.0\n",
            "\tTrajectory Truth: 17.2, 59.9; AI forecast: 21.798340713977815, 60.990567025542255 ; AI error: 282.8969244339429 BCD5 error: 228.7\n",
            "\tIntensity Truth: 115.0, AI forecast: 55.7013338804245, BCD5 forecast: -41.0\n",
            "\tTrajectory Truth: 20.3, 64.0; AI forecast: 22.438057708740235, 60.79460382312536 ; AI error: 220.43855304406128 BCD5 error: 255.3\n",
            "\tIntensity Truth: 90.0, AI forecast: 56.96880042552948, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 24.3, 68.6; AI forecast: 23.206047916412352, 60.627387700974936 ; AI error: 442.95930408324386 BCD5 error: 343.5\n",
            "Found AL122017 at 2017-09-06 12:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 51.74237996339798, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 14.7, 49.9; AI forecast: 20.831029626727105, 61.94175159251317 ; AI error: 780.2581602274494 BCD5 error: 71.6\n",
            "\tIntensity Truth: 130.0, AI forecast: 54.05039280653, BCD5 forecast: -55.0\n",
            "\tTrajectory Truth: 16.1, 56.4; AI forecast: 21.401961982250214, 61.56274352762848 ; AI error: 432.8990918657582 BCD5 error: 210.1\n",
            "\tIntensity Truth: 125.0, AI forecast: 56.09632134437561, BCD5 forecast: -46.0\n",
            "\tTrajectory Truth: 17.9, 60.8; AI forecast: 22.165945506095888, 61.26469635814428 ; AI error: 257.4663575852994 BCD5 error: 272.4\n",
            "\tIntensity Truth: 115.0, AI forecast: 58.03094923496246, BCD5 forecast: -38.0\n",
            "\tTrajectory Truth: 21.2, 65.3; AI forecast: 23.12713756561279, 60.94557596184313 ; AI error: 268.3275002524958 BCD5 error: 340.5\n",
            "\tIntensity Truth: 85.0, AI forecast: 59.19787526130676, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 25.4, 69.4; AI forecast: 23.93635935783386, 60.6966817907989 ; AI error: 482.8271448998296 BCD5 error: 406.4\n",
            "Found AL122017 at 2017-09-06 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 53.37434947490692, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 15.1, 51.5; AI forecast: 21.18009062409401, 62.072364694159475 ; AI error: 704.6882990320609 BCD5 error: 68.1\n",
            "\tIntensity Truth: 135.0, AI forecast: 56.25929832458496, BCD5 forecast: -49.0\n",
            "\tTrajectory Truth: 16.4, 57.8; AI forecast: 22.060827445983886, 61.74468090366572 ; AI error: 406.77774787842174 BCD5 error: 187.0\n",
            "\tIntensity Truth: 120.0, AI forecast: 58.93718421459198, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 18.6, 61.8; AI forecast: 23.169206619262695, 61.326791039109224 ; AI error: 275.61764551715186 BCD5 error: 210.8\n",
            "\tIntensity Truth: 105.0, AI forecast: 60.818904638290405, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 22.2, 66.5; AI forecast: 24.159421539306642, 60.953868087381124 ; AI error: 327.90092996911136 BCD5 error: 293.0\n",
            "\tIntensity Truth: 80.0, AI forecast: 61.92191004753113, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 26.5, 69.5; AI forecast: 24.933175897598268, 60.77882394790649 ; AI error: 480.93874563828723 BCD5 error: 318.9\n",
            "Found AL122017 at 2017-09-07 00:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 53.74430447816849, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 15.5, 53.2; AI forecast: 21.41711469888687, 62.124608024302866 ; AI error: 619.8338276374279 BCD5 error: 42.2\n",
            "\tIntensity Truth: 135.0, AI forecast: 57.21033036708832, BCD5 forecast: -46.0\n",
            "\tTrajectory Truth: 16.7, 58.9; AI forecast: 22.619132947921752, 61.71730723883957 ; AI error: 389.4130946950382 BCD5 error: 104.8\n",
            "\tIntensity Truth: 115.0, AI forecast: 59.869205355644226, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 19.4, 62.9; AI forecast: 23.757989120483398, 61.29202534630895 ; AI error: 276.618608826509 BCD5 error: 94.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 61.730732917785645, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 23.3, 67.6; AI forecast: 24.71720132827759, 61.03892373107374 ; AI error: 369.72634789627716 BCD5 error: 184.6\n",
            "\tIntensity Truth: 75.0, AI forecast: 62.3531699180603, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 27.2, 69.4; AI forecast: 25.35214443206787, 60.943770084157585 ; AI error: 468.46636382042504 BCD5 error: 187.6\n",
            "Found AL122017 at 2017-09-07 06:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 54.99349236488342, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 15.9, 54.9; AI forecast: 21.888549637794494, 61.93843150911852 ; AI error: 537.5115886477226 BCD5 error: 34.6\n",
            "\tIntensity Truth: 130.0, AI forecast: 59.10277783870697, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 17.2, 59.9; AI forecast: 23.34832420349121, 61.43201202303171 ; AI error: 379.0848023140073 BCD5 error: 49.7\n",
            "\tIntensity Truth: 115.0, AI forecast: 62.41309404373169, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 20.3, 64.0; AI forecast: 24.743041372299196, 61.05019449666142 ; AI error: 312.8995700056747 BCD5 error: 33.8\n",
            "\tIntensity Truth: 90.0, AI forecast: 64.63854789733887, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 24.3, 68.6; AI forecast: 25.91088752746582, 60.8306676864624 ; AI error: 433.25789979489235 BCD5 error: 148.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 67.79099225997925, BCD5 forecast: 24.0\n",
            "\tTrajectory Truth: 27.6, 69.1; AI forecast: 27.65243740081787, 60.84396056085825 ; AI error: 439.1123640596473 BCD5 error: 108.7\n",
            "Found AL122017 at 2017-09-07 12:00:00\n",
            "\tIntensity Truth: 130.0, AI forecast: 55.84348917007446, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 16.1, 56.4; AI forecast: 22.16745755672455, 61.78637657370418 ; AI error: 475.3258871436479 BCD5 error: 34.0\n",
            "\tIntensity Truth: 125.0, AI forecast: 60.838425159454346, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 17.9, 60.8; AI forecast: 23.940106439590455, 61.27906558737158 ; AI error: 363.6434372499019 BCD5 error: 36.0\n",
            "\tIntensity Truth: 115.0, AI forecast: 64.79880809783936, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 21.2, 65.3; AI forecast: 25.592759084701537, 60.90367091894149 ; AI error: 358.0483320934974 BCD5 error: 34.1\n",
            "\tIntensity Truth: 85.0, AI forecast: 69.71834897994995, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 25.4, 69.4; AI forecast: 27.99409475326538, 60.66667984500527 ; AI error: 493.5133538163 BCD5 error: 141.4\n",
            "\tIntensity Truth: 70.0, AI forecast: 72.91779279708862, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 27.7, 68.3; AI forecast: 29.997009086608884, 60.8729082942009 ; AI error: 414.1120242246373 BCD5 error: 63.8\n",
            "Found AL122017 at 2017-09-07 18:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 56.75800919532776, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 16.4, 57.8; AI forecast: 22.401226592063903, 61.78816295433789 ; AI error: 425.1731008033198 BCD5 error: 32.1\n",
            "\tIntensity Truth: 120.0, AI forecast: 62.37178564071655, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 18.6, 61.8; AI forecast: 24.32552614212036, 61.30833193585276 ; AI error: 344.85804414217307 BCD5 error: 53.6\n",
            "\tIntensity Truth: 105.0, AI forecast: 68.89610767364502, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 22.2, 66.5; AI forecast: 27.13825206756592, 60.90190364345908 ; AI error: 425.5507721020465 BCD5 error: 16.4\n",
            "\tIntensity Truth: 80.0, AI forecast: 73.83626937866211, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 26.5, 69.5; AI forecast: 29.77481174468994, 60.815548163652416 ; AI error: 499.8759948517626 BCD5 error: 99.8\n",
            "\tIntensity Truth: 70.0, AI forecast: 75.85251331329346, BCD5 forecast: 30.0\n",
            "\tTrajectory Truth: 27.4, 67.4; AI forecast: 31.316592025756833, 61.10318297669291 ; AI error: 404.679138645777 BCD5 error: 156.2\n",
            "Found AL122017 at 2017-09-08 00:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 57.269322872161865, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 16.7, 58.9; AI forecast: 22.454394698143005, 61.82266470212489 ; AI error: 382.9763061513288 BCD5 error: 49.8\n",
            "\tIntensity Truth: 115.0, AI forecast: 65.39927005767822, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 19.4, 62.9; AI forecast: 25.512926149368287, 61.35340471081435 ; AI error: 376.90820314925594 BCD5 error: 85.7\n",
            "\tIntensity Truth: 100.0, AI forecast: 71.96974039077759, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 23.3, 67.6; AI forecast: 28.57554531097412, 61.09094656817615 ; AI error: 472.9312396527015 BCD5 error: 58.3\n",
            "\tIntensity Truth: 75.0, AI forecast: 75.56361675262451, BCD5 forecast: 37.0\n",
            "\tTrajectory Truth: 27.2, 69.4; AI forecast: 30.655269145965576, 61.13123913630843 ; AI error: 481.30770478023874 BCD5 error: 112.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 76.38278245925903, BCD5 forecast: 31.0\n",
            "\tTrajectory Truth: 26.8, 66.7; AI forecast: 31.5275915145874, 61.46276210695505 ; AI error: 394.8039304062696 BCD5 error: 291.2\n",
            "Found AL122017 at 2017-09-08 06:00:00\n",
            "\tIntensity Truth: 130.0, AI forecast: 60.41669726371765, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 17.2, 59.9; AI forecast: 23.742638635635377, 61.835083540342744 ; AI error: 407.6016375136343 BCD5 error: 60.0\n",
            "\tIntensity Truth: 115.0, AI forecast: 69.11634683609009, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 20.3, 64.0; AI forecast: 27.277283954620362, 61.403967620432375 ; AI error: 442.4871622586968 BCD5 error: 109.9\n",
            "\tIntensity Truth: 90.0, AI forecast: 74.69995498657227, BCD5 forecast: 30.0\n",
            "\tTrajectory Truth: 24.3, 68.6; AI forecast: 29.98722448348999, 61.1716581903398 ; AI error: 523.2921510566073 BCD5 error: 121.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 77.5373387336731, BCD5 forecast: 48.0\n",
            "\tTrajectory Truth: 27.6, 69.1; AI forecast: 31.645498752593994, 61.19653682038188 ; AI error: 478.49083473397894 BCD5 error: 192.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 79.9443507194519, BCD5 forecast: 33.0\n",
            "\tTrajectory Truth: 26.3, 66.2; AI forecast: 33.12917156219483, 61.49871364179998 ; AI error: 477.5685977536384 BCD5 error: 391.6\n",
            "Found AL122017 at 2017-09-08 12:00:00\n",
            "\tIntensity Truth: 125.0, AI forecast: 61.55358910560608, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 17.9, 60.8; AI forecast: 24.27467851638794, 61.884767417050895 ; AI error: 387.52577353895555 BCD5 error: 70.9\n",
            "\tIntensity Truth: 115.0, AI forecast: 70.1414704322815, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 21.2, 65.3; AI forecast: 27.77275457382202, 61.45857366994023 ; AI error: 446.8886315487627 BCD5 error: 115.9\n",
            "\tIntensity Truth: 85.0, AI forecast: 75.74516296386719, BCD5 forecast: 38.0\n",
            "\tTrajectory Truth: 25.4, 69.4; AI forecast: 30.377844905853273, 61.190585026890034 ; AI error: 528.0385254271656 BCD5 error: 175.1\n",
            "\tIntensity Truth: 70.0, AI forecast: 80.65901517868042, BCD5 forecast: 54.0\n",
            "\tTrajectory Truth: 27.7, 68.3; AI forecast: 32.98048858642578, 61.100505316257475 ; AI error: 489.32882109704 BCD5 error: 252.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 83.79579067230225, BCD5 forecast: 35.0\n",
            "\tTrajectory Truth: 25.8, 65.8; AI forecast: 35.108558654785156, 61.68357841689139 ; AI error: 597.9476689643442 BCD5 error: 467.3\n",
            "Found AL122017 at 2017-09-08 18:00:00\n",
            "\tIntensity Truth: 120.0, AI forecast: 60.78575849533081, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 18.6, 61.8; AI forecast: 23.906119680404665, 62.05392778227105 ; AI error: 318.8983489683458 BCD5 error: 59.4\n",
            "\tIntensity Truth: 105.0, AI forecast: 68.5992693901062, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 22.2, 66.5; AI forecast: 26.844575786590575, 61.85014711935073 ; AI error: 377.11468066536224 BCD5 error: 109.3\n",
            "\tIntensity Truth: 80.0, AI forecast: 75.48816442489624, BCD5 forecast: 43.0\n",
            "\tTrajectory Truth: 26.5, 69.5; AI forecast: 29.98901958465576, 61.752039522118864 ; AI error: 460.0736318558019 BCD5 error: 181.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 80.29078722000122, BCD5 forecast: 52.0\n",
            "\tTrajectory Truth: 27.4, 67.4; AI forecast: 32.68482360839844, 62.24256460005417 ; AI error: 415.23517001229516 BCD5 error: 233.6\n",
            "\tIntensity Truth: 70.0, AI forecast: 78.31098556518555, BCD5 forecast: 31.0\n",
            "\tTrajectory Truth: 25.4, 65.6; AI forecast: 32.50811595916748, 62.87969570178538 ; AI error: 450.0108418092632 BCD5 error: 470.8\n",
            "Found AL122017 at 2017-09-09 00:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 59.528303146362305, BCD5 forecast: 21.0\n",
            "\tTrajectory Truth: 19.4, 62.9; AI forecast: 23.267819690704346, 62.225666485633695 ; AI error: 235.26639189876926 BCD5 error: 43.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 68.47953677177429, BCD5 forecast: 29.0\n",
            "\tTrajectory Truth: 23.3, 67.6; AI forecast: 26.80124702453613, 62.19217402869835 ; AI error: 361.4650065940393 BCD5 error: 134.6\n",
            "\tIntensity Truth: 75.0, AI forecast: 75.27690887451172, BCD5 forecast: 48.0\n",
            "\tTrajectory Truth: 27.2, 69.4; AI forecast: 30.128321838378906, 62.62711465293541 ; AI error: 397.66746400376167 BCD5 error: 158.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 74.86840963363647, BCD5 forecast: 46.0\n",
            "\tTrajectory Truth: 26.8, 66.7; AI forecast: 30.377658653259275, 63.15684565678239 ; AI error: 284.6216470290898 BCD5 error: 197.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 74.78473663330078, BCD5 forecast: 23.0\n",
            "\tTrajectory Truth: 25.1, 65.7; AI forecast: 30.474592781066896, 63.428377178683874 ; AI error: 344.48520733641067 BCD5 error: 457.9\n",
            "Found AL122017 at 2017-09-09 06:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 60.41816234588623, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 20.3, 64.0; AI forecast: 23.989360570907593, 62.4745264143683 ; AI error: 237.19219829259254 BCD5 error: 32.9\n",
            "\tIntensity Truth: 90.0, AI forecast: 68.87990236282349, BCD5 forecast: 35.0\n",
            "\tTrajectory Truth: 24.3, 68.6; AI forecast: 27.643369102478026, 62.990917368792 ; AI error: 363.18250369689054 BCD5 error: 143.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 69.76717591285706, BCD5 forecast: 47.0\n",
            "\tTrajectory Truth: 27.6, 69.1; AI forecast: 28.091152381896972, 63.481162164360285 ; AI error: 299.7214028210905 BCD5 error: 96.4\n",
            "\tIntensity Truth: 70.0, AI forecast: 70.46373844146729, BCD5 forecast: 38.0\n",
            "\tTrajectory Truth: 26.3, 66.2; AI forecast: 28.285560035705565, 63.76071922145783 ; AI error: 176.48732783097546 BCD5 error: 242.8\n",
            "\tIntensity Truth: 70.0, AI forecast: 69.18943643569946, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 24.9, 65.9; AI forecast: 27.90323085784912, 64.07835960537194 ; AI error: 205.19922818522525 BCD5 error: 507.7\n",
            "Found AL122017 at 2017-09-09 12:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 59.88154590129852, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 21.2, 65.3; AI forecast: 24.13733525276184, 63.040314374305304 ; AI error: 216.26360704405968 BCD5 error: 58.8\n",
            "\tIntensity Truth: 85.0, AI forecast: 62.2681450843811, BCD5 forecast: 34.0\n",
            "\tTrajectory Truth: 25.4, 69.4; AI forecast: 24.683082723617552, 63.55574191473424 ; AI error: 320.78150623023026 BCD5 error: 158.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 63.921449184417725, BCD5 forecast: 41.0\n",
            "\tTrajectory Truth: 27.7, 68.3; AI forecast: 25.007817792892457, 63.8803448036313 ; AI error: 287.47672763142634 BCD5 error: 27.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 63.49748492240906, BCD5 forecast: 31.0\n",
            "\tTrajectory Truth: 25.8, 65.8; AI forecast: 24.77308578491211, 64.22740271165966 ; AI error: 105.30701537154566 BCD5 error: 336.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 62.973012924194336, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 24.8, 66.3; AI forecast: 24.425248384475708, 64.43892926424742 ; AI error: 104.04828758063643 BCD5 error: 574.7\n",
            "Found AL122017 at 2017-09-09 18:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 52.385404855012894, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 22.2, 66.5; AI forecast: 20.019592517614363, 63.02872460167855 ; AI error: 234.3785077770732 BCD5 error: 63.2\n",
            "\tIntensity Truth: 80.0, AI forecast: 54.294850528240204, BCD5 forecast: 34.0\n",
            "\tTrajectory Truth: 26.5, 69.5; AI forecast: 19.912042701244353, 63.589174165949224 ; AI error: 512.4932985324454 BCD5 error: 120.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 54.465152621269226, BCD5 forecast: 36.0\n",
            "\tTrajectory Truth: 27.4, 67.4; AI forecast: 19.66146503686905, 64.14099216982721 ; AI error: 497.9793089751522 BCD5 error: 104.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 54.74433332681656, BCD5 forecast: 27.0\n",
            "\tTrajectory Truth: 25.4, 65.6; AI forecast: 19.447639298439025, 64.50733315199614 ; AI error: 362.4844295826905 BCD5 error: 424.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 54.812547862529755, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 25.0, 66.9; AI forecast: 19.209847390651703, 64.91009560674429 ; AI error: 364.81939747247424 BCD5 error: 620.2\n",
            "Found AL122017 at 2017-09-10 00:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.7764787375927, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 23.3, 67.6; AI forecast: 20.19771314561367, 62.80626603253185 ; AI error: 325.7726104096196 BCD5 error: 62.8\n",
            "\tIntensity Truth: 75.0, AI forecast: 52.02968254685402, BCD5 forecast: 34.0\n",
            "\tTrajectory Truth: 27.2, 69.4; AI forecast: 19.846536403894426, 63.3018198557198 ; AI error: 554.4087648349465 BCD5 error: 60.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 52.55567282438278, BCD5 forecast: 33.0\n",
            "\tTrajectory Truth: 26.8, 66.7; AI forecast: 19.544907128810884, 63.65474784597754 ; AI error: 466.84114901162116 BCD5 error: 232.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 52.999227643013, BCD5 forecast: 24.0\n",
            "\tTrajectory Truth: 25.1, 65.7; AI forecast: 19.231567013263703, 64.05025289058685 ; AI error: 364.0734636721017 BCD5 error: 516.3\n",
            "\tIntensity Truth: 60.0, AI forecast: 53.279639184474945, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 25.4, 67.6; AI forecast: 19.22654620409012, 64.39064339473843 ; AI error: 411.2382210513501 BCD5 error: 672.3\n",
            "Found AL122017 at 2017-09-10 06:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 49.880477990955114, BCD5 forecast: 25.0\n",
            "\tTrajectory Truth: 24.3, 68.6; AI forecast: 19.913541108369827, 62.771086835674936 ; AI error: 417.61778880052117 BCD5 error: 48.7\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.249335523694754, BCD5 forecast: 39.0\n",
            "\tTrajectory Truth: 27.6, 69.1; AI forecast: 19.436078703403474, 63.138471302017564 ; AI error: 589.641309505624 BCD5 error: 42.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.73116846382618, BCD5 forecast: 32.0\n",
            "\tTrajectory Truth: 26.3, 66.2; AI forecast: 19.00955984592438, 63.57555856145918 ; AI error: 461.1958034918426 BCD5 error: 354.7\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.18420921266079, BCD5 forecast: 23.0\n",
            "\tTrajectory Truth: 24.9, 65.9; AI forecast: 18.919158744812012, 63.961790553480384 ; AI error: 374.9509970374239 BCD5 error: 604.6\n",
            "\tIntensity Truth: 60.0, AI forecast: 51.18691235780716, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 25.8, 68.2; AI forecast: 18.976097297668456, 64.33840383663774 ; AI error: 462.3151134445819 BCD5 error: 728.2\n",
            "Found AL122017 at 2017-09-10 12:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 50.14451978728175, BCD5 forecast: 31.0\n",
            "\tTrajectory Truth: 25.4, 69.4; AI forecast: 19.936579686403274, 62.736197939142585 ; AI error: 493.6830598276994 BCD5 error: 31.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.40594719350338, BCD5 forecast: 38.0\n",
            "\tTrajectory Truth: 27.7, 68.3; AI forecast: 19.40809817314148, 63.23937638327479 ; AI error: 570.2726637250205 BCD5 error: 152.4\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.69593720138073, BCD5 forecast: 32.0\n",
            "\tTrajectory Truth: 25.8, 65.8; AI forecast: 19.208929812908174, 63.70845918655395 ; AI error: 412.35864515401005 BCD5 error: 468.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.62802888453007, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 24.8, 66.3; AI forecast: 19.164867722988127, 64.18668267801404 ; AI error: 358.18750512803877 BCD5 error: 683.4\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.12041127309203, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 26.3, 69.0; AI forecast: 19.16724761724472, 64.57122763618827 ; AI error: 493.38089384681444 BCD5 error: 782.7\n",
            "Found AL122017 at 2017-09-10 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.53214932233095, BCD5 forecast: 24.0\n",
            "\tTrajectory Truth: 26.5, 69.5; AI forecast: 19.88255141377449, 62.940130781941114 ; AI error: 537.2876110920379 BCD5 error: 28.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.232710897922516, BCD5 forecast: 29.0\n",
            "\tTrajectory Truth: 27.4, 67.4; AI forecast: 19.611472737789153, 63.51351590529084 ; AI error: 514.1501486139283 BCD5 error: 245.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.750224485993385, BCD5 forecast: 25.0\n",
            "\tTrajectory Truth: 25.4, 65.6; AI forecast: 19.56096682548523, 64.08617468997836 ; AI error: 360.48465255381285 BCD5 error: 551.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 47.965175807476044, BCD5 forecast: 23.0\n",
            "\tTrajectory Truth: 25.0, 66.9; AI forecast: 19.64501622915268, 64.57384827509522 ; AI error: 346.4760164398128 BCD5 error: 738.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.524841487407684, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 26.8, 69.9; AI forecast: 20.12253541946411, 64.67033614739775 ; AI error: 493.5003142543566 BCD5 error: 849.2\n",
            "Found AL122017 at 2017-09-11 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 48.92635889351368, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 27.2, 69.4; AI forecast: 20.19513598382473, 62.92907497379929 ; AI error: 550.6145109729389 BCD5 error: 59.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 47.89422303438187, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 26.8, 66.7; AI forecast: 20.109243351221085, 63.52088392935693 ; AI error: 438.15724981934306 BCD5 error: 348.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.79662764072418, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 25.1, 65.7; AI forecast: 20.1894169986248, 64.01969385817647 ; AI error: 309.17320179117496 BCD5 error: 615.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 45.37850171327591, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 25.4, 67.6; AI forecast: 20.788173046708106, 64.20168227925896 ; AI error: 334.464389640788 BCD5 error: 769.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 44.337118268013, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 27.2, 70.7; AI forecast: 21.137765556573868, 63.99796826392412 ; AI error: 516.7502665016067 BCD5 error: 903.5\n",
            "Found AL122017 at 2017-09-11 06:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.0106046795845, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 27.6, 69.1; AI forecast: 20.275067573785783, 62.8909984562546 ; AI error: 556.0950876856255 BCD5 error: 99.4\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.21326804161072, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 26.3, 66.2; AI forecast: 20.26533904671669, 63.36606146581471 ; AI error: 394.55141690962705 BCD5 error: 425.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 44.42415237426758, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 24.9, 65.9; AI forecast: 20.885096764564516, 63.56319027841091 ; AI error: 273.5025776908174 BCD5 error: 661.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 43.182929158210754, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 25.8, 68.2; AI forecast: 21.402287590503693, 63.42268296182155 ; AI error: 372.4818525427095 BCD5 error: 785.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 42.11113750934601, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 27.7, 71.4; AI forecast: 21.631706476211548, 63.209467317909 ; AI error: 576.2772386949081 BCD5 error: 939.8\n",
            "Found AL122017 at 2017-09-11 12:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 47.21019446849823, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 27.7, 68.3; AI forecast: 20.366286993026733, 62.71706040706485 ; AI error: 536.0863362903327 BCD5 error: 144.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 44.6059250831604, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 25.8, 65.8; AI forecast: 20.929673928022385, 62.86116556655615 ; AI error: 334.24460935655685 BCD5 error: 490.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 42.84780561923981, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 24.8, 66.3; AI forecast: 21.471148562431335, 62.72058878559619 ; AI error: 281.0399224146946 BCD5 error: 732.7\n",
            "\tIntensity Truth: 60.0, AI forecast: 41.50501012802124, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 26.3, 69.0; AI forecast: 21.824924516677857, 62.54104741597548 ; AI error: 444.35843722897175 BCD5 error: 877.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 40.72870373725891, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 28.2, 71.8; AI forecast: 21.750700104236603, 62.402007766906166 ; AI error: 641.0968477353979 BCD5 error: 1066.5\n",
            "Found AL122017 at 2017-09-11 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.29120975732803, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 27.4, 67.4; AI forecast: 21.051173371076583, 62.29246480279835 ; AI error: 472.6223547397518 BCD5 error: 179.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 43.66952896118164, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 25.4, 65.6; AI forecast: 21.625901186466216, 62.04526442894712 ; AI error: 299.37360846648306 BCD5 error: 500.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 41.75654351711273, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 25.0, 66.9; AI forecast: 22.052636003494264, 61.77669810000807 ; AI error: 332.90205533968947 BCD5 error: 739.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 40.631482005119324, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 26.8, 69.9; AI forecast: 22.096121978759765, 61.56357337702065 ; AI error: 535.8384778332536 BCD5 error: 906.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 40.29892385005951, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 28.6, 72.0; AI forecast: 21.92601795196533, 61.386234904825685 ; AI error: 701.3538465200633 BCD5 error: 1088.2\n",
            "Found AL122017 at 2017-09-12 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.62959933280945, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 26.8, 66.7; AI forecast: 21.17572562098503, 62.156381017621605 ; AI error: 419.60224653417566 BCD5 error: 194.6\n",
            "\tIntensity Truth: 70.0, AI forecast: 43.84340941905975, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 25.1, 65.7; AI forecast: 21.780771386623382, 61.83911139611155 ; AI error: 291.4202486302928 BCD5 error: 450.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 42.09610641002655, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 25.4, 67.6; AI forecast: 22.065809202194213, 61.51645791847258 ; AI error: 389.6288266087389 BCD5 error: 646.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 41.34583055973053, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 27.2, 70.7; AI forecast: 22.15362329483032, 61.203500892966986 ; AI error: 599.8685254153759 BCD5 error: 821.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 40.917765498161316, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 29.1, 72.0; AI forecast: 22.25780258178711, 61.023302281647915 ; AI error: 721.5498191582884 BCD5 error: 971.4\n",
            "Found AL122017 at 2017-09-12 06:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.56202644109726, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 26.3, 66.2; AI forecast: 21.16952913403511, 61.98424703357741 ; AI error: 385.3746240599424 BCD5 error: 176.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 44.147127866744995, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 24.9, 65.9; AI forecast: 21.62752071619034, 61.55054209623486 ; AI error: 310.05453440162245 BCD5 error: 400.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 42.891157269477844, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 25.8, 68.2; AI forecast: 21.92599675655365, 61.09453265406191 ; AI error: 454.08335118225165 BCD5 error: 592.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 42.0178085565567, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 27.7, 71.4; AI forecast: 22.259676122665404, 60.771643644198775 ; AI error: 663.8505073647768 BCD5 error: 796.0\n",
            "\tIntensity Truth: 75.0, AI forecast: 41.57933533191681, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 29.8, 72.0; AI forecast: 22.28058180809021, 60.69931477457285 ; AI error: 757.83436331158 BCD5 error: 911.8\n",
            "Found AL122017 at 2017-09-12 12:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 47.43193119764328, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 25.8, 65.8; AI forecast: 21.21512451171875, 61.82233878783882 ; AI error: 351.7044137533277 BCD5 error: 147.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 45.876064002513885, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 24.8, 66.3; AI forecast: 21.797644102573393, 61.214913526549935 ; AI error: 333.3028535877192 BCD5 error: 342.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 44.63328301906586, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 26.3, 69.0; AI forecast: 22.390413928031922, 60.74536730088293 ; AI error: 508.7255049818011 BCD5 error: 557.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 43.933414816856384, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 28.2, 71.8; AI forecast: 22.671271991729736, 60.49022741094231 ; AI error: 696.7895348957892 BCD5 error: 776.2\n",
            "\tIntensity Truth: 80.0, AI forecast: 44.257548451423645, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 30.5, 71.9; AI forecast: 22.80956988334656, 60.492467906326056 ; AI error: 765.9366589674909 BCD5 error: 854.0\n",
            "Found AL122017 at 2017-09-12 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.37435409426689, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 25.4, 65.6; AI forecast: 21.311885154247285, 61.602911912277335 ; AI error: 329.7781722761273 BCD5 error: 83.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.81514084339142, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 25.0, 66.9; AI forecast: 22.116103076934813, 61.017360873520374 ; AI error: 367.0856272430847 BCD5 error: 240.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 45.793588161468506, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 26.8, 69.9; AI forecast: 22.614168214797974, 60.63349938988685 ; AI error: 564.2172096823617 BCD5 error: 448.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 45.82956075668335, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 28.6, 72.0; AI forecast: 22.958959817886353, 60.53575841560959 ; AI error: 705.7681977328701 BCD5 error: 639.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 45.66418528556824, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 31.2, 71.8; AI forecast: 22.919405508041383, 60.735435659438366 ; AI error: 771.917281302345 BCD5 error: 683.3\n",
            "Found AL122017 at 2017-09-13 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.26200142502785, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 25.1, 65.7; AI forecast: 21.523984801769256, 61.66685185693204 ; AI error: 309.0709214519833 BCD5 error: 52.3\n",
            "\tIntensity Truth: 60.0, AI forecast: 47.039379477500916, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 25.4, 67.6; AI forecast: 22.246597385406496, 61.18204208500683 ; AI error: 400.04401557023886 BCD5 error: 184.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.914701759815216, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 27.2, 70.7; AI forecast: 22.814918804168702, 60.9937901135534 ; AI error: 589.8281273465924 BCD5 error: 376.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 46.59111708402634, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 29.1, 72.0; AI forecast: 22.98613634109497, 61.10701057128608 ; AI error: 692.2956252407804 BCD5 error: 512.0\n",
            "\tIntensity Truth: 80.0, AI forecast: 46.35786324739456, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 31.9, 71.6; AI forecast: 23.037004160881043, 61.41079207845032 ; AI error: 759.3214677781314 BCD5 error: 535.3\n",
            "Found AL122017 at 2017-09-13 06:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.96632008254528, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 24.9, 65.9; AI forecast: 21.416438782215117, 61.77056250516325 ; AI error: 309.32364811712495 BCD5 error: 57.4\n",
            "\tIntensity Truth: 60.0, AI forecast: 48.889658972620964, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 25.8, 68.2; AI forecast: 22.20516119003296, 61.46297324337065 ; AI error: 427.8201166888892 BCD5 error: 184.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.52575123310089, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 27.7, 71.4; AI forecast: 22.592292046546937, 61.460930265858764 ; AI error: 620.8047680899776 BCD5 error: 366.1\n",
            "\tIntensity Truth: 75.0, AI forecast: 48.22474658489227, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 29.8, 72.0; AI forecast: 22.8632239818573, 61.6612510593608 ; AI error: 694.3697648892175 BCD5 error: 457.1\n",
            "\tIntensity Truth: 75.0, AI forecast: 48.27458828687668, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 32.7, 71.4; AI forecast: 22.982193326950075, 61.96700909240171 ; AI error: 768.1151498981022 BCD5 error: 466.3\n",
            "Found AL122017 at 2017-09-13 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.17738465219736, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 24.8, 66.3; AI forecast: 21.49166496992111, 61.94417997971177 ; AI error: 311.8562814970681 BCD5 error: 67.7\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.89189511165023, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 26.3, 69.0; AI forecast: 22.057678842544554, 61.849308893084526 ; AI error: 467.04843552281875 BCD5 error: 205.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.608081094920635, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 28.2, 71.8; AI forecast: 22.507683801651, 61.96066449210048 ; AI error: 633.4730074957888 BCD5 error: 345.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.64143376797438, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 30.5, 71.9; AI forecast: 22.800490736961365, 62.197665926907206 ; AI error: 695.6497414621933 BCD5 error: 392.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.625678695738316, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 33.5, 71.2; AI forecast: 22.869066572189332, 62.53231214890256 ; AI error: 785.2428204604121 BCD5 error: 400.5\n",
            "Found AL122017 at 2017-09-13 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.70912644639611, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 25.0, 66.9; AI forecast: 21.144975250959398, 62.17704354492016 ; AI error: 348.69532813082355 BCD5 error: 65.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.45617787539959, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 26.8, 69.9; AI forecast: 21.689141702651977, 62.20587467560544 ; AI error: 520.9121348586165 BCD5 error: 197.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.544577710330486, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 28.6, 72.0; AI forecast: 22.097096467018126, 62.369066714029756 ; AI error: 651.8543872525498 BCD5 error: 284.9\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.58864275366068, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 31.2, 71.8; AI forecast: 22.28941011428833, 62.65834760731086 ; AI error: 724.9216339450169 BCD5 error: 308.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.59252554923296, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 34.2, 71.2; AI forecast: 22.281843185424805, 63.002142869867384 ; AI error: 835.8975030272404 BCD5 error: 328.1\n",
            "Found AL122017 at 2017-09-14 00:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.95364980306476, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 25.4, 67.6; AI forecast: 21.24400576353073, 62.318533065298105 ; AI error: 383.3928449702864 BCD5 error: 64.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.18408635631204, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 27.2, 70.7; AI forecast: 21.82476488351822, 62.407059389352796 ; AI error: 555.9595868139751 BCD5 error: 184.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.35109240561724, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 29.1, 72.0; AI forecast: 22.177115654945375, 62.62568367710337 ; AI error: 655.4440451592053 BCD5 error: 225.4\n",
            "\tIntensity Truth: 80.0, AI forecast: 50.47293234616518, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 31.9, 71.6; AI forecast: 22.32045705318451, 62.913948200829324 ; AI error: 738.4594845989544 BCD5 error: 234.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.52223492413759, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 34.9, 71.4; AI forecast: 22.52637114524841, 63.203522382676596 ; AI error: 858.347242624455 BCD5 error: 285.9\n",
            "Found AL122017 at 2017-09-14 06:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.51571790128946, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 25.8, 68.2; AI forecast: 21.192263340950014, 62.360366962943225 ; AI error: 424.05717296289475 BCD5 error: 69.6\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.841413512825966, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 27.7, 71.4; AI forecast: 21.651713860034942, 62.50871728705242 ; AI error: 605.5938164466859 BCD5 error: 183.2\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.074058040976524, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 29.8, 72.0; AI forecast: 21.91062641143799, 62.739011344127356 ; AI error: 688.4545194964612 BCD5 error: 183.4\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.21995560824871, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 32.7, 71.4; AI forecast: 22.23711085319519, 62.991796352714296 ; AI error: 770.827598497412 BCD5 error: 188.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.15914322435856, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 35.6, 71.6; AI forecast: 22.442353868484496, 63.245899175852536 ; AI error: 902.6350156480416 BCD5 error: 267.4\n",
            "Found AL122017 at 2017-09-14 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.235611367970705, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 26.3, 69.0; AI forecast: 20.95781016945839, 62.458224025508386 ; AI error: 481.8658370519002 BCD5 error: 64.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.34387927502394, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 28.2, 71.8; AI forecast: 21.22015391588211, 62.66017886055633 ; AI error: 650.8003861199835 BCD5 error: 149.3\n",
            "\tIntensity Truth: 80.0, AI forecast: 50.34523416310549, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 30.5, 71.9; AI forecast: 21.566094410419463, 62.89051014818251 ; AI error: 723.2220997688172 BCD5 error: 140.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.08739626035094, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 33.5, 71.2; AI forecast: 21.798348140716552, 63.13707927130162 ; AI error: 822.3511818689834 BCD5 error: 153.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 48.86703468859196, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 36.3, 71.7; AI forecast: 21.715330469608308, 63.291464471817015 ; AI error: 979.6054278357691 BCD5 error: 258.7\n",
            "Found AL122017 at 2017-09-14 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.964862330816686, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 26.8, 69.9; AI forecast: 20.779178285598753, 62.53369423514232 ; AI error: 542.3853173554004 BCD5 error: 53.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.806747045367956, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 28.6, 72.0; AI forecast: 21.127647751569747, 62.756370186619456 ; AI error: 673.9096011748466 BCD5 error: 122.3\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.381004609167576, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 31.2, 71.8; AI forecast: 21.368525636196136, 63.00713470298797 ; AI error: 755.9450005672397 BCD5 error: 131.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 47.97412395477295, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 34.2, 71.2; AI forecast: 21.312300884723662, 63.196259094029664 ; AI error: 882.1108674383628 BCD5 error: 158.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 46.83938592672348, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 37.0, 71.5; AI forecast: 21.18431151509285, 63.32873646654188 ; AI error: 1040.7518062672882 BCD5 error: 274.9\n",
            "Found AL122017 at 2017-09-15 00:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.542841613292694, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 27.2, 70.7; AI forecast: 20.90453708767891, 62.55118426633999 ; AI error: 584.8971738069274 BCD5 error: 70.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 48.84579233825207, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 29.1, 72.0; AI forecast: 21.184374266862868, 62.7786857381463 ; AI error: 690.1493004868269 BCD5 error: 115.5\n",
            "\tIntensity Truth: 80.0, AI forecast: 47.22367346286774, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 31.9, 71.6; AI forecast: 21.192322421073914, 62.94866412226111 ; AI error: 792.4941649113265 BCD5 error: 127.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 45.84489405155182, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 34.9, 71.4; AI forecast: 21.1539894759655, 63.06145192179829 ; AI error: 935.2229784266137 BCD5 error: 191.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 44.413474798202515, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 37.6, 71.2; AI forecast: 21.242955923080444, 62.92198510114103 ; AI error: 1072.0677805061625 BCD5 error: 291.1\n",
            "Found AL122017 at 2017-09-15 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.19950269162655, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 27.7, 71.4; AI forecast: 20.807367432117463, 62.538447523303326 ; AI error: 637.2107601015458 BCD5 error: 70.0\n",
            "\tIntensity Truth: 75.0, AI forecast: 47.49391943216324, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 29.8, 72.0; AI forecast: 20.858742690086366, 62.686157408449795 ; AI error: 736.6815953277899 BCD5 error: 83.5\n",
            "\tIntensity Truth: 75.0, AI forecast: 46.06844276189804, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 32.7, 71.4; AI forecast: 20.8993010699749, 62.76773902531713 ; AI error: 845.3352929629392 BCD5 error: 98.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 44.622971415519714, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 35.6, 71.6; AI forecast: 21.09879520535469, 62.575776955951 ; AI error: 991.4805005555133 BCD5 error: 195.1\n",
            "\tIntensity Truth: 60.0, AI forecast: 44.48380172252655, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 38.1, 70.8; AI forecast: 21.287444841861724, 62.55490972185507 ; AI error: 1095.98063107217 BCD5 error: 269.8\n",
            "Found AL122017 at 2017-09-15 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.326271176338196, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 28.2, 71.8; AI forecast: 20.673577988147734, 62.425919541576874 ; AI error: 682.6794947743961 BCD5 error: 35.7\n",
            "\tIntensity Truth: 80.0, AI forecast: 46.96175843477249, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 30.5, 71.9; AI forecast: 20.829705268144608, 62.448967126570636 ; AI error: 773.0044808134211 BCD5 error: 31.7\n",
            "\tIntensity Truth: 70.0, AI forecast: 45.6489560008049, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 33.5, 71.2; AI forecast: 21.154551738500594, 62.178906823787834 ; AI error: 882.7437031816512 BCD5 error: 39.3\n",
            "\tIntensity Truth: 60.0, AI forecast: 45.773058235645294, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 36.3, 71.7; AI forecast: 21.50871993303299, 62.059861009474844 ; AI error: 1021.0472225274623 BCD5 error: 155.0\n",
            "\tIntensity Truth: 60.0, AI forecast: 46.88521683216095, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 38.7, 70.2; AI forecast: 21.99381306171417, 62.09459461541846 ; AI error: 1086.2134058903418 BCD5 error: 211.4\n",
            "Found AL122017 at 2017-09-15 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.15195472538471, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 28.6, 72.0; AI forecast: 20.998577457666396, 62.33163376759039 ; AI error: 696.5616355988678 BCD5 error: 20.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 48.15678685903549, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.2, 71.8; AI forecast: 21.570326066017152, 62.02211596630514 ; AI error: 780.7673273072559 BCD5 error: 42.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.68265315890312, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 34.2, 71.2; AI forecast: 22.17240676879883, 61.821044438332315 ; AI error: 875.2329602660562 BCD5 error: 11.6\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.29229735955596, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 37.0, 71.5; AI forecast: 22.916376900672912, 61.773023787513374 ; AI error: 984.0223464126582 BCD5 error: 109.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 52.178033739328384, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 39.2, 69.4; AI forecast: 23.69668664932251, 61.93131567304954 ; AI error: 1005.3989065156308 BCD5 error: 137.3\n",
            "Found AL122017 at 2017-09-16 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.386749900877476, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 29.1, 72.0; AI forecast: 21.35280147790909, 62.03350234255194 ; AI error: 713.101515687226 BCD5 error: 33.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 50.14023186638951, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.9, 71.6; AI forecast: 22.201772928237915, 61.782210915908216 ; AI error: 783.1637620552632 BCD5 error: 56.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.89305305480957, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 34.9, 71.4; AI forecast: 23.15642294883728, 61.66550053488463 ; AI error: 869.7162000355712 BCD5 error: 24.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 53.851517736911774, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 37.6, 71.2; AI forecast: 24.113078355789185, 61.75355911646038 ; AI error: 943.5877955129714 BCD5 error: 113.2\n",
            "\tIntensity Truth: 55.0, AI forecast: 53.854219019412994, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.4, 68.5; AI forecast: 24.580378103256226, 61.876516049169 ; AI error: 950.81418747527 BCD5 error: 113.0\n",
            "Found AL122017 at 2017-09-16 06:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.504859924316406, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 29.8, 72.0; AI forecast: 21.642928028106688, 62.06162985255941 ; AI error: 726.557283306481 BCD5 error: 28.6\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.63835275173187, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 32.7, 71.4; AI forecast: 22.858472204208375, 61.877015477418894 ; AI error: 777.0268757452747 BCD5 error: 32.6\n",
            "\tIntensity Truth: 65.0, AI forecast: 55.74735939502716, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 35.6, 71.6; AI forecast: 24.038354349136352, 61.88937286073342 ; AI error: 857.8219441563722 BCD5 error: 77.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 55.798627734184265, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 38.1, 70.8; AI forecast: 24.698739290237427, 61.934029780235136 ; AI error: 922.899926470017 BCD5 error: 159.2\n",
            "\tIntensity Truth: 55.0, AI forecast: 55.50061047077179, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 39.7, 68.1; AI forecast: 25.108976984024046, 61.97963867513462 ; AI error: 928.7315780367963 BCD5 error: 166.2\n",
            "Found AL122017 at 2017-09-16 12:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.95560926198959, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 30.5, 71.9; AI forecast: 21.999424004554747, 62.02910289159044 ; AI error: 736.1943608368325 BCD5 error: 12.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 55.74665069580078, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 33.5, 71.2; AI forecast: 23.498945474624634, 61.90197696993127 ; AI error: 774.586820249308 BCD5 error: 42.3\n",
            "\tIntensity Truth: 60.0, AI forecast: 56.4530223608017, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 36.3, 71.7; AI forecast: 24.49944701194763, 61.80206234380603 ; AI error: 873.3033668227686 BCD5 error: 139.7\n",
            "\tIntensity Truth: 60.0, AI forecast: 56.83253288269043, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 38.7, 70.2; AI forecast: 25.26920528411865, 61.67475663777441 ; AI error: 914.7570596519175 BCD5 error: 191.5\n",
            "\tIntensity Truth: 55.0, AI forecast: 58.26404571533203, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 39.7, 68.0; AI forecast: 26.10991144180298, 61.603408401273185 ; AI error: 876.7079338269313 BCD5 error: 221.8\n",
            "Found AL122017 at 2017-09-16 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.92733037471771, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 31.2, 71.8; AI forecast: 22.42479271888733, 62.0338367071934 ; AI error: 741.8727570135078 BCD5 error: 26.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 55.808871388435364, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 34.2, 71.2; AI forecast: 23.92883982658386, 61.73183798007667 ; AI error: 791.0680607923002 BCD5 error: 77.0\n",
            "\tIntensity Truth: 60.0, AI forecast: 57.448058128356934, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 37.0, 71.5; AI forecast: 25.240080785751342, 61.37615032419562 ; AI error: 875.8604775254074 BCD5 error: 194.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 60.307698249816895, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 39.2, 69.4; AI forecast: 26.7309850692749, 61.04258222058415 ; AI error: 857.9205161570789 BCD5 error: 219.1\n",
            "\tIntensity Truth: 50.0, AI forecast: 63.895862102508545, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 39.5, 68.0; AI forecast: 28.3930251121521, 60.96867389380932 ; AI error: 752.5981366454857 BCD5 error: 293.9\n",
            "Found AL122017 at 2017-09-17 00:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.43325158953667, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.9, 71.6; AI forecast: 22.19161148071289, 61.88341932818293 ; AI error: 780.0355203153741 BCD5 error: 31.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 54.688052237033844, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 34.9, 71.4; AI forecast: 23.765096426010132, 61.404298580437896 ; AI error: 847.8470501155757 BCD5 error: 124.6\n",
            "\tIntensity Truth: 60.0, AI forecast: 58.26715290546417, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 37.6, 71.2; AI forecast: 25.59259886741638, 60.961392969638105 ; AI error: 889.6920972392585 BCD5 error: 257.8\n",
            "\tIntensity Truth: 55.0, AI forecast: 62.705817222595215, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 39.4, 68.5; AI forecast: 27.716153144836426, 60.73944597765803 ; AI error: 800.9918195131418 BCD5 error: 278.0\n",
            "\tIntensity Truth: 45.0, AI forecast: 63.54567766189575, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 39.5, 68.2; AI forecast: 28.659881687164308, 60.82449682056904 ; AI error: 746.3994546350367 BCD5 error: 439.4\n",
            "Found AL122017 at 2017-09-17 06:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.20615530014038, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 32.7, 71.4; AI forecast: 22.386459398269654, 61.66889008264988 ; AI error: 806.4465539678083 BCD5 error: 37.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 57.515740394592285, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 35.6, 71.6; AI forecast: 24.555632877349854, 61.051113307476044 ; AI error: 859.0786490348075 BCD5 error: 181.1\n",
            "\tIntensity Truth: 60.0, AI forecast: 62.59914040565491, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 38.1, 70.8; AI forecast: 27.073812007904053, 60.65437142476439 ; AI error: 836.4702987077532 BCD5 error: 302.6\n",
            "\tIntensity Truth: 55.0, AI forecast: 64.09401297569275, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 39.7, 68.1; AI forecast: 28.451294136047363, 60.566123065352436 ; AI error: 771.6068695840117 BCD5 error: 350.7\n",
            "\tIntensity Truth: 45.0, AI forecast: 64.88354682922363, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.6, 68.6; AI forecast: 29.36193981170654, 60.51006580814719 ; AI error: 732.8350591320824 BCD5 error: 565.5\n",
            "Found AL122017 at 2017-09-17 12:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 55.42470335960388, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 33.5, 71.2; AI forecast: 23.03024082183838, 61.48967318218201 ; AI error: 810.7495343321888 BCD5 error: 45.4\n",
            "\tIntensity Truth: 60.0, AI forecast: 61.40115976333618, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 36.3, 71.7; AI forecast: 25.954980993270873, 60.87060293927789 ; AI error: 832.8049479880616 BCD5 error: 213.6\n",
            "\tIntensity Truth: 60.0, AI forecast: 63.67751598358154, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 38.7, 70.2; AI forecast: 27.763378524780272, 60.55761843174696 ; AI error: 814.7883108450956 BCD5 error: 319.6\n",
            "\tIntensity Truth: 55.0, AI forecast: 65.17738461494446, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 39.7, 68.0; AI forecast: 29.112533569335938, 60.28649673983455 ; AI error: 740.9537289749436 BCD5 error: 404.8\n",
            "\tIntensity Truth: 40.0, AI forecast: 65.85967063903809, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 39.7, 69.0; AI forecast: 29.919722270965575, 60.23271916806698 ; AI error: 728.2707528491654 BCD5 error: 642.3\n",
            "Found AL122017 at 2017-09-17 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 56.72289431095123, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 34.2, 71.2; AI forecast: 23.632465219497682, 61.56197848878801 ; AI error: 810.9232243513287 BCD5 error: 59.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 59.75871741771698, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 37.0, 71.5; AI forecast: 25.768126583099367, 61.02286756597459 ; AI error: 860.8034034661953 BCD5 error: 235.4\n",
            "\tIntensity Truth: 60.0, AI forecast: 61.89817667007446, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.2, 69.4; AI forecast: 27.466579341888426, 60.55353894308209 ; AI error: 831.5749391624696 BCD5 error: 322.6\n",
            "\tIntensity Truth: 50.0, AI forecast: 63.16881537437439, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 39.5, 68.0; AI forecast: 28.630097961425783, 60.30641273334622 ; AI error: 755.8093727830245 BCD5 error: 464.8\n",
            "Found AL122017 at 2017-09-18 00:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 52.80966639518738, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 34.9, 71.4; AI forecast: 22.530221366882323, 61.78913692515343 ; AI error: 897.5873489759986 BCD5 error: 99.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 54.96591359376907, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 37.6, 71.2; AI forecast: 24.348400163650513, 61.32017115317285 ; AI error: 942.9357933400437 BCD5 error: 263.6\n",
            "\tIntensity Truth: 55.0, AI forecast: 56.38348996639252, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 39.4, 68.5; AI forecast: 25.77219409942627, 61.02862429097294 ; AI error: 900.4347282512241 BCD5 error: 349.9\n",
            "\tIntensity Truth: 45.0, AI forecast: 56.18457615375519, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 39.5, 68.2; AI forecast: 26.467104530334474, 60.975220494344825 ; AI error: 862.1823121025074 BCD5 error: 555.5\n",
            "Found AL122017 at 2017-09-18 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.98270887136459, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 35.6, 71.6; AI forecast: 22.332648754119873, 61.73604998011142 ; AI error: 948.973588437284 BCD5 error: 125.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 53.354177474975586, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 38.1, 70.8; AI forecast: 23.89196581840515, 61.27460771873593 ; AI error: 982.5084308078214 BCD5 error: 284.2\n",
            "\tIntensity Truth: 55.0, AI forecast: 53.21267992258072, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 39.7, 68.1; AI forecast: 24.816763353347778, 61.018561558797956 ; AI error: 962.3620406493549 BCD5 error: 386.0\n",
            "\tIntensity Truth: 45.0, AI forecast: 51.336220651865005, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 39.6, 68.6; AI forecast: 25.65404052734375, 60.90157258547842 ; AI error: 922.4456509012783 BCD5 error: 636.8\n",
            "Found AL122017 at 2017-09-18 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.93295365571976, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 36.3, 71.7; AI forecast: 22.050782322883606, 61.733561999537045 ; AI error: 1001.0059870408578 BCD5 error: 122.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 50.59478897601366, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 38.7, 70.2; AI forecast: 23.091431140899658, 61.28440533019602 ; AI error: 1042.3076293082495 BCD5 error: 243.4\n",
            "\tIntensity Truth: 55.0, AI forecast: 48.736664205789566, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 39.7, 68.0; AI forecast: 24.1689254283905, 60.95013092383742 ; AI error: 998.4067785650675 BCD5 error: 374.6\n",
            "\tIntensity Truth: 40.0, AI forecast: 47.47800529003143, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 39.7, 69.0; AI forecast: 24.775084829330446, 60.49222179278731 ; AI error: 993.606052226665 BCD5 error: 638.2\n",
            "Found AL122017 at 2017-09-18 18:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.23500321805477, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 37.0, 71.5; AI forecast: 21.618133985996245, 61.641690568625926 ; AI error: 1056.4199516720694 BCD5 error: 82.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 47.293081283569336, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 39.2, 69.4; AI forecast: 22.88000957965851, 61.0033493515104 ; AI error: 1069.5670000265002 BCD5 error: 158.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.138997972011566, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 39.5, 68.0; AI forecast: 23.722949266433716, 60.281626395881176 ; AI error: 1025.1245798732975 BCD5 error: 343.1\n",
            "Found AL122017 at 2017-09-19 00:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 47.9906190931797, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 37.6, 71.2; AI forecast: 22.121538281440735, 61.38379493206739 ; AI error: 1059.04571250051 BCD5 error: 46.3\n",
            "\tIntensity Truth: 55.0, AI forecast: 47.008907198905945, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 39.4, 68.5; AI forecast: 23.35115303993225, 60.369634716212744 ; AI error: 1048.6621253064266 BCD5 error: 113.2\n",
            "\tIntensity Truth: 45.0, AI forecast: 46.637635231018066, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 39.5, 68.2; AI forecast: 24.220237684249877, 59.59841266497969 ; AI error: 1015.6079036406381 BCD5 error: 355.2\n",
            "Found AL122017 at 2017-09-19 06:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.47611417621374, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 38.1, 70.8; AI forecast: 22.093179154396058, 61.110267656669016 ; AI error: 1083.2860737211681 BCD5 error: 41.2\n",
            "\tIntensity Truth: 55.0, AI forecast: 49.28801216185093, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 39.7, 68.1; AI forecast: 23.36199641227722, 60.069437531381844 ; AI error: 1062.3654410760919 BCD5 error: 128.2\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.639047026634216, BCD5 forecast: 20.0\n",
            "\tTrajectory Truth: 39.6, 68.6; AI forecast: 24.434543657302857, 59.34301343485713 ; AI error: 1023.8155051518808 BCD5 error: 409.0\n",
            "Found AL122017 at 2017-09-19 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.832444842904806, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 38.7, 70.2; AI forecast: 22.045394515991212, 61.085045623779294 ; AI error: 1104.314395130888 BCD5 error: 48.6\n",
            "\tIntensity Truth: 55.0, AI forecast: 51.09975799918175, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.7, 68.0; AI forecast: 23.412226533889772, 60.1355648688972 ; AI error: 1056.3282942181233 BCD5 error: 192.4\n",
            "\tIntensity Truth: 40.0, AI forecast: 53.1889745593071, BCD5 forecast: 21.0\n",
            "\tTrajectory Truth: 39.7, 69.0; AI forecast: 24.990753984451295, 59.52658454626798 ; AI error: 1003.9479922777301 BCD5 error: 492.3\n",
            "Found AL122017 at 2017-09-19 18:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 51.68825417757034, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 39.2, 69.4; AI forecast: 22.251630878448488, 61.122065528482196 ; AI error: 1102.353607265968 BCD5 error: 48.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 54.024387896060944, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 39.5, 68.0; AI forecast: 24.189385175704956, 60.247892185300586 ; AI error: 999.6394355723115 BCD5 error: 264.3\n",
            "Found AL122017 at 2017-09-20 00:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 52.524605095386505, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.4, 68.5; AI forecast: 22.7767276763916, 61.23655339255929 ; AI error: 1064.6657589021247 BCD5 error: 45.9\n",
            "\tIntensity Truth: 45.0, AI forecast: 53.32871377468109, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 39.5, 68.2; AI forecast: 24.420784997940064, 60.44949797168374 ; AI error: 986.6754709076292 BCD5 error: 293.3\n",
            "Found AL122017 at 2017-09-20 06:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 50.42051859200001, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 39.7, 68.1; AI forecast: 22.161912536621095, 61.375621454417704 ; AI error: 1107.584765805833 BCD5 error: 70.8\n",
            "\tIntensity Truth: 45.0, AI forecast: 49.36395548284054, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 39.6, 68.6; AI forecast: 23.32332863807678, 60.61506438851356 ; AI error: 1058.2035015867134 BCD5 error: 373.6\n",
            "Found AL122017 at 2017-09-20 12:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 48.65092948079109, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 39.7, 68.0; AI forecast: 21.82982532978058, 61.29795480147004 ; AI error: 1126.3639893690172 BCD5 error: 134.9\n",
            "\tIntensity Truth: 40.0, AI forecast: 48.37121471762657, BCD5 forecast: 23.0\n",
            "\tTrajectory Truth: 39.7, 69.0; AI forecast: 23.063447189331054, 60.43484422266483 ; AI error: 1089.7266867098122 BCD5 error: 476.9\n",
            "Found AL122017 at 2017-09-20 18:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 49.89072298631072, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 39.5, 68.0; AI forecast: 22.141694450378417, 61.19288861826062 ; AI error: 1098.8064444979782 BCD5 error: 175.9\n",
            "Found AL122017 at 2017-09-21 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 49.48823634535074, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 39.5, 68.2; AI forecast: 22.330090284347534, 61.152940530702466 ; AI error: 1091.9706605749416 BCD5 error: 178.5\n",
            "Found AL122017 at 2017-09-21 06:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 48.25091615319252, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 39.6, 68.6; AI forecast: 22.069274067878723, 61.2190748244524 ; AI error: 1118.149296675998 BCD5 error: 140.3\n",
            "Found AL122017 at 2017-09-21 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 48.620741963386536, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 39.7, 69.0; AI forecast: 22.073621129989625, 61.16244480460882 ; AI error: 1131.5151063851827 BCD5 error: 97.5\n",
            "Found AL122017 at 2017-09-21 18:00:00\n",
            "Found AL122017 at 2017-09-22 00:00:00\n",
            "Found AL122017 at 2017-09-22 06:00:00\n",
            "Found AL122017 at 2017-09-22 12:00:00\n",
            "Found AL132017 at 2017-09-06 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 53.54847878217697, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 21.6, 94.6; AI forecast: 22.871492195129395, 63.209615260362625 ; AI error: 1742.9514001977163 BCD5 error: 37.4\n",
            "\tIntensity Truth: 90.0, AI forecast: 55.899749398231506, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 21.1, 96.2; AI forecast: 24.784510946273805, 63.85901610665023 ; AI error: 1797.6515879057984 BCD5 error: 183.7\n",
            "Found AL132017 at 2017-09-07 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.19276064634323, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 21.5, 95.0; AI forecast: 22.780253624916078, 63.1085873182863 ; AI error: 1771.8633086722007 BCD5 error: 49.1\n",
            "\tIntensity Truth: 70.0, AI forecast: 57.278034687042236, BCD5 forecast: 19.0\n",
            "\tTrajectory Truth: 20.8, 96.9; AI forecast: 25.015807962417604, 63.8429051734507 ; AI error: 1841.1209865013832 BCD5 error: 197.1\n",
            "Found AL132017 at 2017-09-07 06:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 55.40752947330475, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 21.4, 95.3; AI forecast: 23.160629320144654, 63.11306777019053 ; AI error: 1787.7865116604562 BCD5 error: 53.1\n",
            "\tIntensity Truth: 35.0, AI forecast: 60.46188473701477, BCD5 forecast: 42.0\n",
            "\tTrajectory Truth: 20.3, 97.4; AI forecast: 25.671669435501098, 63.681211517751215 ; AI error: 1886.2435089164665 BCD5 error: 220.9\n",
            "Found AL132017 at 2017-09-07 12:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 56.28731310367584, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 21.1, 95.7; AI forecast: 23.29225516319275, 62.95544101335108 ; AI error: 1821.2704073919451 BCD5 error: 71.6\n",
            "Found AL132017 at 2017-09-07 18:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 59.80788230895996, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 21.1, 96.2; AI forecast: 25.142907667160035, 62.94807999450713 ; AI error: 1847.4290229082499 BCD5 error: 58.5\n",
            "Found AL132017 at 2017-09-08 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 54.57498162984848, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 20.8, 96.9; AI forecast: 22.70054335594177, 63.18169528618455 ; AI error: 1879.8369861817794 BCD5 error: 47.6\n",
            "Found AL132017 at 2017-09-08 06:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 54.97265636920929, BCD5 forecast: 54.0\n",
            "\tTrajectory Truth: 20.3, 97.4; AI forecast: 22.680013847351074, 63.22807230614126 ; AI error: 1910.3015475957936 BCD5 error: 58.6\n",
            "Found AL132017 at 2017-09-08 12:00:00\n",
            "Found AL142017 at 2017-09-16 12:00:00\n",
            "Found AL142017 at 2017-09-16 18:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 48.70240554213524, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 16.8, 44.4; AI forecast: 19.576540696620942, 60.20905542969703 ; AI error: 916.6468217523895 BCD5 error: 24.9\n",
            "Found AL142017 at 2017-09-17 00:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 49.87850835546851, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 17.6, 45.0; AI forecast: 20.10026726126671, 60.54832431450486 ; AI error: 895.7497146386116 BCD5 error: 64.2\n",
            "Found AL142017 at 2017-09-17 06:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 49.68092802911997, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 18.3, 45.2; AI forecast: 20.041668206453323, 60.489692858606574 ; AI error: 873.0519062966804 BCD5 error: 113.2\n",
            "Found AL142017 at 2017-09-19 18:00:00\n",
            "Found AL142017 at 2017-09-20 00:00:00\n",
            "Found AL142017 at 2017-09-20 06:00:00\n",
            "Found AL142017 at 2017-09-23 00:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 50.3272345662117, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 31.9, 50.1; AI forecast: 22.222362518310547, 60.57115565612912 ; AI error: 805.9498933305186 BCD5 error: 106.6\n",
            "\tIntensity Truth: 85.0, AI forecast: 50.43472111225128, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 31.2, 49.6; AI forecast: 23.72810492515564, 58.89250475764274 ; AI error: 667.5216867715892 BCD5 error: 284.7\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.44357681274414, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 30.3, 51.0; AI forecast: 25.21802954673767, 57.45872840434313 ; AI error: 459.0082622534203 BCD5 error: 539.4\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.2925691306591, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 29.9, 55.1; AI forecast: 26.424318504333495, 56.43665728420019 ; AI error: 220.34302587167159 BCD5 error: 863.7\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.88716673851013, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 31.4, 57.2; AI forecast: 27.47102336883545, 55.739790718257424 ; AI error: 247.93768722753924 BCD5 error: 1061.5\n",
            "Found AL142017 at 2017-09-23 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.71729652583599, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 31.7, 50.2; AI forecast: 22.263016653060912, 60.4808700017631 ; AI error: 788.8216161928062 BCD5 error: 108.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.08381921052933, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 31.0, 49.5; AI forecast: 24.060055780410767, 58.74709437340498 ; AI error: 644.485686892985 BCD5 error: 267.7\n",
            "\tIntensity Truth: 85.0, AI forecast: 53.162646889686584, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 30.1, 52.0; AI forecast: 25.618558073043822, 57.34533590227365 ; AI error: 390.9185560471607 BCD5 error: 538.2\n",
            "\tIntensity Truth: 95.0, AI forecast: 53.89717906713486, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 30.1, 56.0; AI forecast: 27.061111450195312, 56.219405652582644 ; AI error: 182.82250838255445 BCD5 error: 838.9\n",
            "\tIntensity Truth: 90.0, AI forecast: 53.62484037876129, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 32.1, 57.3; AI forecast: 27.824703693389893, 55.54676441848278 ; AI error: 272.39525663880755 BCD5 error: 979.1\n",
            "Found AL142017 at 2017-09-23 12:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 52.34064266085625, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 31.5, 50.1; AI forecast: 22.680271530151366, 60.3901975415647 ; AI error: 762.7109943274597 BCD5 error: 104.0\n",
            "\tIntensity Truth: 80.0, AI forecast: 54.1540002822876, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 30.8, 49.7; AI forecast: 24.647041511535644, 58.65432681292295 ; AI error: 602.0488094259917 BCD5 error: 261.9\n",
            "\tIntensity Truth: 90.0, AI forecast: 55.51621079444885, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 29.9, 53.2; AI forecast: 26.537178230285644, 57.136707650125025 ; AI error: 290.02631205537756 BCD5 error: 540.7\n",
            "\tIntensity Truth: 100.0, AI forecast: 55.82939922809601, BCD5 forecast: -38.0\n",
            "\tTrajectory Truth: 30.3, 56.6; AI forecast: 27.776672554016113, 56.04711049944162 ; AI error: 154.2558137062446 BCD5 error: 797.6\n",
            "\tIntensity Truth: 85.0, AI forecast: 56.7475426197052, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 33.0, 57.2; AI forecast: 28.76824264526367, 55.568418490886685 ; AI error: 267.6118385085259 BCD5 error: 871.6\n",
            "Found AL142017 at 2017-09-23 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.648756206035614, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 31.3, 49.8; AI forecast: 22.746720147132873, 60.431656307727096 ; AI error: 765.3838193870126 BCD5 error: 98.8\n",
            "\tIntensity Truth: 75.0, AI forecast: 54.76199120283127, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 30.6, 50.2; AI forecast: 24.994704008102417, 58.619371636211866 ; AI error: 559.3314198529747 BCD5 error: 228.5\n",
            "\tIntensity Truth: 95.0, AI forecast: 55.7931512594223, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 29.9, 54.2; AI forecast: 26.637487602233886, 57.17985511571169 ; AI error: 251.36805629309512 BCD5 error: 471.2\n",
            "\tIntensity Truth: 100.0, AI forecast: 57.43082046508789, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 30.8, 57.0; AI forecast: 28.099455642700196, 56.31416485160589 ; AI error: 166.05808616790426 BCD5 error: 676.8\n",
            "\tIntensity Truth: 80.0, AI forecast: 58.28814208507538, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 34.3, 56.6; AI forecast: 28.940127754211424, 56.025092743337154 ; AI error: 323.146780998298 BCD5 error: 672.6\n",
            "Found AL142017 at 2017-09-24 00:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 53.00441116094589, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 31.2, 49.6; AI forecast: 23.041836881637572, 60.35940395668149 ; AI error: 754.5275293415257 BCD5 error: 73.9\n",
            "\tIntensity Truth: 80.0, AI forecast: 54.867351055145264, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 30.3, 51.0; AI forecast: 25.058721494674682, 58.62659867405891 ; AI error: 513.0296628209235 BCD5 error: 186.3\n",
            "\tIntensity Truth: 95.0, AI forecast: 57.32119679450989, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 29.9, 55.1; AI forecast: 26.971540641784667, 57.397480620443815 ; AI error: 213.5927981626507 BCD5 error: 431.1\n",
            "\tIntensity Truth: 95.0, AI forecast: 59.012712240219116, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 31.4, 57.2; AI forecast: 28.343326377868653, 56.722966885566706 ; AI error: 185.19625580101228 BCD5 error: 583.7\n",
            "\tIntensity Truth: 75.0, AI forecast: 59.95141088962555, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 35.7, 55.5; AI forecast: 29.332132720947264, 56.535586304962635 ; AI error: 385.8998636445344 BCD5 error: 501.0\n",
            "Found AL142017 at 2017-09-24 06:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.64057004451752, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 31.0, 49.5; AI forecast: 22.932877445220946, 60.46752167344093 ; AI error: 760.1442098099509 BCD5 error: 55.2\n",
            "\tIntensity Truth: 85.0, AI forecast: 57.78212130069733, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 30.1, 52.0; AI forecast: 25.438255548477173, 58.932203106582165 ; AI error: 462.3810509268685 BCD5 error: 207.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 61.2467098236084, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 30.1, 56.0; AI forecast: 27.584138107299804, 57.867532789707184 ; AI error: 180.16902974652578 BCD5 error: 467.8\n",
            "\tIntensity Truth: 90.0, AI forecast: 64.18703317642212, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 32.1, 57.3; AI forecast: 29.521954154968263, 57.272150044143196 ; AI error: 154.79376719068588 BCD5 error: 587.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 68.33112359046936, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 37.3, 53.8; AI forecast: 31.904706954956055, 57.32694557756185 ; AI error: 367.7744937896449 BCD5 error: 410.6\n",
            "Found AL142017 at 2017-09-24 12:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 55.87531268596649, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 30.8, 49.7; AI forecast: 23.3841411113739, 60.61629613190889 ; AI error: 733.254692447128 BCD5 error: 44.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 60.83267688751221, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 29.9, 53.2; AI forecast: 26.007267904281616, 59.21715340092778 ; AI error: 395.4386861163849 BCD5 error: 292.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 65.16637086868286, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 30.3, 56.6; AI forecast: 28.464589500427245, 58.231558619439596 ; AI error: 139.3863545942027 BCD5 error: 538.0\n",
            "\tIntensity Truth: 85.0, AI forecast: 70.67033290863037, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 33.0, 57.2; AI forecast: 31.53426456451416, 57.80394614338874 ; AI error: 93.1912590233758 BCD5 error: 613.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 72.4173355102539, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 39.0, 51.2; AI forecast: 33.129665565490725, 57.78656143546104 ; AI error: 475.54712411448884 BCD5 error: 322.5\n",
            "Found AL142017 at 2017-09-24 18:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 56.344760060310364, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 30.6, 50.2; AI forecast: 23.286739015579222, 60.76579354889691 ; AI error: 715.2989348146452 BCD5 error: 85.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 61.92754626274109, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 29.9, 54.2; AI forecast: 26.07240390777588, 59.47310854196548 ; AI error: 361.81537513156906 BCD5 error: 366.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 68.67348194122314, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 30.8, 57.0; AI forecast: 29.66190528869629, 58.65561303049326 ; AI error: 109.74913060723175 BCD5 error: 577.2\n",
            "\tIntensity Truth: 80.0, AI forecast: 71.65457725524902, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 34.3, 56.6; AI forecast: 31.860465621948244, 58.22335261404514 ; AI error: 167.6930734825695 BCD5 error: 594.5\n",
            "\tIntensity Truth: 55.0, AI forecast: 71.57844543457031, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 41.0, 48.2; AI forecast: 32.617231941223146, 58.026517041027546 ; AI error: 689.3360959129303 BCD5 error: 215.7\n",
            "Found AL142017 at 2017-09-25 00:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 57.21042573451996, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 30.3, 51.0; AI forecast: 23.542274236679077, 60.87469232343137 ; AI error: 665.8498518925537 BCD5 error: 125.6\n",
            "\tIntensity Truth: 95.0, AI forecast: 65.55800557136536, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 29.9, 55.1; AI forecast: 27.667338943481447, 59.748878174275156 ; AI error: 278.9140761855872 BCD5 error: 388.4\n",
            "\tIntensity Truth: 95.0, AI forecast: 70.0952935218811, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 31.4, 57.2; AI forecast: 30.538181686401366, 58.880963678658006 ; AI error: 100.826063778923 BCD5 error: 545.0\n",
            "\tIntensity Truth: 75.0, AI forecast: 71.39416933059692, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 35.7, 55.5; AI forecast: 31.97485942840576, 58.28355990201234 ; AI error: 263.2050983346533 BCD5 error: 481.2\n",
            "\tIntensity Truth: 50.0, AI forecast: 72.36371994018555, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 43.2, 44.5; AI forecast: 33.044006729125975, 58.09741145670414 ; AI error: 883.4544740602952 BCD5 error: 157.0\n",
            "Found AL142017 at 2017-09-25 06:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 59.69272971153259, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 30.1, 52.0; AI forecast: 24.872347402572633, 61.168605579063296 ; AI error: 580.1651595279435 BCD5 error: 133.1\n",
            "\tIntensity Truth: 95.0, AI forecast: 65.4371702671051, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 30.1, 56.0; AI forecast: 28.16946325302124, 60.01937889978289 ; AI error: 240.53305420775376 BCD5 error: 353.6\n",
            "\tIntensity Truth: 90.0, AI forecast: 67.52956628799438, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 32.1, 57.3; AI forecast: 29.963826751708986, 59.12893737331032 ; AI error: 159.06355431860808 BCD5 error: 443.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 68.98186206817627, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 37.3, 53.8; AI forecast: 31.32277908325195, 58.6616902321577 ; AI error: 432.186249573315 BCD5 error: 291.1\n",
            "Found AL142017 at 2017-09-25 12:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 56.66073977947235, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 29.9, 53.2; AI forecast: 23.65017123222351, 61.16540806256234 ; AI error: 568.0948834733763 BCD5 error: 133.3\n",
            "\tIntensity Truth: 100.0, AI forecast: 59.702908396720886, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 30.3, 56.6; AI forecast: 25.62716073989868, 60.14644853472709 ; AI error: 337.70588197397694 BCD5 error: 278.4\n",
            "\tIntensity Truth: 85.0, AI forecast: 61.91528081893921, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 33.0, 57.2; AI forecast: 27.3289213180542, 59.48691421821713 ; AI error: 360.56311428835545 BCD5 error: 308.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 60.268940925598145, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 39.0, 51.2; AI forecast: 27.727409744262694, 59.14215147569775 ; AI error: 784.4943641207464 BCD5 error: 116.7\n",
            "Found AL142017 at 2017-09-25 18:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.80551731586456, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 29.9, 54.2; AI forecast: 22.12843246459961, 61.31910097077488 ; AI error: 604.0312183891177 BCD5 error: 95.2\n",
            "\tIntensity Truth: 100.0, AI forecast: 55.064952969551086, BCD5 forecast: -35.0\n",
            "\tTrajectory Truth: 30.8, 57.0; AI forecast: 23.787576913833618, 60.52721145674586 ; AI error: 461.0879683451614 BCD5 error: 165.1\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.56155186891556, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 34.3, 56.6; AI forecast: 24.316838693618774, 60.07998161539435 ; AI error: 626.34002207726 BCD5 error: 119.7\n",
            "\tIntensity Truth: 55.0, AI forecast: 51.72473564743996, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 41.0, 48.2; AI forecast: 24.531685400009156, 59.95336795672774 ; AI error: 1150.6305425234693 BCD5 error: 348.2\n",
            "Found AL142017 at 2017-09-26 00:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.51398801803589, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 29.9, 55.1; AI forecast: 22.220947599411012, 61.474288685619825 ; AI error: 574.8433761499231 BCD5 error: 50.1\n",
            "\tIntensity Truth: 95.0, AI forecast: 51.47468715906143, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 31.4, 57.2; AI forecast: 22.92147397994995, 60.84991725310683 ; AI error: 545.0010223305088 BCD5 error: 46.5\n",
            "\tIntensity Truth: 75.0, AI forecast: 50.2308957837522, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 35.7, 55.5; AI forecast: 23.342624139785766, 60.52805600240826 ; AI error: 786.7338581995875 BCD5 error: 128.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.417057394981384, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 43.2, 44.5; AI forecast: 23.439006519317626, 60.288622996211046 ; AI error: 1421.1141803001783 BCD5 error: 662.6\n",
            "Found AL142017 at 2017-09-26 06:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 49.029235169291496, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 30.1, 56.0; AI forecast: 21.086950474977492, 61.65609614662826 ; AI error: 621.5333196349814 BCD5 error: 12.0\n",
            "\tIntensity Truth: 90.0, AI forecast: 48.16248416900635, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 32.1, 57.3; AI forecast: 21.536558938026428, 61.19137607812881 ; AI error: 667.4638706195049 BCD5 error: 54.8\n",
            "\tIntensity Truth: 70.0, AI forecast: 47.020007371902466, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 37.3, 53.8; AI forecast: 21.794648373126982, 60.74780844934284 ; AI error: 998.367267485991 BCD5 error: 314.3\n",
            "Found AL142017 at 2017-09-26 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 49.87212484702468, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 30.3, 56.6; AI forecast: 21.16575664281845, 61.836534552089866 ; AI error: 616.9974760472571 BCD5 error: 16.7\n",
            "\tIntensity Truth: 85.0, AI forecast: 49.21462781727314, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 33.0, 57.2; AI forecast: 21.58628821372986, 61.264173758774994 ; AI error: 718.5780109795386 BCD5 error: 113.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.24002858996391, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 39.0, 51.2; AI forecast: 22.428026270866393, 61.009809244051574 ; AI error: 1114.697183599264 BCD5 error: 477.5\n",
            "Found AL142017 at 2017-09-26 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.36310683935881, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 30.8, 57.0; AI forecast: 21.18720226883888, 61.68893314991146 ; AI error: 629.9830573424297 BCD5 error: 16.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.333576023578644, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 34.3, 56.6; AI forecast: 22.32864248752594, 61.21012205258012 ; AI error: 758.6773662620993 BCD5 error: 154.3\n",
            "\tIntensity Truth: 55.0, AI forecast: 56.48225009441376, BCD5 forecast: 24.0\n",
            "\tTrajectory Truth: 41.0, 48.2; AI forecast: 23.67516779899597, 60.95380205214023 ; AI error: 1221.8957256230217 BCD5 error: 605.6\n",
            "Found AL142017 at 2017-09-27 00:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 54.57311600446701, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 31.4, 57.2; AI forecast: 22.112829637527465, 61.70517301838845 ; AI error: 607.4785418766761 BCD5 error: 43.2\n",
            "\tIntensity Truth: 75.0, AI forecast: 58.7466424703598, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 35.7, 55.5; AI forecast: 23.82466654777527, 61.224738081172106 ; AI error: 772.4945536686288 BCD5 error: 233.2\n",
            "\tIntensity Truth: 50.0, AI forecast: 61.95193290710449, BCD5 forecast: 26.0\n",
            "\tTrajectory Truth: 43.2, 44.5; AI forecast: 25.30354251861572, 61.01529771313071 ; AI error: 1346.0039966267138 BCD5 error: 781.8\n",
            "Found AL142017 at 2017-09-27 06:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 55.26995897293091, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 32.1, 57.3; AI forecast: 22.25435357093811, 61.662472809292375 ; AI error: 635.2094124620276 BCD5 error: 50.6\n",
            "\tIntensity Truth: 70.0, AI forecast: 59.489957094192505, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 37.3, 53.8; AI forecast: 23.924556016921997, 61.201806706935166 ; AI error: 888.6980543050204 BCD5 error: 314.7\n",
            "Found AL142017 at 2017-09-27 12:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 55.37632942199707, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 33.0, 57.2; AI forecast: 22.236281394958496, 61.653299054503435 ; AI error: 688.0920470537421 BCD5 error: 49.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 60.14007329940796, BCD5 forecast: 19.0\n",
            "\tTrajectory Truth: 39.0, 51.2; AI forecast: 24.158527994155882, 61.058187602087855 ; AI error: 1022.2921573156044 BCD5 error: 378.5\n",
            "Found AL142017 at 2017-09-27 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 55.60620069503784, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 34.3, 56.6; AI forecast: 22.431592440605165, 61.46408339962363 ; AI error: 757.2066288077792 BCD5 error: 54.1\n",
            "\tIntensity Truth: 55.0, AI forecast: 59.25763666629791, BCD5 forecast: 27.0\n",
            "\tTrajectory Truth: 41.0, 48.2; AI forecast: 24.086040687561034, 60.7770665679127 ; AI error: 1195.6000186008107 BCD5 error: 435.4\n",
            "Found AL142017 at 2017-09-28 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.82863104343414, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 35.7, 55.5; AI forecast: 22.06571674346924, 61.43806972764432 ; AI error: 875.5979707975357 BCD5 error: 94.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 57.29244649410248, BCD5 forecast: 26.0\n",
            "\tTrajectory Truth: 43.2, 44.5; AI forecast: 23.70854506492615, 60.72157413735985 ; AI error: 1419.0455749861999 BCD5 error: 559.8\n",
            "Found AL142017 at 2017-09-28 06:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 53.48315626382828, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 37.3, 53.8; AI forecast: 22.083782076835632, 61.44335764162242 ; AI error: 995.8221999123055 BCD5 error: 143.8\n",
            "Found AL142017 at 2017-09-28 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 52.5180858373642, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 39.0, 51.2; AI forecast: 22.002004504203796, 61.51415834408253 ; AI error: 1149.6856406467923 BCD5 error: 167.6\n",
            "Found AL142017 at 2017-09-28 18:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 49.29923415184021, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 41.0, 48.2; AI forecast: 21.238095664978026, 61.34857306703925 ; AI error: 1361.798584736082 BCD5 error: 169.9\n",
            "Found AL142017 at 2017-09-29 00:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.9848695397377, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 43.2, 44.5; AI forecast: 21.425994908809663, 61.111348420381546 ; AI error: 1548.9244973382556 BCD5 error: 190.8\n",
            "Found AL142017 at 2017-09-29 06:00:00\n",
            "Found AL152017 at 2017-09-17 18:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 54.54067766666412, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 14.9, 60.4; AI forecast: 21.389201843738554, 62.592889684904364 ; AI error: 409.18350609865206 BCD5 error: 66.2\n",
            "\tIntensity Truth: 145.0, AI forecast: 58.711732029914856, BCD5 forecast: -61.0\n",
            "\tTrajectory Truth: 16.6, 63.5; AI forecast: 22.747706818580628, 62.39791965642944 ; AI error: 374.3261753889759 BCD5 error: 114.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 64.4446349143982, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 18.6, 67.0; AI forecast: 25.29885983467102, 62.08521868893877 ; AI error: 486.3571593835389 BCD5 error: 94.9\n",
            "\tIntensity Truth: 105.0, AI forecast: 66.6181755065918, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 20.5, 69.5; AI forecast: 26.56539316177368, 61.94974729428068 ; AI error: 552.3271007874089 BCD5 error: 115.8\n",
            "\tIntensity Truth: 110.0, AI forecast: 67.8222131729126, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 22.8, 71.2; AI forecast: 27.295935916900635, 61.960626845154906 ; AI error: 570.1979156792349 BCD5 error: 139.4\n",
            "Found AL152017 at 2017-09-18 00:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 55.850404500961304, BCD5 forecast: -57.0\n",
            "\tTrajectory Truth: 15.3, 61.1; AI forecast: 22.112169575691222, 62.08110735835507 ; AI error: 412.78800236591866 BCD5 error: 57.3\n",
            "\tIntensity Truth: 150.0, AI forecast: 63.12739610671997, BCD5 forecast: -57.0\n",
            "\tTrajectory Truth: 17.0, 64.3; AI forecast: 25.03864426612854, 61.68160696122795 ; AI error: 504.4095444899665 BCD5 error: 85.5\n",
            "\tIntensity Truth: 95.0, AI forecast: 66.89284443855286, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 19.0, 67.6; AI forecast: 26.832994079589845, 61.40222229138016 ; AI error: 581.6838867254123 BCD5 error: 70.5\n",
            "\tIntensity Truth: 110.0, AI forecast: 69.64622020721436, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 20.8, 70.0; AI forecast: 28.169853115081786, 61.270834892243144 ; AI error: 650.1638081208426 BCD5 error: 105.9\n",
            "\tIntensity Truth: 105.0, AI forecast: 72.27905035018921, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 23.7, 71.6; AI forecast: 29.719906616210935, 61.29957707375288 ; AI error: 659.6801503881043 BCD5 error: 98.5\n",
            "Found AL152017 at 2017-09-18 06:00:00\n",
            "\tIntensity Truth: 135.0, AI forecast: 58.66767466068268, BCD5 forecast: -43.0\n",
            "\tTrajectory Truth: 15.7, 61.9; AI forecast: 23.509330224990844, 62.00606908435002 ; AI error: 468.9142240099217 BCD5 error: 40.4\n",
            "\tIntensity Truth: 140.0, AI forecast: 63.733744621276855, BCD5 forecast: -45.0\n",
            "\tTrajectory Truth: 17.6, 65.1; AI forecast: 25.514916515350343, 61.680919175781305 ; AI error: 512.0496428267137 BCD5 error: 45.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 67.54135370254517, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 19.4, 68.2; AI forecast: 27.082260131835938, 61.497017692215735 ; AI error: 590.8908072042309 BCD5 error: 37.6\n",
            "\tIntensity Truth: 110.0, AI forecast: 71.11125469207764, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 21.2, 70.5; AI forecast: 28.900799083709714, 61.438944939523935 ; AI error: 675.2679082320838 BCD5 error: 71.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 70.88787078857422, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 24.4, 71.9; AI forecast: 29.21916751861572, 61.6219348134473 ; AI error: 621.758888265672 BCD5 error: 62.2\n",
            "Found AL152017 at 2017-09-18 12:00:00\n",
            "\tIntensity Truth: 140.0, AI forecast: 57.07442283630371, BCD5 forecast: -31.0\n",
            "\tTrajectory Truth: 16.1, 62.7; AI forecast: 22.534296560287476, 62.058269844297314 ; AI error: 388.0231697420363 BCD5 error: 5.8\n",
            "\tIntensity Truth: 115.0, AI forecast: 63.02171468734741, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 18.2, 66.2; AI forecast: 24.55496029853821, 61.88196072336286 ; AI error: 451.41644818805383 BCD5 error: 22.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 68.9030909538269, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 19.9, 68.8; AI forecast: 27.20241641998291, 61.66189553979784 ; AI error: 588.4060521931704 BCD5 error: 66.8\n",
            "\tIntensity Truth: 110.0, AI forecast: 71.1262845993042, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 21.9, 70.9; AI forecast: 28.543118000030518, 61.729323595203454 ; AI error: 637.6911357555248 BCD5 error: 98.0\n",
            "\tIntensity Truth: 100.0, AI forecast: 74.91392135620117, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 25.1, 72.1; AI forecast: 30.78945646286011, 61.8041954094544 ; AI error: 643.6388939483714 BCD5 error: 66.9\n",
            "Found AL152017 at 2017-09-18 18:00:00\n",
            "\tIntensity Truth: 145.0, AI forecast: 57.98460781574249, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 16.6, 63.5; AI forecast: 22.744223260879515, 62.06796614946797 ; AI error: 377.6702729221954 BCD5 error: 18.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 65.9357225894928, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 18.6, 67.0; AI forecast: 25.90039429664612, 61.680496119149026 ; AI error: 528.5060125460506 BCD5 error: 57.8\n",
            "\tIntensity Truth: 105.0, AI forecast: 70.24020195007324, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 20.5, 69.5; AI forecast: 27.890050315856932, 61.51383179295808 ; AI error: 622.6459834329534 BCD5 error: 112.3\n",
            "\tIntensity Truth: 110.0, AI forecast: 75.9473967552185, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 22.8, 71.2; AI forecast: 30.91835460662842, 61.21685157269239 ; AI error: 722.8614385602746 BCD5 error: 139.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 78.75000238418579, BCD5 forecast: -22.0\n",
            "\tTrajectory Truth: 25.9, 72.3; AI forecast: 32.96412239074707, 61.353471823781724 ; AI error: 711.6811503402691 BCD5 error: 118.3\n",
            "Found AL152017 at 2017-09-19 00:00:00\n",
            "\tIntensity Truth: 150.0, AI forecast: 61.068105697631836, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 17.0, 64.3; AI forecast: 24.26786494255066, 61.86741474699229 ; AI error: 457.2328857436208 BCD5 error: 24.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 68.30100297927856, BCD5 forecast: 20.0\n",
            "\tTrajectory Truth: 19.0, 67.6; AI forecast: 27.142784881591798, 61.581829769723115 ; AI error: 590.9558026410983 BCD5 error: 64.1\n",
            "\tIntensity Truth: 110.0, AI forecast: 76.41125679016113, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 20.8, 70.0; AI forecast: 31.066439437866208, 61.20220350623131 ; AI error: 777.4893832443094 BCD5 error: 139.3\n",
            "\tIntensity Truth: 105.0, AI forecast: 81.95415735244751, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 23.7, 71.6; AI forecast: 34.38031234741211, 61.19249867722392 ; AI error: 841.3079468758008 BCD5 error: 163.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 85.78075408935547, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 26.6, 72.4; AI forecast: 37.31022052764892, 62.48777284855023 ; AI error: 816.5122985448314 BCD5 error: 176.0\n",
            "Found AL152017 at 2017-09-19 06:00:00\n",
            "\tIntensity Truth: 140.0, AI forecast: 62.60308504104614, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 17.6, 65.1; AI forecast: 25.677955293655394, 62.329801510099784 ; AI error: 508.9912987654913 BCD5 error: 13.3\n",
            "\tIntensity Truth: 100.0, AI forecast: 72.10209369659424, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 19.4, 68.2; AI forecast: 30.655017471313478, 62.27272888758452 ; AI error: 748.3699164148834 BCD5 error: 54.3\n",
            "\tIntensity Truth: 110.0, AI forecast: 78.33822965621948, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 21.2, 70.5; AI forecast: 34.94604091644287, 63.40119231194257 ; AI error: 906.2446691060542 BCD5 error: 127.9\n",
            "\tIntensity Truth: 100.0, AI forecast: 78.55623006820679, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 24.4, 71.9; AI forecast: 36.828276252746576, 63.79843210428953 ; AI error: 854.7340937165148 BCD5 error: 121.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 75.15651226043701, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 27.5, 72.6; AI forecast: 38.77345161437988, 63.811387944221494 ; AI error: 807.3586436521732 BCD5 error: 126.1\n",
            "Found AL152017 at 2017-09-19 12:00:00\n",
            "\tIntensity Truth: 115.0, AI forecast: 62.469213008880615, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 18.2, 66.2; AI forecast: 25.853917932510377, 62.50035256193951 ; AI error: 503.4742187771821 BCD5 error: 12.9\n",
            "\tIntensity Truth: 100.0, AI forecast: 71.92703247070312, BCD5 forecast: 28.0\n",
            "\tTrajectory Truth: 19.9, 68.8; AI forecast: 31.459987831115722, 63.82026890031993 ; AI error: 744.2501626013324 BCD5 error: 72.2\n",
            "\tIntensity Truth: 110.0, AI forecast: 74.90625143051147, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 21.9, 70.9; AI forecast: 34.67944202423096, 64.0199627019465 ; AI error: 848.5104925173079 BCD5 error: 139.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 73.62436294555664, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 25.1, 72.1; AI forecast: 37.70040435791016, 64.0968142017722 ; AI error: 859.6786636614459 BCD5 error: 141.7\n",
            "\tIntensity Truth: 95.0, AI forecast: 75.37072896957397, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 28.4, 72.8; AI forecast: 39.36061458587646, 64.08282413631677 ; AI error: 787.6561724766639 BCD5 error: 134.6\n",
            "Found AL152017 at 2017-09-19 18:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 62.84796118736267, BCD5 forecast: 40.0\n",
            "\tTrajectory Truth: 18.6, 67.0; AI forecast: 27.222799396514894, 64.10685998424887 ; AI error: 541.808341867501 BCD5 error: 24.8\n",
            "\tIntensity Truth: 105.0, AI forecast: 69.00311350822449, BCD5 forecast: 19.0\n",
            "\tTrajectory Truth: 20.5, 69.5; AI forecast: 31.750389671325685, 64.2574007384479 ; AI error: 731.9059553276074 BCD5 error: 72.2\n",
            "\tIntensity Truth: 110.0, AI forecast: 69.91682767868042, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 22.8, 71.2; AI forecast: 35.669202995300296, 64.11069277152419 ; AI error: 856.6292558065794 BCD5 error: 126.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 74.49136018753052, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 25.9, 72.3; AI forecast: 38.22215595245361, 63.67968388944864 ; AI error: 859.0812695358326 BCD5 error: 134.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 77.62478351593018, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 29.1, 72.9; AI forecast: 39.432672309875485, 64.0392034508288 ; AI error: 759.4716683016742 BCD5 error: 140.4\n",
            "Found AL152017 at 2017-09-20 00:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 59.097230434417725, BCD5 forecast: 42.0\n",
            "\tTrajectory Truth: 19.0, 67.6; AI forecast: 25.018502950668335, 62.67709363074973 ; AI error: 453.3887282189164 BCD5 error: 30.5\n",
            "\tIntensity Truth: 110.0, AI forecast: 61.63165807723999, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 20.8, 70.0; AI forecast: 29.47960739135742, 62.90328135397285 ; AI error: 647.960751835851 BCD5 error: 96.0\n",
            "\tIntensity Truth: 105.0, AI forecast: 68.74439120292664, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 23.7, 71.6; AI forecast: 32.68657665252685, 62.66930431360379 ; AI error: 716.5941067825793 BCD5 error: 121.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 74.70169067382812, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 26.6, 72.4; AI forecast: 35.42328014373779, 62.68822919065133 ; AI error: 727.4631570371114 BCD5 error: 152.3\n",
            "\tIntensity Truth: 85.0, AI forecast: 78.01894187927246, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 29.7, 72.9; AI forecast: 37.10312633514404, 63.05762109402567 ; AI error: 663.3154470012039 BCD5 error: 165.9\n",
            "Found AL152017 at 2017-09-20 06:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 60.72142958641052, BCD5 forecast: 30.0\n",
            "\tTrajectory Truth: 19.4, 68.2; AI forecast: 24.246811056137084, 62.083040456753224 ; AI error: 448.11736335482476 BCD5 error: 60.9\n",
            "\tIntensity Truth: 110.0, AI forecast: 69.10282850265503, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 21.2, 70.5; AI forecast: 27.89713191986084, 62.02045643897727 ; AI error: 612.9249411394826 BCD5 error: 143.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 74.05861377716064, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 24.4, 71.9; AI forecast: 30.299491310119627, 62.31074735486181 ; AI error: 621.6374428627669 BCD5 error: 145.6\n",
            "\tIntensity Truth: 95.0, AI forecast: 73.87880563735962, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 27.5, 72.6; AI forecast: 30.433424949645996, 62.87857378851622 ; AI error: 539.9430919150611 BCD5 error: 156.1\n",
            "\tIntensity Truth: 75.0, AI forecast: 70.77600955963135, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 30.3, 72.9; AI forecast: 30.349561882019042, 63.874298562109466 ; AI error: 467.6481008513823 BCD5 error: 188.5\n",
            "Found AL152017 at 2017-09-20 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 55.61110258102417, BCD5 forecast: 18.0\n",
            "\tTrajectory Truth: 19.9, 68.8; AI forecast: 23.085102558135986, 63.23775558061897 ; AI error: 364.804503078936 BCD5 error: 62.2\n",
            "\tIntensity Truth: 110.0, AI forecast: 56.99891149997711, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 21.9, 70.9; AI forecast: 23.84937505722046, 64.01842449232936 ; AI error: 398.20617565109904 BCD5 error: 107.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 55.48931539058685, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 25.1, 72.1; AI forecast: 24.75323853492737, 65.30021672174334 ; AI error: 370.7773481581231 BCD5 error: 105.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 54.633438885211945, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 28.4, 72.8; AI forecast: 25.922609424591066, 65.70648688226937 ; AI error: 406.98381021005156 BCD5 error: 76.4\n",
            "\tIntensity Truth: 70.0, AI forecast: 56.58137261867523, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 30.8, 73.0; AI forecast: 29.217226886749266, 63.62336092367768 ; AI error: 496.5223450834539 BCD5 error: 92.3\n",
            "Found AL152017 at 2017-09-20 18:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 49.38882473856211, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 20.5, 69.5; AI forecast: 20.658136004209517, 63.129911900311704 ; AI error: 358.16030618802586 BCD5 error: 8.2\n",
            "\tIntensity Truth: 110.0, AI forecast: 47.52724051475525, BCD5 forecast: -27.0\n",
            "\tTrajectory Truth: 22.8, 71.2; AI forecast: 21.62436068058014, 64.28231620714068 ; AI error: 390.90090105469835 BCD5 error: 28.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 46.89203768968582, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 25.9, 72.3; AI forecast: 23.061310124397277, 64.72014180719852 ; AI error: 447.7702864424351 BCD5 error: 21.6\n",
            "\tIntensity Truth: 90.0, AI forecast: 49.83643552288413, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 29.1, 72.9; AI forecast: 26.863774490356445, 63.03457969371229 ; AI error: 539.8385046156154 BCD5 error: 24.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.88512904942036, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 31.4, 73.1; AI forecast: 28.99813575744629, 61.92651699790731 ; AI error: 597.1690974026692 BCD5 error: 25.6\n",
            "Found AL152017 at 2017-09-21 00:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 46.80855840444565, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 20.8, 70.0; AI forecast: 21.539472889900207, 62.82209308277815 ; AI error: 404.28806727814884 BCD5 error: 16.4\n",
            "\tIntensity Truth: 105.0, AI forecast: 45.65090328454971, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 23.7, 71.6; AI forecast: 23.100432014465333, 63.17162598967552 ; AI error: 465.7469019054391 BCD5 error: 13.2\n",
            "\tIntensity Truth: 100.0, AI forecast: 48.66903454065323, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 26.6, 72.4; AI forecast: 27.143395709991456, 61.527129370160395 ; AI error: 583.0529323585099 BCD5 error: 12.0\n",
            "\tIntensity Truth: 85.0, AI forecast: 50.0369176780805, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 29.7, 72.9; AI forecast: 29.286807918548583, 60.69916996732354 ; AI error: 637.8020700864311 BCD5 error: 39.8\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.6132143214345, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 32.0, 73.1; AI forecast: 28.615020179748534, 61.37965411096811 ; AI error: 640.1874881254322 BCD5 error: 62.3\n",
            "Found AL152017 at 2017-09-21 06:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 47.57950723171234, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 21.2, 70.5; AI forecast: 22.127183604240418, 62.77706753183156 ; AI error: 434.4667352498989 BCD5 error: 24.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.089209508150816, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 24.4, 71.9; AI forecast: 26.68896074295044, 61.09225051924586 ; AI error: 601.1647434148624 BCD5 error: 12.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 51.176690831780434, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 27.5, 72.6; AI forecast: 29.16138114929199, 60.11482137739658 ; AI error: 666.9922702967642 BCD5 error: 18.8\n",
            "\tIntensity Truth: 75.0, AI forecast: 50.66932573914528, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 30.3, 72.9; AI forecast: 28.67311897277832, 60.84722656197846 ; AI error: 637.1285149669512 BCD5 error: 33.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.78846391662955, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 32.6, 73.1; AI forecast: 28.358539009094237, 61.15766616538167 ; AI error: 667.8237185700905 BCD5 error: 76.7\n",
            "Found AL152017 at 2017-09-21 12:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 51.73313170671463, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 21.9, 70.9; AI forecast: 25.668352937698366, 60.96203049384057 ; AI error: 590.7792777904208 BCD5 error: 30.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 52.33660101890564, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 25.1, 72.1; AI forecast: 28.675404739379882, 59.73656152412295 ; AI error: 695.5603467777245 BCD5 error: 20.2\n",
            "\tIntensity Truth: 95.0, AI forecast: 51.81404083967209, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 28.4, 72.8; AI forecast: 28.521633529663085, 60.40261432230472 ; AI error: 654.1354497351884 BCD5 error: 12.1\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.06455817818642, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 30.8, 73.0; AI forecast: 28.325090980529787, 60.787130475789304 ; AI error: 654.5068080870573 BCD5 error: 52.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.71977652609348, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 33.3, 73.1; AI forecast: 27.98379611968994, 61.36758749336004 ; AI error: 684.3354333439466 BCD5 error: 111.0\n",
            "Found AL152017 at 2017-09-21 18:00:00\n",
            "\tIntensity Truth: 110.0, AI forecast: 49.92775609251112, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 22.8, 71.2; AI forecast: 24.060140228271486, 61.9171015384607 ; AI error: 516.8568860542083 BCD5 error: 22.9\n",
            "\tIntensity Truth: 100.0, AI forecast: 49.82738560065627, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 25.9, 72.3; AI forecast: 24.356204414367674, 62.24808834018185 ; AI error: 554.0587953916778 BCD5 error: 44.2\n",
            "\tIntensity Truth: 90.0, AI forecast: 49.63663179427385, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 29.1, 72.9; AI forecast: 24.438780736923217, 62.632956322375684 ; AI error: 617.0678654893253 BCD5 error: 37.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 49.87600876018405, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 31.4, 73.1; AI forecast: 24.34097275733948, 63.096246615238485 ; AI error: 678.7751817898671 BCD5 error: 30.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.957682243548334, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 33.9, 73.1; AI forecast: 24.12242169380188, 63.65021806359291 ; AI error: 767.8145233200244 BCD5 error: 85.4\n",
            "Found AL152017 at 2017-09-22 00:00:00\n",
            "\tIntensity Truth: 105.0, AI forecast: 52.51657038927078, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 23.7, 71.6; AI forecast: 21.22056246995926, 62.563741102535275 ; AI error: 522.8902635470754 BCD5 error: 55.1\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.00791019201279, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 26.6, 72.4; AI forecast: 21.83146780729294, 62.9162859365344 ; AI error: 592.6990958186793 BCD5 error: 84.5\n",
            "\tIntensity Truth: 85.0, AI forecast: 55.75489342212677, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 29.7, 72.9; AI forecast: 22.466066193580627, 63.126115363836284 ; AI error: 682.402529680586 BCD5 error: 80.8\n",
            "\tIntensity Truth: 70.0, AI forecast: 57.184810638427734, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 32.0, 73.1; AI forecast: 23.044276189804076, 63.40140795521438 ; AI error: 744.770798581336 BCD5 error: 46.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 61.56025409698486, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 34.4, 73.0; AI forecast: 24.979533767700197, 63.55779312215745 ; AI error: 749.1623487582349 BCD5 error: 73.5\n",
            "Found AL152017 at 2017-09-22 06:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.2898063659668, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 24.4, 71.9; AI forecast: 21.00345841050148, 62.83540163319557 ; AI error: 541.7370472187953 BCD5 error: 36.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.81493961811066, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 27.5, 72.6; AI forecast: 21.58601325750351, 63.20297509357333 ; AI error: 623.6980199921268 BCD5 error: 42.0\n",
            "\tIntensity Truth: 75.0, AI forecast: 54.05044376850128, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 30.3, 72.9; AI forecast: 22.19732823371887, 63.6243922099471 ; AI error: 696.6556489411386 BCD5 error: 40.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 57.94071972370148, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 32.6, 73.1; AI forecast: 23.99915952682495, 63.86797583475709 ; AI error: 709.8612704649057 BCD5 error: 108.6\n",
            "\tIntensity Truth: 65.0, AI forecast: 56.073132157325745, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 34.9, 72.9; AI forecast: 24.392367792129516, 64.40537963882089 ; AI error: 770.2692557006551 BCD5 error: 178.0\n",
            "Found AL152017 at 2017-09-22 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.98372572660446, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 25.1, 72.1; AI forecast: 21.179871827363968, 62.633359196130186 ; AI error: 572.9776482228132 BCD5 error: 24.8\n",
            "\tIntensity Truth: 95.0, AI forecast: 53.58272910118103, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 28.4, 72.8; AI forecast: 21.899039697647094, 62.97996546328068 ; AI error: 660.7258113409207 BCD5 error: 69.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 57.857070565223694, BCD5 forecast: 17.0\n",
            "\tTrajectory Truth: 30.8, 73.0; AI forecast: 23.821278619766236, 63.14520248770714 ; AI error: 671.7150418011566 BCD5 error: 173.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 56.2885183095932, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 33.3, 73.1; AI forecast: 24.346323013305664, 63.6435857348144 ; AI error: 731.6671027548455 BCD5 error: 275.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 56.81942105293274, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 35.4, 72.8; AI forecast: 24.733444690704346, 63.7465416315943 ; AI error: 793.7570755146253 BCD5 error: 366.8\n",
            "Found AL152017 at 2017-09-22 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 51.772740483284, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 25.9, 72.3; AI forecast: 21.306522130966187, 62.625778810959304 ; AI error: 599.1720748233007 BCD5 error: 41.9\n",
            "\tIntensity Truth: 90.0, AI forecast: 56.196280121803284, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 29.1, 72.9; AI forecast: 23.279484510421753, 62.751888705976306 ; AI error: 648.4294065108472 BCD5 error: 114.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 54.80131655931473, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 31.4, 73.1; AI forecast: 23.926885175704957, 63.20429374091327 ; AI error: 690.9201320301586 BCD5 error: 244.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 55.498576164245605, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 33.9, 73.1; AI forecast: 24.390069675445556, 63.23968353532254 ; AI error: 769.4331178583253 BCD5 error: 358.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 55.38659453392029, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 36.0, 72.6; AI forecast: 24.465106439590453, 63.450962896645066 ; AI error: 838.5845002809727 BCD5 error: 458.9\n",
            "Found AL152017 at 2017-09-23 00:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 55.66313326358795, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 26.6, 72.4; AI forecast: 22.972754526138306, 62.25066606291802 ; AI error: 594.2960627874005 BCD5 error: 31.9\n",
            "\tIntensity Truth: 85.0, AI forecast: 55.18785536289215, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 29.7, 72.9; AI forecast: 24.121871948242188, 62.43549267975613 ; AI error: 652.254188059139 BCD5 error: 90.2\n",
            "\tIntensity Truth: 70.0, AI forecast: 57.038694024086, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 32.0, 73.1; AI forecast: 25.14300847053528, 62.13476300006732 ; AI error: 709.0853722298398 BCD5 error: 213.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 58.09538185596466, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 34.4, 73.0; AI forecast: 25.764775037765503, 61.994768142420796 ; AI error: 770.8534154600884 BCD5 error: 324.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 61.74112558364868, BCD5 forecast: -13.0\n",
            "\tTrajectory Truth: 36.6, 72.2; AI forecast: 27.22136878967285, 61.86176716629416 ; AI error: 770.1652027997176 BCD5 error: 411.8\n",
            "Found AL152017 at 2017-09-23 06:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 49.50404707342386, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 27.5, 72.6; AI forecast: 21.437041223049164, 62.19614780219271 ; AI error: 674.6267761776893 BCD5 error: 21.3\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.4343723654747, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 30.3, 72.9; AI forecast: 22.334479403495788, 61.81361733525991 ; AI error: 763.8667795674837 BCD5 error: 83.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 52.93605774641037, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 32.6, 73.1; AI forecast: 23.100304341316225, 61.54754635952413 ; AI error: 836.3962849330384 BCD5 error: 203.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 57.241610288619995, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 34.9, 72.9; AI forecast: 24.81932649612427, 61.29962782487273 ; AI error: 853.8110121946073 BCD5 error: 313.3\n",
            "\tIntensity Truth: 60.0, AI forecast: 58.34219515323639, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 36.7, 71.3; AI forecast: 25.310676860809327, 61.63330855090171 ; AI error: 844.5262182489465 BCD5 error: 381.1\n",
            "Found AL152017 at 2017-09-23 12:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.92436718940735, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 28.4, 72.8; AI forecast: 21.728926408290864, 61.714548161067064 ; AI error: 723.2087087777322 BCD5 error: 36.9\n",
            "\tIntensity Truth: 70.0, AI forecast: 54.86218184232712, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 30.8, 73.0; AI forecast: 22.757975244522093, 61.284848471730946 ; AI error: 791.2231212361567 BCD5 error: 123.3\n",
            "\tIntensity Truth: 65.0, AI forecast: 59.462648034095764, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 33.3, 73.1; AI forecast: 24.70474076271057, 60.80974793769419 ; AI error: 825.1991690648076 BCD5 error: 250.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 60.6425142288208, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 35.4, 72.8; AI forecast: 25.342458295822144, 61.01692850925028 ; AI error: 857.2750518237432 BCD5 error: 375.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 60.95677614212036, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 36.8, 70.0; AI forecast: 25.591570472717287, 61.44739715643227 ; AI error: 802.7606474674549 BCD5 error: 409.8\n",
            "Found AL152017 at 2017-09-23 18:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 52.14825212955475, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 29.1, 72.9; AI forecast: 21.61298850774765, 61.59315207023173 ; AI error: 759.796585727497 BCD5 error: 47.5\n",
            "\tIntensity Truth: 70.0, AI forecast: 57.0335191488266, BCD5 forecast: 16.0\n",
            "\tTrajectory Truth: 31.4, 73.1; AI forecast: 23.662428188323975, 60.9263952717185 ; AI error: 796.4981141133576 BCD5 error: 150.6\n",
            "\tIntensity Truth: 65.0, AI forecast: 58.56591045856476, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 33.9, 73.1; AI forecast: 24.470521116256712, 60.9313559487462 ; AI error: 851.6121328639398 BCD5 error: 284.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 59.256362318992615, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 36.0, 72.6; AI forecast: 24.885503911972044, 61.19383682161569 ; AI error: 889.5959214792905 BCD5 error: 408.1\n",
            "\tIntensity Truth: 55.0, AI forecast: 59.56244766712189, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 36.8, 68.6; AI forecast: 25.038903951644897, 61.53798570092767 ; AI error: 793.6876840858827 BCD5 error: 420.2\n",
            "Found AL152017 at 2017-09-24 00:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 56.32211983203888, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 29.7, 72.9; AI forecast: 23.131481456756593, 61.27344994656741 ; AI error: 738.4911214033298 BCD5 error: 52.6\n",
            "\tIntensity Truth: 70.0, AI forecast: 59.11298215389252, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 32.0, 73.1; AI forecast: 24.597414541244508, 60.84030510857701 ; AI error: 784.9383834469505 BCD5 error: 175.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 61.06724977493286, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 34.4, 73.0; AI forecast: 25.687565326690674, 60.69114599972963 ; AI error: 825.1759626427439 BCD5 error: 321.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 62.760009765625, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 36.6, 72.2; AI forecast: 26.533810997009276, 60.62208332717418 ; AI error: 844.876504086117 BCD5 error: 437.7\n",
            "\tIntensity Truth: 55.0, AI forecast: 66.63427114486694, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 36.9, 66.8; AI forecast: 28.30839834213257, 60.53621282428503 ; AI error: 604.9944710471715 BCD5 error: 428.5\n",
            "Found AL152017 at 2017-09-24 06:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.14591884613037, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 30.3, 72.9; AI forecast: 21.883385133743285, 61.56950346902013 ; AI error: 791.989561011455 BCD5 error: 72.8\n",
            "\tIntensity Truth: 65.0, AI forecast: 55.727683901786804, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 32.6, 73.1; AI forecast: 23.117418718338012, 61.143165649473666 ; AI error: 851.449725836289 BCD5 error: 211.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 58.2879775762558, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 34.9, 72.9; AI forecast: 24.24572558403015, 60.80872791856527 ; AI error: 897.3474619651057 BCD5 error: 368.9\n",
            "\tIntensity Truth: 60.0, AI forecast: 63.3698570728302, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 36.7, 71.3; AI forecast: 26.4978328704834, 60.41455376818776 ; AI error: 826.4859049341113 BCD5 error: 476.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 65.1262891292572, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 37.0, 64.6; AI forecast: 27.39511775970459, 60.51648259162903 ; AI error: 612.6828451421942 BCD5 error: 453.5\n",
            "Found AL152017 at 2017-09-24 12:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 52.5016263127327, BCD5 forecast: 19.0\n",
            "\tTrajectory Truth: 30.8, 73.0; AI forecast: 21.800728368759156, 61.7916572375223 ; AI error: 808.9379749722688 BCD5 error: 77.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 54.9906399846077, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 33.3, 73.1; AI forecast: 23.049434185028076, 61.405572845041746 ; AI error: 871.5881300407451 BCD5 error: 202.9\n",
            "\tIntensity Truth: 65.0, AI forecast: 59.95463669300079, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 35.4, 72.8; AI forecast: 25.3439670085907, 60.9704562574625 ; AI error: 858.9118980469759 BCD5 error: 361.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 61.598966121673584, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 36.8, 70.0; AI forecast: 26.281076908111572, 60.989787535369395 ; AI error: 781.0571731944068 BCD5 error: 432.0\n",
            "\tIntensity Truth: 50.0, AI forecast: 59.7781378030777, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 37.0, 62.0; AI forecast: 26.4544620513916, 61.72625687550753 ; AI error: 633.3125216262534 BCD5 error: 399.7\n",
            "Found AL152017 at 2017-09-24 18:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 53.243320882320404, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 31.4, 73.1; AI forecast: 22.074802231788635, 61.57459587361663 ; AI error: 832.858202892088 BCD5 error: 70.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 59.01389300823212, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 33.9, 73.1; AI forecast: 24.720663022994994, 60.87374803908169 ; AI error: 843.4368808492248 BCD5 error: 185.2\n",
            "\tIntensity Truth: 65.0, AI forecast: 61.48933291435242, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 36.0, 72.6; AI forecast: 26.088591194152833, 60.59641168639064 ; AI error: 856.178175876116 BCD5 error: 322.9\n",
            "\tIntensity Truth: 55.0, AI forecast: 60.43349742889404, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 36.8, 68.6; AI forecast: 26.63041467666626, 61.02213275246322 ; AI error: 722.2938516287933 BCD5 error: 354.7\n",
            "\tIntensity Truth: 50.0, AI forecast: 62.46070146560669, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 37.4, 59.0; AI forecast: 27.359871292114256, 60.916038908064365 ; AI error: 610.5488962283476 BCD5 error: 312.0\n",
            "Found AL152017 at 2017-09-25 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 55.97770392894745, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 32.0, 73.1; AI forecast: 23.27390377521515, 61.493296400643885 ; AI error: 808.7031164459339 BCD5 error: 72.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 58.60229671001434, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 34.4, 73.0; AI forecast: 24.795857000350953, 61.02686299197376 ; AI error: 849.158393086115 BCD5 error: 187.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 57.66388535499573, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 36.6, 72.2; AI forecast: 25.59888939857483, 61.31105691827833 ; AI error: 864.519365697057 BCD5 error: 313.7\n",
            "\tIntensity Truth: 55.0, AI forecast: 59.62665021419525, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 36.9, 66.8; AI forecast: 26.422267723083497, 61.100492579489945 ; AI error: 692.866409494175 BCD5 error: 301.8\n",
            "\tIntensity Truth: 50.0, AI forecast: 58.09398353099823, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 38.1, 55.6; AI forecast: 26.386923122406007, 61.59166368097067 ; AI error: 765.7791289349974 BCD5 error: 302.8\n",
            "Found AL152017 at 2017-09-25 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 51.68435513973236, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 32.6, 73.1; AI forecast: 21.61728366613388, 61.8771899221465 ; AI error: 890.1493496967511 BCD5 error: 58.4\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.60345787554979, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 34.9, 72.9; AI forecast: 22.435637593269348, 62.064990056771784 ; AI error: 939.7812252343873 BCD5 error: 167.1\n",
            "\tIntensity Truth: 60.0, AI forecast: 52.23050341010094, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 36.7, 71.3; AI forecast: 23.244510078430174, 61.831676210090514 ; AI error: 944.8828415639933 BCD5 error: 255.5\n",
            "\tIntensity Truth: 50.0, AI forecast: 51.00036233663559, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 37.0, 64.6; AI forecast: 23.6144748210907, 62.227136651519686 ; AI error: 812.9445479358357 BCD5 error: 217.1\n",
            "\tIntensity Truth: 50.0, AI forecast: 49.2537397891283, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 39.1, 52.2; AI forecast: 23.91076397895813, 62.45675509655848 ; AI error: 1050.5750199515255 BCD5 error: 364.1\n",
            "Found AL152017 at 2017-09-25 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 47.8540775179863, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 33.3, 73.1; AI forecast: 21.182295697927476, 62.34424936437281 ; AI error: 925.5119355855462 BCD5 error: 45.1\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.54027047753334, BCD5 forecast: -7.0\n",
            "\tTrajectory Truth: 35.4, 72.8; AI forecast: 21.863029277324678, 62.12838457385078 ; AI error: 986.8404801708675 BCD5 error: 150.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 47.13693171739578, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 36.8, 70.0; AI forecast: 22.355825853347778, 62.426964189205314 ; AI error: 952.2482951318477 BCD5 error: 197.7\n",
            "\tIntensity Truth: 50.0, AI forecast: 45.482472479343414, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 37.0, 62.0; AI forecast: 22.96903281211853, 62.647379046026614 ; AI error: 843.0917157517274 BCD5 error: 212.5\n",
            "\tIntensity Truth: 50.0, AI forecast: 44.15432691574097, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 40.0, 48.8; AI forecast: 23.221569967269897, 62.64520458588376 ; AI error: 1227.8566929969488 BCD5 error: 482.5\n",
            "Found AL152017 at 2017-09-25 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.43173883110285, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 33.9, 73.1; AI forecast: 21.236612820625304, 62.03977894810959 ; AI error: 960.1051033032184 BCD5 error: 56.0\n",
            "\tIntensity Truth: 65.0, AI forecast: 48.367283791303635, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 36.0, 72.6; AI forecast: 21.737815296649934, 62.308593665447546 ; AI error: 1011.4256449588229 BCD5 error: 175.7\n",
            "\tIntensity Truth: 55.0, AI forecast: 46.08153164386749, BCD5 forecast: 6.0\n",
            "\tTrajectory Truth: 36.8, 68.6; AI forecast: 22.44957733154297, 62.53356985570863 ; AI error: 917.3627729196978 BCD5 error: 208.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 44.289743304252625, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 37.4, 59.0; AI forecast: 22.941565728187562, 62.54558562422171 ; AI error: 887.1795009972843 BCD5 error: 255.8\n",
            "Found AL152017 at 2017-09-26 00:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.764419078826904, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 34.4, 73.0; AI forecast: 20.98508490920067, 62.238809898961335 ; AI error: 986.4474610990992 BCD5 error: 66.7\n",
            "\tIntensity Truth: 65.0, AI forecast: 44.145501255989075, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 36.6, 72.2; AI forecast: 21.809772384166717, 62.15514491433277 ; AI error: 1030.7932890295021 BCD5 error: 179.1\n",
            "\tIntensity Truth: 55.0, AI forecast: 42.4432772397995, BCD5 forecast: 8.0\n",
            "\tTrajectory Truth: 36.9, 66.8; AI forecast: 22.488454723358153, 61.996420884970576 ; AI error: 900.4476098565409 BCD5 error: 192.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 41.46298944950104, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 38.1, 55.6; AI forecast: 22.68386106491089, 61.79748666007072 ; AI error: 979.0036377431348 BCD5 error: 311.7\n",
            "Found AL152017 at 2017-09-26 06:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.26207262277603, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 34.9, 72.9; AI forecast: 21.284189927577973, 62.13726072916761 ; AI error: 995.1029420961629 BCD5 error: 70.5\n",
            "\tIntensity Truth: 60.0, AI forecast: 43.638264536857605, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 36.7, 71.3; AI forecast: 22.054589486122133, 61.89057726906612 ; AI error: 1006.4007050388493 BCD5 error: 170.0\n",
            "\tIntensity Truth: 50.0, AI forecast: 42.02919363975525, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 37.0, 64.6; AI forecast: 22.454073762893678, 61.61023148763925 ; AI error: 887.0004017869578 BCD5 error: 195.6\n",
            "\tIntensity Truth: 50.0, AI forecast: 41.58716022968292, BCD5 forecast: 9.0\n",
            "\tTrajectory Truth: 39.1, 52.2; AI forecast: 22.705981397628783, 61.46972951069474 ; AI error: 1092.4898699420576 BCD5 error: 386.2\n",
            "Found AL152017 at 2017-09-26 12:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 46.70454293489456, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 35.4, 72.8; AI forecast: 21.414200413227082, 62.08872845219448 ; AI error: 1010.890915532836 BCD5 error: 76.0\n",
            "\tIntensity Truth: 60.0, AI forecast: 44.46346879005432, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 36.8, 70.0; AI forecast: 22.06503999233246, 61.68560562040656 ; AI error: 984.6750553259379 BCD5 error: 155.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 43.80721867084503, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 37.0, 62.0; AI forecast: 22.62909128665924, 61.35320043265819 ; AI error: 863.4870091548208 BCD5 error: 230.2\n",
            "\tIntensity Truth: 50.0, AI forecast: 42.68671929836273, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 40.0, 48.8; AI forecast: 23.07952733039856, 61.07413961961865 ; AI error: 1191.6431408301648 BCD5 error: 489.8\n",
            "Found AL152017 at 2017-09-26 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 47.249096035957336, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 36.0, 72.6; AI forecast: 21.28451203107834, 62.038200813625004 ; AI error: 1042.5489308029257 BCD5 error: 62.9\n",
            "\tIntensity Truth: 55.0, AI forecast: 46.13041132688522, BCD5 forecast: 11.0\n",
            "\tTrajectory Truth: 36.8, 68.6; AI forecast: 22.102418184280396, 61.63803060948848 ; AI error: 953.8008966973154 BCD5 error: 131.6\n",
            "\tIntensity Truth: 50.0, AI forecast: 44.35899257659912, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 37.4, 59.0; AI forecast: 22.77298493385315, 61.376428769528864 ; AI error: 886.7540691664316 BCD5 error: 277.6\n",
            "Found AL152017 at 2017-09-27 00:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 49.15396861732006, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 36.6, 72.2; AI forecast: 21.66894773244858, 61.79182590171695 ; AI error: 1047.9210579065434 BCD5 error: 48.5\n",
            "\tIntensity Truth: 55.0, AI forecast: 47.14410454034805, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 36.9, 66.8; AI forecast: 22.61673219203949, 61.403098972886795 ; AI error: 902.0727190429119 BCD5 error: 136.1\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.59878611564636, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 38.1, 55.6; AI forecast: 23.363075542449952, 61.08916684985161 ; AI error: 928.5553921609652 BCD5 error: 379.2\n",
            "Found AL152017 at 2017-09-27 06:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 47.50910967588425, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 36.7, 71.3; AI forecast: 21.520255744457245, 61.749199418909846 ; AI error: 1038.5896808708756 BCD5 error: 33.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.63186937570572, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 37.0, 64.6; AI forecast: 22.41708960533142, 61.26673139967024 ; AI error: 892.4705077830677 BCD5 error: 198.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 44.96858894824982, BCD5 forecast: 12.0\n",
            "\tTrajectory Truth: 39.1, 52.2; AI forecast: 23.20302882194519, 60.89772872701287 ; AI error: 1052.5819215747488 BCD5 error: 487.7\n",
            "Found AL152017 at 2017-09-27 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.21623043715954, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 36.8, 70.0; AI forecast: 21.681292140483855, 61.70963622666895 ; AI error: 1005.193993349943 BCD5 error: 71.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 47.21138805150986, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 37.0, 62.0; AI forecast: 22.70555398464203, 61.22438997551799 ; AI error: 859.1853779678416 BCD5 error: 285.9\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.80367946624756, BCD5 forecast: 13.0\n",
            "\tTrajectory Truth: 40.0, 48.8; AI forecast: 23.643459463119505, 60.71500078961253 ; AI error: 1152.4378514607772 BCD5 error: 577.1\n",
            "Found AL152017 at 2017-09-27 18:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 47.48657315969467, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 36.8, 68.6; AI forecast: 21.63558782339096, 61.665049996227026 ; AI error: 979.537683882947 BCD5 error: 125.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 46.6925373673439, BCD5 forecast: 15.0\n",
            "\tTrajectory Truth: 37.4, 59.0; AI forecast: 22.74905948638916, 60.990948834642765 ; AI error: 885.6446243996173 BCD5 error: 356.4\n",
            "Found AL152017 at 2017-09-28 00:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 49.69664862379432, BCD5 forecast: 10.0\n",
            "\tTrajectory Truth: 36.9, 66.8; AI forecast: 22.06498041152954, 61.445709926635026 ; AI error: 933.1607554189902 BCD5 error: 122.4\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.91733057796955, BCD5 forecast: 14.0\n",
            "\tTrajectory Truth: 38.1, 55.6; AI forecast: 23.331372213363647, 60.77220327816903 ; AI error: 925.5877747632239 BCD5 error: 398.4\n",
            "Found AL152017 at 2017-09-28 06:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.81135605275631, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 37.0, 64.6; AI forecast: 21.860677671432494, 61.46571625322103 ; AI error: 923.4637027086309 BCD5 error: 91.3\n",
            "\tIntensity Truth: 50.0, AI forecast: 47.708459198474884, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 39.1, 52.2; AI forecast: 23.00629868507385, 60.77205582559108 ; AI error: 1060.8070278027374 BCD5 error: 427.9\n",
            "Found AL152017 at 2017-09-28 12:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.79462115466595, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 37.0, 62.0; AI forecast: 21.90801570415497, 61.3509803161025 ; AI error: 906.7578239382269 BCD5 error: 111.0\n",
            "\tIntensity Truth: 50.0, AI forecast: 47.43235498666763, BCD5 forecast: 5.0\n",
            "\tTrajectory Truth: 40.0, 48.8; AI forecast: 23.1114461183548, 60.48622218742966 ; AI error: 1174.6414053364963 BCD5 error: 469.4\n",
            "Found AL152017 at 2017-09-28 18:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.232775777578354, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 37.4, 59.0; AI forecast: 21.90472240447998, 61.2056125510484 ; AI error: 937.3493860428744 BCD5 error: 143.3\n",
            "Found AL152017 at 2017-09-29 00:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 49.14698339998722, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 38.1, 55.6; AI forecast: 22.4449764251709, 60.93637168779969 ; AI error: 979.3182683141852 BCD5 error: 151.8\n",
            "Found AL152017 at 2017-09-29 06:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 47.529994547367096, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 39.1, 52.2; AI forecast: 22.15568025112152, 60.85589765533805 ; AI error: 1109.8997954521137 BCD5 error: 162.4\n",
            "Found AL152017 at 2017-09-29 12:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 48.890646398067474, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 40.0, 48.8; AI forecast: 22.46151418685913, 60.62232219055295 ; AI error: 1212.7691173427904 BCD5 error: 146.9\n",
            "Found AL152017 at 2017-09-29 18:00:00\n",
            "Found AL152017 at 2017-09-30 00:00:00\n",
            "Found AL152017 at 2017-09-30 06:00:00\n",
            "Found AL152017 at 2017-09-30 12:00:00\n",
            "Found AL162017 at 2017-10-05 06:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 51.05012185871601, BCD5 forecast: -11.0\n",
            "\tTrajectory Truth: 16.3, 84.7; AI forecast: 20.902828353643418, 62.71923917811364 ; AI error: 1279.7450675854068 BCD5 error: 54.3\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.84496492147446, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 23.5, 86.5; AI forecast: 21.13620798587799, 63.02682447191327 ; AI error: 1310.0037421283528 BCD5 error: 374.1\n",
            "\tIntensity Truth: 60.0, AI forecast: 52.22157537937164, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 30.5, 88.9; AI forecast: 21.2179971575737, 63.207694947719574 ; AI error: 1491.3079090439835 BCD5 error: 684.3\n",
            "Found AL162017 at 2017-10-05 12:00:00\n",
            "\tIntensity Truth: 40.0, AI forecast: 51.1897624284029, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 17.9, 84.7; AI forecast: 20.85845630168915, 62.76472624093294 ; AI error: 1253.9946884453109 BCD5 error: 98.7\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.8961426615715, BCD5 forecast: -38.0\n",
            "\tTrajectory Truth: 25.7, 87.9; AI forecast: 21.044201415777206, 63.03375562485307 ; AI error: 1396.43273113724 BCD5 error: 455.2\n",
            "\tIntensity Truth: 35.0, AI forecast: 52.99268126487732, BCD5 forecast: 7.0\n",
            "\tTrajectory Truth: 32.2, 88.0; AI forecast: 21.535282039642333, 63.027336343005295 ; AI error: 1477.8031716266642 BCD5 error: 727.0\n",
            "Found AL162017 at 2017-10-05 18:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.830268040299416, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 19.5, 85.2; AI forecast: 20.725107914209367, 62.78738142326474 ; AI error: 1264.7457728511706 BCD5 error: 156.9\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.92886143922806, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 27.6, 88.9; AI forecast: 21.211352729797362, 62.94574598185718 ; AI error: 1466.798542829801 BCD5 error: 538.5\n",
            "Found AL162017 at 2017-10-06 00:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 51.47033780813217, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 21.3, 85.9; AI forecast: 21.167383682727813, 62.5744853252545 ; AI error: 1304.2227157675848 BCD5 error: 182.2\n",
            "\tIntensity Truth: 75.0, AI forecast: 53.47397118806839, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 29.1, 89.2; AI forecast: 22.130702877044676, 62.70555898351594 ; AI error: 1490.4066657680416 BCD5 error: 548.2\n",
            "Found AL162017 at 2017-10-06 06:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 52.41901978850365, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 23.5, 86.5; AI forecast: 21.597852313518523, 62.5639603218995 ; AI error: 1330.642945563463 BCD5 error: 216.8\n",
            "\tIntensity Truth: 60.0, AI forecast: 53.50912183523178, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 30.5, 88.9; AI forecast: 22.296897602081298, 62.57656700294464 ; AI error: 1494.5307166954626 BCD5 error: 516.8\n",
            "Found AL162017 at 2017-10-06 12:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.39347285032272, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 25.7, 87.9; AI forecast: 21.339022707939147, 62.33507847535657 ; AI error: 1429.1782863277197 BCD5 error: 275.0\n",
            "\tIntensity Truth: 35.0, AI forecast: 51.17720700800419, BCD5 forecast: 22.0\n",
            "\tTrajectory Truth: 32.2, 88.0; AI forecast: 21.609298169612885, 62.26583584697218 ; AI error: 1512.1319042991365 BCD5 error: 480.5\n",
            "Found AL162017 at 2017-10-06 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.92543575819582, BCD5 forecast: -23.0\n",
            "\tTrajectory Truth: 27.6, 88.9; AI forecast: 20.90876861810684, 62.31163429314037 ; AI error: 1506.4413229258623 BCD5 error: 273.0\n",
            "Found AL162017 at 2017-10-07 00:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 51.632870733737946, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 29.1, 89.2; AI forecast: 21.822537195682525, 61.92936530653387 ; AI error: 1537.4068811794473 BCD5 error: 249.7\n",
            "Found AL162017 at 2017-10-07 06:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 53.081383407115936, BCD5 forecast: 30.0\n",
            "\tTrajectory Truth: 30.5, 88.9; AI forecast: 22.363682174682616, 61.72977457474917 ; AI error: 1535.6413239253463 BCD5 error: 73.4\n",
            "Found AL162017 at 2017-10-07 12:00:00\n",
            "\tIntensity Truth: 35.0, AI forecast: 54.29495811462402, BCD5 forecast: 21.0\n",
            "\tTrajectory Truth: 32.2, 88.0; AI forecast: 22.8701532125473, 61.37401329055428 ; AI error: 1518.9803363582805 BCD5 error: 66.0\n",
            "Found AL162017 at 2017-10-07 18:00:00\n",
            "Found AL162017 at 2017-10-08 00:00:00\n",
            "Found AL162017 at 2017-10-08 06:00:00\n",
            "Found AL162017 at 2017-10-08 12:00:00\n",
            "Found AL172017 at 2017-10-09 06:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.19992044195533, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.9, 38.8; AI forecast: 21.44684067964554, 60.537029936909676 ; AI error: 1320.5944482593588 BCD5 error: 59.7\n",
            "\tIntensity Truth: 55.0, AI forecast: 50.13212714344263, BCD5 forecast: -9.0\n",
            "\tTrajectory Truth: 30.4, 37.2; AI forecast: 22.2493848323822, 58.85531104505062 ; AI error: 1261.0874708024564 BCD5 error: 272.3\n",
            "\tIntensity Truth: 75.0, AI forecast: 49.29234094917774, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 30.2, 35.7; AI forecast: 22.751892161369323, 57.395118635892864 ; AI error: 1246.1358341142652 BCD5 error: 411.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 48.82090620696545, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 30.9, 34.4; AI forecast: 23.530970907211305, 56.0888694614172 ; AI error: 1236.9771987933977 BCD5 error: 504.4\n",
            "\tIntensity Truth: 95.0, AI forecast: 47.83447206020355, BCD5 forecast: -43.0\n",
            "\tTrajectory Truth: 33.4, 29.7; AI forecast: 24.061894273757936, 55.103191792964935 ; AI error: 1445.2246224769924 BCD5 error: 494.6\n",
            "Found AL172017 at 2017-10-09 12:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.47802601009607, BCD5 forecast: -6.0\n",
            "\tTrajectory Truth: 31.6, 38.5; AI forecast: 21.433341288566588, 60.437061399966474 ; AI error: 1323.550860125465 BCD5 error: 97.2\n",
            "\tIntensity Truth: 60.0, AI forecast: 49.91935446858406, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 30.0, 36.7; AI forecast: 22.065513467788698, 58.61470331698656 ; AI error: 1271.8325726717685 BCD5 error: 318.4\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.56972528249025, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 30.4, 35.7; AI forecast: 23.00514612197876, 56.85189941972494 ; AI error: 1215.7916829381213 BCD5 error: 420.0\n",
            "\tIntensity Truth: 80.0, AI forecast: 48.57763558626175, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 31.4, 33.4; AI forecast: 23.723480653762817, 55.36693615317344 ; AI error: 1253.8612591728886 BCD5 error: 492.6\n",
            "\tIntensity Truth: 100.0, AI forecast: 47.59319216012955, BCD5 forecast: -48.0\n",
            "\tTrajectory Truth: 34.2, 27.7; AI forecast: 24.168806266784667, 54.399288260936736 ; AI error: 1517.6166578264053 BCD5 error: 481.2\n",
            "Found AL172017 at 2017-10-09 18:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.229870323091745, BCD5 forecast: 2.0\n",
            "\tTrajectory Truth: 31.3, 38.2; AI forecast: 21.44965524673462, 60.235251041501755 ; AI error: 1321.0598048784573 BCD5 error: 135.5\n",
            "\tIntensity Truth: 65.0, AI forecast: 50.503958500921726, BCD5 forecast: -12.0\n",
            "\tTrajectory Truth: 29.8, 36.2; AI forecast: 22.691179156303406, 58.0563441991806 ; AI error: 1249.4195668201517 BCD5 error: 349.8\n",
            "\tIntensity Truth: 85.0, AI forecast: 50.05835139658302, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 30.5, 35.6; AI forecast: 23.721199560165406, 56.08071832209825 ; AI error: 1165.56773134492 BCD5 error: 431.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 49.60948761552572, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 32.0, 32.5; AI forecast: 24.502762174606325, 54.572437757253645 ; AI error: 1248.1722868602315 BCD5 error: 468.0\n",
            "\tIntensity Truth: 100.0, AI forecast: 50.5022381991148, BCD5 forecast: -47.0\n",
            "\tTrajectory Truth: 35.3, 25.2; AI forecast: 25.461012744903563, 53.724792945384976 ; AI error: 1584.0507711023906 BCD5 error: 453.2\n",
            "Found AL172017 at 2017-10-10 00:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 50.92475280165672, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 30.9, 37.8; AI forecast: 22.09709963798523, 59.85111503154039 ; AI error: 1294.1939224839607 BCD5 error: 121.0\n",
            "\tIntensity Truth: 70.0, AI forecast: 50.83069756627083, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 29.9, 35.8; AI forecast: 23.420490074157716, 57.45139947235584 ; AI error: 1222.788985643868 BCD5 error: 282.2\n",
            "\tIntensity Truth: 90.0, AI forecast: 50.549403093755245, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 30.5, 35.1; AI forecast: 24.474567270278932, 55.44020431041717 ; AI error: 1140.1586718786273 BCD5 error: 366.0\n",
            "\tIntensity Truth: 85.0, AI forecast: 51.502582877874374, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 32.6, 31.5; AI forecast: 25.716597032546996, 54.03020887374878 ; AI error: 1248.4825965638283 BCD5 error: 392.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 50.66127263009548, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 36.4, 22.6; AI forecast: 26.32721815109253, 53.076881027221674 ; AI error: 1666.6791525529484 BCD5 error: 496.8\n",
            "Found AL172017 at 2017-10-10 06:00:00\n",
            "\tIntensity Truth: 55.0, AI forecast: 50.66984444856644, BCD5 forecast: -5.0\n",
            "\tTrajectory Truth: 30.4, 37.2; AI forecast: 22.05026979446411, 59.68755730092525 ; AI error: 1307.6951935515367 BCD5 error: 91.4\n",
            "\tIntensity Truth: 75.0, AI forecast: 50.961510464549065, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 30.2, 35.7; AI forecast: 23.354123067855834, 57.2767188206315 ; AI error: 1224.9541116988632 BCD5 error: 192.2\n",
            "\tIntensity Truth: 90.0, AI forecast: 52.4072265625, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 30.9, 34.4; AI forecast: 24.9171094417572, 55.379041177034374 ; AI error: 1167.423239849475 BCD5 error: 283.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.02783018350601, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 33.4, 29.7; AI forecast: 25.88228006362915, 53.90175798535347 ; AI error: 1337.286991643644 BCD5 error: 386.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 52.33302131295204, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 37.9, 19.8; AI forecast: 26.661233139038085, 53.26800386607647 ; AI error: 1815.7869948046218 BCD5 error: 685.7\n",
            "Found AL172017 at 2017-10-10 12:00:00\n",
            "\tIntensity Truth: 60.0, AI forecast: 51.055782064795494, BCD5 forecast: -10.0\n",
            "\tTrajectory Truth: 30.0, 36.7; AI forecast: 22.011010384559633, 59.685120267421006 ; AI error: 1326.7046866070154 BCD5 error: 88.6\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.00644040107727, BCD5 forecast: -26.0\n",
            "\tTrajectory Truth: 30.4, 35.7; AI forecast: 23.806787633895873, 57.373120082914824 ; AI error: 1221.6835420794664 BCD5 error: 143.5\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.982139587402344, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 31.4, 33.4; AI forecast: 25.01852231025696, 55.40100014805793 ; AI error: 1222.8874586168515 BCD5 error: 262.5\n",
            "\tIntensity Truth: 100.0, AI forecast: 53.55215281248093, BCD5 forecast: -41.0\n",
            "\tTrajectory Truth: 34.2, 27.7; AI forecast: 26.070490980148314, 54.25036213696003 ; AI error: 1457.312560019438 BCD5 error: 450.9\n",
            "\tIntensity Truth: 85.0, AI forecast: 53.04907292127609, BCD5 forecast: -33.0\n",
            "\tTrajectory Truth: 39.9, 17.0; AI forecast: 26.47379093170166, 53.68258839249611 ; AI error: 1993.9361401689987 BCD5 error: 833.1\n",
            "Found AL172017 at 2017-10-10 18:00:00\n",
            "\tIntensity Truth: 65.0, AI forecast: 52.70168751478195, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 29.8, 36.2; AI forecast: 22.502699041366576, 59.781715128570795 ; AI error: 1341.2441583117507 BCD5 error: 78.5\n",
            "\tIntensity Truth: 85.0, AI forecast: 53.130240738391876, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 30.5, 35.6; AI forecast: 23.913393545150758, 57.411699555814266 ; AI error: 1227.501709657948 BCD5 error: 106.1\n",
            "\tIntensity Truth: 80.0, AI forecast: 53.95539611577988, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 32.0, 32.5; AI forecast: 25.16988024711609, 55.79901511967182 ; AI error: 1291.8441592937418 BCD5 error: 255.7\n",
            "\tIntensity Truth: 100.0, AI forecast: 53.57088476419449, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 35.3, 25.2; AI forecast: 25.77734808921814, 54.74461769163608 ; AI error: 1623.7204687050735 BCD5 error: 538.4\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.4202686548233, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 43.1, 14.3; AI forecast: 25.891874074935913, 54.20327998995781 ; AI error: 2200.6358251970555 BCD5 error: 977.9\n",
            "Found AL172017 at 2017-10-11 00:00:00\n",
            "\tIntensity Truth: 70.0, AI forecast: 51.033063903450966, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 29.9, 35.8; AI forecast: 22.05199146270752, 59.75764263793826 ; AI error: 1372.932284918235 BCD5 error: 36.4\n",
            "\tIntensity Truth: 90.0, AI forecast: 52.44579762220383, BCD5 forecast: -35.0\n",
            "\tTrajectory Truth: 30.5, 35.1; AI forecast: 23.536427640914916, 57.77633204758167 ; AI error: 1280.1187056387955 BCD5 error: 61.6\n",
            "\tIntensity Truth: 85.0, AI forecast: 52.68291026353836, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 32.6, 31.5; AI forecast: 24.46212205886841, 56.26166624724865 ; AI error: 1390.3956606091501 BCD5 error: 243.8\n",
            "\tIntensity Truth: 95.0, AI forecast: 52.17853620648384, BCD5 forecast: -38.0\n",
            "\tTrajectory Truth: 36.4, 22.6; AI forecast: 24.94114203453064, 55.227140527963634 ; AI error: 1808.954438599049 BCD5 error: 636.9\n",
            "Found AL172017 at 2017-10-11 06:00:00\n",
            "\tIntensity Truth: 75.0, AI forecast: 52.359536439180374, BCD5 forecast: -14.0\n",
            "\tTrajectory Truth: 30.2, 35.7; AI forecast: 22.179356026649476, 60.14849053248763 ; AI error: 1398.861586025744 BCD5 error: 42.3\n",
            "\tIntensity Truth: 90.0, AI forecast: 53.30002695322037, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 30.9, 34.4; AI forecast: 23.346156930923463, 58.24683294296264 ; AI error: 1349.2354987126018 BCD5 error: 56.9\n",
            "\tIntensity Truth: 95.0, AI forecast: 53.37211161851883, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 33.4, 29.7; AI forecast: 24.09589238166809, 56.73828823715448 ; AI error: 1523.3164472145065 BCD5 error: 299.7\n",
            "\tIntensity Truth: 90.0, AI forecast: 54.226520359516144, BCD5 forecast: -34.0\n",
            "\tTrajectory Truth: 37.9, 19.8; AI forecast: 25.113549852371214, 55.79588109105825 ; AI error: 1980.6677536372417 BCD5 error: 746.9\n",
            "Found AL172017 at 2017-10-11 12:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 51.930027306079865, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 30.4, 35.7; AI forecast: 21.850526905059816, 60.16036041602492 ; AI error: 1411.1506401671681 BCD5 error: 52.3\n",
            "\tIntensity Truth: 80.0, AI forecast: 52.91273444890976, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 31.4, 33.4; AI forecast: 22.84648745059967, 58.22156985849142 ; AI error: 1418.250287133662 BCD5 error: 77.9\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.70322102308273, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 34.2, 27.7; AI forecast: 24.192509746551515, 56.779186193644996 ; AI error: 1631.064209915004 BCD5 error: 364.4\n",
            "\tIntensity Truth: 85.0, AI forecast: 55.98440945148468, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 39.9, 17.0; AI forecast: 25.336877727508544, 55.822869321703905 ; AI error: 2127.98731880076 BCD5 error: 851.3\n",
            "Found AL172017 at 2017-10-11 18:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 52.0364585518837, BCD5 forecast: -18.0\n",
            "\tTrajectory Truth: 30.5, 35.6; AI forecast: 21.752424693107606, 60.08870806470513 ; AI error: 1416.8282535471142 BCD5 error: 43.1\n",
            "\tIntensity Truth: 80.0, AI forecast: 54.68809217214584, BCD5 forecast: -17.0\n",
            "\tTrajectory Truth: 32.0, 32.5; AI forecast: 23.357641839981078, 58.190749232470985 ; AI error: 1456.6377207025803 BCD5 error: 71.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 56.75886392593384, BCD5 forecast: -42.0\n",
            "\tTrajectory Truth: 35.3, 25.2; AI forecast: 24.79288830757141, 56.728749378025526 ; AI error: 1746.5780744027306 BCD5 error: 416.1\n",
            "\tIntensity Truth: 80.0, AI forecast: 59.07584369182587, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 43.1, 14.3; AI forecast: 26.2634069442749, 55.86193435937166 ; AI error: 2257.5488991191014 BCD5 error: 919.3\n",
            "Found AL172017 at 2017-10-12 00:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 54.27638828754425, BCD5 forecast: -20.0\n",
            "\tTrajectory Truth: 30.5, 35.1; AI forecast: 22.59174780845642, 60.06825281605124 ; AI error: 1418.8464538873259 BCD5 error: 50.4\n",
            "\tIntensity Truth: 85.0, AI forecast: 57.65994131565094, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 32.6, 31.5; AI forecast: 24.498437643051147, 58.087644119560714 ; AI error: 1479.3455525594513 BCD5 error: 127.7\n",
            "\tIntensity Truth: 95.0, AI forecast: 61.15620732307434, BCD5 forecast: -37.0\n",
            "\tTrajectory Truth: 36.4, 22.6; AI forecast: 26.460651779174803, 56.643139488995075 ; AI error: 1832.1338637872886 BCD5 error: 514.4\n",
            "Found AL172017 at 2017-10-12 06:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 54.8126956820488, BCD5 forecast: -16.0\n",
            "\tTrajectory Truth: 30.9, 34.4; AI forecast: 22.609127378463747, 59.98482326567173 ; AI error: 1455.0032419060815 BCD5 error: 71.0\n",
            "\tIntensity Truth: 95.0, AI forecast: 59.53549087047577, BCD5 forecast: -29.0\n",
            "\tTrajectory Truth: 33.4, 29.7; AI forecast: 24.907665967941284, 58.005591903626915 ; AI error: 1563.370616238924 BCD5 error: 238.2\n",
            "\tIntensity Truth: 90.0, AI forecast: 62.68685579299927, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 37.9, 19.8; AI forecast: 26.75225658416748, 56.44614911526441 ; AI error: 1961.1352341977029 BCD5 error: 679.1\n",
            "Found AL172017 at 2017-10-12 12:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 56.56282365322113, BCD5 forecast: -2.0\n",
            "\tTrajectory Truth: 31.4, 33.4; AI forecast: 23.132517528533935, 59.92337776795029 ; AI error: 1495.3998789204968 BCD5 error: 103.8\n",
            "\tIntensity Truth: 100.0, AI forecast: 61.354076862335205, BCD5 forecast: -31.0\n",
            "\tTrajectory Truth: 34.2, 27.7; AI forecast: 25.445441961288452, 57.774036686122415 ; AI error: 1645.168245996745 BCD5 error: 348.5\n",
            "\tIntensity Truth: 85.0, AI forecast: 65.97989797592163, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 39.9, 17.0; AI forecast: 28.012806129455566, 56.121770687401295 ; AI error: 2055.638736684102 BCD5 error: 847.0\n",
            "Found AL172017 at 2017-10-12 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 56.30263864994049, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 32.0, 32.5; AI forecast: 22.934397172927856, 59.7659425035119 ; AI error: 1545.7893690841088 BCD5 error: 106.4\n",
            "\tIntensity Truth: 100.0, AI forecast: 62.39088416099548, BCD5 forecast: -30.0\n",
            "\tTrajectory Truth: 35.3, 25.2; AI forecast: 25.841038465499878, 57.55060086399317 ; AI error: 1756.8812269614657 BCD5 error: 429.7\n",
            "\tIntensity Truth: 80.0, AI forecast: 66.51482820510864, BCD5 forecast: -19.0\n",
            "\tTrajectory Truth: 43.1, 14.3; AI forecast: 28.172286415100096, 55.88865648955107 ; AI error: 2190.6288860613604 BCD5 error: 975.9\n",
            "Found AL172017 at 2017-10-13 00:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 57.79568254947662, BCD5 forecast: -1.0\n",
            "\tTrajectory Truth: 32.6, 31.5; AI forecast: 23.665338802337647, 59.6839096866548 ; AI error: 1579.8799308568234 BCD5 error: 79.6\n",
            "\tIntensity Truth: 95.0, AI forecast: 63.49825620651245, BCD5 forecast: -25.0\n",
            "\tTrajectory Truth: 36.4, 22.6; AI forecast: 26.441328239440917, 57.412681658565994 ; AI error: 1869.4033981007851 BCD5 error: 430.8\n",
            "Found AL172017 at 2017-10-13 06:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 56.97302222251892, BCD5 forecast: -15.0\n",
            "\tTrajectory Truth: 33.4, 29.7; AI forecast: 23.281033945083617, 59.65452615991234 ; AI error: 1688.0069648552396 BCD5 error: 75.1\n",
            "\tIntensity Truth: 90.0, AI forecast: 63.4938645362854, BCD5 forecast: -24.0\n",
            "\tTrajectory Truth: 37.9, 19.8; AI forecast: 26.34992094039917, 57.59826968610287 ; AI error: 2026.9077864206513 BCD5 error: 417.9\n",
            "Found AL172017 at 2017-10-13 12:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 57.074753642082214, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 34.2, 27.7; AI forecast: 23.60322723388672, 60.0844886675477 ; AI error: 1807.7510610340394 BCD5 error: 99.2\n",
            "\tIntensity Truth: 85.0, AI forecast: 60.8111310005188, BCD5 forecast: -32.0\n",
            "\tTrajectory Truth: 39.9, 17.0; AI forecast: 25.719051027297972, 58.19171683490276 ; AI error: 2222.4395531874934 BCD5 error: 469.9\n",
            "Found AL172017 at 2017-10-13 18:00:00\n",
            "\tIntensity Truth: 100.0, AI forecast: 54.279673397541046, BCD5 forecast: -36.0\n",
            "\tTrajectory Truth: 35.3, 25.2; AI forecast: 22.53860273361206, 60.05485275685787 ; AI error: 1972.4909515217457 BCD5 error: 178.3\n",
            "\tIntensity Truth: 80.0, AI forecast: 57.16857731342316, BCD5 forecast: -28.0\n",
            "\tTrajectory Truth: 43.1, 14.3; AI forecast: 24.523184537887573, 58.07398325055837 ; AI error: 2416.417026618808 BCD5 error: 580.2\n",
            "Found AL172017 at 2017-10-14 00:00:00\n",
            "\tIntensity Truth: 95.0, AI forecast: 53.523347079753876, BCD5 forecast: -21.0\n",
            "\tTrajectory Truth: 36.4, 22.6; AI forecast: 22.714572715759278, 59.910966865718365 ; AI error: 2098.3132250415483 BCD5 error: 175.9\n",
            "Found AL172017 at 2017-10-14 06:00:00\n",
            "\tIntensity Truth: 90.0, AI forecast: 51.7184916138649, BCD5 forecast: -8.0\n",
            "\tTrajectory Truth: 37.9, 19.8; AI forecast: 22.489917874336243, 59.55082104727626 ; AI error: 2239.296374651039 BCD5 error: 136.4\n",
            "Found AL172017 at 2017-10-14 12:00:00\n",
            "\tIntensity Truth: 85.0, AI forecast: 49.70182513818145, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 39.9, 17.0; AI forecast: 22.753838300704956, 59.19248992428183 ; AI error: 2368.2277067736054 BCD5 error: 122.4\n",
            "Found AL172017 at 2017-10-14 18:00:00\n",
            "\tIntensity Truth: 80.0, AI forecast: 54.34817045927048, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 43.1, 14.3; AI forecast: 23.042813873291017, 58.432428024709225 ; AI error: 2487.8454068889996 BCD5 error: 155.3\n",
            "Found AL172017 at 2017-10-15 00:00:00\n",
            "Found AL172017 at 2017-10-15 06:00:00\n",
            "Found AL172017 at 2017-10-15 12:00:00\n",
            "Found AL172017 at 2017-10-15 18:00:00\n",
            "Found AL192017 at 2017-11-07 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.85403390228748, BCD5 forecast: -3.0\n",
            "\tTrajectory Truth: 34.6, 48.7; AI forecast: 21.69995094537735, 59.99769249558449 ; AI error: 976.9942397200497 BCD5 error: 108.5\n",
            "\tIntensity Truth: 45.0, AI forecast: 51.03053316473961, BCD5 forecast: 3.0\n",
            "\tTrajectory Truth: 41.8, 48.8; AI forecast: 22.653345680236818, 57.87650339305401 ; AI error: 1236.752374349733 BCD5 error: 416.2\n",
            "Found AL192017 at 2017-11-07 06:00:00\n",
            "\tIntensity Truth: 50.0, AI forecast: 50.946481600403786, BCD5 forecast: 0.0\n",
            "\tTrajectory Truth: 36.4, 48.7; AI forecast: 21.667076528072357, 59.97750589475035 ; AI error: 1062.523153063303 BCD5 error: 133.5\n",
            "Found AL192017 at 2017-11-07 12:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 50.678503811359406, BCD5 forecast: 1.0\n",
            "\tTrajectory Truth: 38.3, 48.8; AI forecast: 21.60131217241287, 59.768030353635545 ; AI error: 1151.4755429350607 BCD5 error: 178.4\n",
            "Found AL192017 at 2017-11-07 18:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 51.63644164800644, BCD5 forecast: -4.0\n",
            "\tTrajectory Truth: 40.1, 49.0; AI forecast: 21.915799593925477, 59.53043516501784 ; AI error: 1216.6644903455403 BCD5 error: 198.7\n",
            "Found AL192017 at 2017-11-08 00:00:00\n",
            "\tIntensity Truth: 45.0, AI forecast: 52.35202491283417, BCD5 forecast: 4.0\n",
            "\tTrajectory Truth: 41.8, 48.8; AI forecast: 22.568463063240053, 59.2162046097219 ; AI error: 1267.8352160919208 BCD5 error: 181.9\n",
            "Found AL192017 at 2017-11-08 06:00:00\n",
            "Found AL192017 at 2017-11-08 12:00:00\n"
          ]
        }
      ],
      "source": [
        "# Compare predictions when we can find them\n",
        "import errors\n",
        "errordb = errors.models.models(\"errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt\")\n",
        "ai_wind_errors = []\n",
        "ai_track_errors = []\n",
        "bcd5_wind_errors = []\n",
        "bcd5_track_errors = []\n",
        "for index, prediction in enumerate(tracks['wind_predictions']) :\n",
        "    # Find the time stamp for the storm ID in the error database\n",
        "    if prediction == [] :\n",
        "      continue\n",
        "    valid_time = prediction[0]['valid_time']\n",
        "    storm_id = prediction[0]['storm_id']\n",
        "    # Check to see if we have error for this storm and at the valid time\n",
        "    if storm_id in errordb.models['BCD5'].storm and valid_time in errordb.models['BCD5'].storm[storm_id] :\n",
        "        print(\"Found {} at {}\".format(storm_id, valid_time))\n",
        "        # If we find it, compare\n",
        "        for i, forecast in enumerate(prediction) :\n",
        "            # See if we can find another prediction like that in the error database\n",
        "            if errordb.models['BCD5'].storm[storm_id][valid_time]['intensity_forecast'][forecast['forecast_time'].to_pydatetime()] :\n",
        "                print(\"\\tIntensity Truth: {}, AI forecast: {}, BCD5 forecast: {}\".format(forecast['truth'],\n",
        "                                                                                         forecast['ai-wind'],\n",
        "                                                                                         errordb.models['BCD5'].storm[storm_id][valid_time]['track_forecast'][forecast['forecast_time'].to_pydatetime()]))\n",
        "                print(\"\\tTrajectory Truth: {}, {}; AI forecast: {}, {} ; AI error: {} BCD5 error: {}\".format(tracks['lat_predictions'][index][i]['truth'],\n",
        "                                                                                                       tracks['long_predictions'][index][i]['truth'],\n",
        "                                                                                                       tracks['lat_predictions'][index][i]['ai-lat'],\n",
        "                                                                                                       tracks['long_predictions'][index][i]['ai-long'],\n",
        "                                                                                                       distance((tracks['lat_predictions'][index][i]['truth'], tracks['long_predictions'][index][i]['truth']), (tracks['lat_predictions'][index][i]['ai-lat'], tracks['long_predictions'][index][i]['ai-long'])),\n",
        "                                                                                                       errordb.models['BCD5'].storm[storm_id][valid_time]['intensity_forecast'][forecast['forecast_time'].to_pydatetime()]\n",
        "                                                                                                      ))\n",
        "                ai_wind_errors.append(abs(forecast['truth'] - forecast['ai-wind']))\n",
        "                ai_track_errors.append(abs(distance((tracks['lat_predictions'][index][i]['truth'], tracks['long_predictions'][index][i]['truth']), (tracks['lat_predictions'][index][i]['ai-lat'], tracks['long_predictions'][index][i]['ai-long']))))\n",
        "                bcd5_wind_errors.append(abs(errordb.models['BCD5'].storm[storm_id][valid_time]['track_forecast'][forecast['forecast_time'].to_pydatetime()]))                \n",
        "                bcd5_track_errors.append(abs(errordb.models['BCD5'].storm[storm_id][valid_time]['intensity_forecast'][forecast['forecast_time'].to_pydatetime()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "btLAyw8CTA7B",
        "outputId": "9310bc94-b2ad-4c95-d26c-904f68243a47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  997.000000\n",
              "mean    34.422137\n",
              "std     27.445393\n",
              "min      0.086743\n",
              "25%     12.332398\n",
              "50%     27.308779\n",
              "75%     50.385195\n",
              "max    107.685952"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70adbe84-1efc-4852-a129-ca1cda99cd0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>34.422137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>27.445393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.086743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.332398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>27.308779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.385195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>107.685952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70adbe84-1efc-4852-a129-ca1cda99cd0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70adbe84-1efc-4852-a129-ca1cda99cd0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70adbe84-1efc-4852-a129-ca1cda99cd0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "pd.DataFrame(ai_wind_errors).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "eRxsLuy4TA7D",
        "outputId": "89989c01-580c-49af-9a84-eebcfecd092a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  997.000000\n",
              "mean    17.656971\n",
              "std     15.179471\n",
              "min      0.000000\n",
              "25%      6.000000\n",
              "50%     13.000000\n",
              "75%     26.000000\n",
              "max     79.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f3b8e4f-edbe-412e-a0a8-2b46130f26d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.656971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.179471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f3b8e4f-edbe-412e-a0a8-2b46130f26d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f3b8e4f-edbe-412e-a0a8-2b46130f26d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f3b8e4f-edbe-412e-a0a8-2b46130f26d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "pd.DataFrame(bcd5_wind_errors).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aam7310tTA7F",
        "outputId": "fbee186f-4930-4426-d605-c5b9a4b7ff4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   997.000000\n",
              "mean    997.406095\n",
              "std     488.626847\n",
              "min     154.882521\n",
              "25%     634.849012\n",
              "50%     934.169383\n",
              "75%    1187.469225\n",
              "max    2334.247018"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bc2f1f8-e34f-4c81-ad3f-cf4bb2b41a67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>997.406095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>488.626847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>154.882521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>634.849012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>934.169383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1187.469225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2334.247018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bc2f1f8-e34f-4c81-ad3f-cf4bb2b41a67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bc2f1f8-e34f-4c81-ad3f-cf4bb2b41a67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bc2f1f8-e34f-4c81-ad3f-cf4bb2b41a67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "pd.DataFrame(ai_track_errors).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "rbC4Y2CfTA7G",
        "outputId": "b945b6be-afb2-406f-c130-c7fbd4593ee3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0\n",
              "count   997.000000\n",
              "mean    249.861785\n",
              "std     225.954794\n",
              "min       5.800000\n",
              "25%      72.800000\n",
              "50%     176.900000\n",
              "75%     366.100000\n",
              "max    1164.700000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14c2aaf5-c024-4c38-8ee2-f56aff7fe7a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>249.861785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>225.954794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>72.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>176.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>366.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1164.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14c2aaf5-c024-4c38-8ee2-f56aff7fe7a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14c2aaf5-c024-4c38-8ee2-f56aff7fe7a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14c2aaf5-c024-4c38-8ee2-f56aff7fe7a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pd.DataFrame(bcd5_track_errors).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWcOFR7fx7CO",
        "outputId": "d517c341-e45a-4902-c1cf-b9b65cf54e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1.18253968, -0.23901582,  0.28571429,  0.        ,\n",
              "         -0.55      , -2.        , -1.25      ,  1.        ,\n",
              "         -5.        , -0.0625    ,  0.4       ],\n",
              "        [ 1.12698413, -0.26713533,  0.28571429,  0.        ,\n",
              "         -0.7       , -2.        , -1.25      ,  1.        ,\n",
              "         -5.        , -0.0625    ,  0.8       ],\n",
              "        [ 1.07142857, -0.29876977,  0.14285714, -1.        ,\n",
              "         -0.65      , -2.        , -1.33333333,  1.        ,\n",
              "         -5.        ,  0.        , -0.4       ],\n",
              "        [ 1.03174603, -0.32688928,  0.        , -1.        ,\n",
              "         -0.6       , -1.6       , -1.25      ,  1.        ,\n",
              "         -5.        ,  0.        ,  0.        ],\n",
              "        [ 0.99206349, -0.35852373,  0.        ,  0.        ,\n",
              "         -0.55      , -1.6       , -1.33333333,  1.        ,\n",
              "         -5.        ,  0.        ,  0.4       ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "tracks['inputs'][:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SmjvdTI14mr",
        "outputId": "6f4f60de-a4fd-4015-91b8-3b63a7d93a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47.72679101675749,\n",
              " 48.78862038254738,\n",
              " 48.46569649875164,\n",
              " 47.401592172682285,\n",
              " 45.882226610556245]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "[output[2] for output in \n",
        " scaler.inverse_transform(\n",
        "     [[0,0,winds[0],0,0,0,0,0,0,0,0] for winds in model_wind.predict(tracks['inputs'][:1])[0]]\n",
        " )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lvAJObXp66cR"
      },
      "outputs": [],
      "source": [
        "def hurricane_ai(input):\n",
        "  '''\n",
        "  input = {\n",
        "    -120 : timestep,\n",
        "    -96 : timestep,\n",
        "    -72 : timestep,\n",
        "    -48 : timestep,\n",
        "    -24 : timestep,\n",
        "    0 : timestep\n",
        "  }\n",
        "  output = {\n",
        "    24 : prediction,\n",
        "    48 : prediction,\n",
        "    72 : prediction,\n",
        "    96 : prediction,\n",
        "    120 : prediction\n",
        "  }\n",
        "  timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'min_pressure' : float,\n",
        "      'entry-time' : datetime\n",
        "  }\n",
        "  prediction = {\n",
        "    'lat' : float,\n",
        "    'long' : float,\n",
        "    'max-winds' : float\n",
        "  }\n",
        "  '''\n",
        "  # Take entries and transform them into our data model\n",
        "  extract = []\n",
        "  temp = None\n",
        "  for index, value in enumerate([-120, -96, -72, -48, -24, 0]):\n",
        "    if not index :\n",
        "      temp = input[value]\n",
        "      continue\n",
        "    else:\n",
        "      extract.append(list(feature_extraction(input[value], temp).values()))\n",
        "      temp = input[value]\n",
        "  \n",
        "  state = np.expand_dims(scaler.transform(extract), axis = 0)\n",
        "  print('extract: {}, state: {}'.format(extract, state))\n",
        "  # Finally, use our hurricane ai to predict storm state\n",
        "  lat = [output[0] for output in scaler.inverse_transform(\n",
        "      [[lat[0],0,0,0,0,0,0,0,0,0,0] for lat in model_lat.predict(state)[0]])]\n",
        "  long = [output[1] for output in scaler.inverse_transform(\n",
        "      [[0,long[0],0,0,0,0,0,0,0,0,0] for long in model_long.predict(state)[0]])]\n",
        "  wind = [output[2] for output in scaler.inverse_transform(\n",
        "      [[0,0,wind[0],0,0,0,0,0,0,0,0] for wind in model_wind.predict(state)[0]])]\n",
        "   \n",
        "  output = dict()\n",
        "  for index, value in enumerate([24, 48, 72, 96, 120]) :\n",
        "    output[value] = {\n",
        "        'lat' : lat[index],\n",
        "        'long' : long[index],\n",
        "        'max_wind' : wind[index]\n",
        "    }\n",
        "  \n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SjOHJAOlM2bR"
      },
      "outputs": [],
      "source": [
        "from dateutil.parser import parse\n",
        "input = {\n",
        "  0 : {\n",
        "      'entry_time' : parse('Fri Aug 30 2019 1100 PM'),\n",
        "      'lat' : 25.5,\n",
        "      'long' : 71.4,\n",
        "      'max_wind' : 140 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 948.0\n",
        "    },\n",
        "  -24 : {\n",
        "      'entry_time' : parse('Thu Aug 29 2019 1100 PM'),\n",
        "      'lat' : 23.3,\n",
        "      'long' : 68.4,\n",
        "      'max_wind' : 105 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 977.0\n",
        "    },\n",
        "  -48 : {\n",
        "      'entry_time' : parse('Wed Aug 28 2019 1100 PM'),\n",
        "      'lat' : 19.7,\n",
        "      'long' : 66.0,\n",
        "      'max_wind' : 85 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 986.0\n",
        "    },\n",
        "  -72 : {\n",
        "      'entry_time' : parse('Tue Aug 27 2019 1100 PM'),\n",
        "      'lat' : 16.0,\n",
        "      'long' : 63.0,\n",
        "      'max_wind' : 50 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 1006.0\n",
        "    },\n",
        "  -96 : {\n",
        "      'entry_time' : parse('Mon Aug 26 2019 1100 PM'),\n",
        "      'lat' : 13.2,\n",
        "      'long' : 59.7,\n",
        "      'max_wind' : 50 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 1003.0\n",
        "    },\n",
        "  -120 : {\n",
        "      'entry_time' : parse('Sun Aug 25 2019 1100 PM'),\n",
        "      'lat' : 11.7,\n",
        "      'long' : 55.3,\n",
        "      'max_wind' : 50 / 1.51 , # mph to knots\n",
        "      'min_pressure' : 1003.0\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_evczPmdLabu",
        "outputId": "87712bb4-c1fb-4f06-9b2a-77699eecc7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extract: [[13.2, 59.7, 33.11258278145695, 0.0, 1003.0, 0.0625, 0.18333333333333357, 2019, 8, 26, 23], [16.0, 63.0, 33.11258278145695, 0.0, 1006.0, 0.1166666666666667, 0.13749999999999987, 2019, 8, 27, 23], [19.7, 66.0, 56.29139072847682, 11.589403973509935, 986.0, 0.15416666666666665, 0.125, 2019, 8, 28, 23], [23.3, 68.4, 69.5364238410596, 6.622516556291391, 977.0, 0.15000000000000005, 0.10000000000000024, 2019, 8, 29, 23], [25.5, 71.4, 92.71523178807946, 11.589403973509931, 948.0, 0.09166666666666663, 0.125, 2019, 8, 30, 23]], state: [[[-0.55555556  0.11950791 -0.33964049  0.          0.15\n",
            "    0.15        0.33333333  1.125      -1.          0.5625\n",
            "    1.13333333]\n",
            "  [-0.33333333  0.23550088 -0.33964049  0.          0.3\n",
            "    0.8         0.10416667  1.125      -1.          0.625\n",
            "    1.13333333]\n",
            "  [-0.03968254  0.34094903  0.32261116  1.1589404  -0.7\n",
            "    1.25        0.04166667  1.125      -1.          0.6875\n",
            "    1.13333333]\n",
            "  [ 0.24603175  0.42530756  0.70104068  0.66225166 -1.15\n",
            "    1.2        -0.08333333  1.125      -1.          0.75\n",
            "    1.13333333]\n",
            "  [ 0.42063492  0.53075571  1.36329234  1.1589404  -2.6\n",
            "    0.5         0.04166667  1.125      -1.          0.8125\n",
            "    1.13333333]]]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{24: {'lat': 21.25751706957817,\n",
              "  'long': 57.34351139329374,\n",
              "  'max_wind': 46.73190778121352},\n",
              " 48: {'lat': 22.545081627368926,\n",
              "  'long': 58.04283459614962,\n",
              "  'max_wind': 48.29919803887606},\n",
              " 72: {'lat': 24.335165071487424,\n",
              "  'long': 58.701074599847196,\n",
              "  'max_wind': 50.07107838988304},\n",
              " 96: {'lat': 26.03364340662956,\n",
              "  'long': 59.0436025429517,\n",
              "  'max_wind': 51.35034926235676},\n",
              " 120: {'lat': 27.577855026721952,\n",
              "  'long': 59.306639136746526,\n",
              "  'max_wind': 52.32640214264393}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "hurricane_ai(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "u58TQ3E0fQ5H",
        "outputId": "60c70ddd-a17e-44f6-e55e-29454661cd98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X8b7S3umtz1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "PACFL_code",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "95eeeebb92837c7373b86928c2484231cfe753ebd466f3486b62e031e41724b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
